pygame 2.6.1 (SDL 2.28.4, Python 3.8.20)
Hello from the pygame community. https://www.pygame.org/contribute.html
TrainPipeline:init: 初始化: TrainPipeline
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1, episode_len:9
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2, episode_len:9
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:3, episode_len:9
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:4, episode_len:9
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:5, episode_len:9
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:6, episode_len:9
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:7, episode_len:9
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:8, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.23485,lr_multiplier:0.667,loss:1.991982102394104,entropy:2.2622547149658203,explained_var_old:0.904,explained_var_new:0.952
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:9, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.09309,lr_multiplier:0.444,loss:1.7932803630828857,entropy:1.581100344657898,explained_var_old:0.951,explained_var_new:0.962
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:10, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.04130,lr_multiplier:0.296,loss:1.7416396141052246,entropy:1.7727439403533936,explained_var_old:0.964,explained_var_new:0.975
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:11, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01364,lr_multiplier:0.296,loss:1.6992192268371582,entropy:1.6639223098754883,explained_var_old:0.974,explained_var_new:0.984
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:12, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00714,lr_multiplier:0.444,loss:1.6505757570266724,entropy:1.6053555011749268,explained_var_old:0.985,explained_var_new:0.992
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:13, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00775,lr_multiplier:0.667,loss:1.6825778484344482,entropy:1.7069581747055054,explained_var_old:0.992,explained_var_new:0.998
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:14, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01085,lr_multiplier:0.667,loss:1.6701076030731201,entropy:1.650517463684082,explained_var_old:0.999,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:15, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00667,lr_multiplier:1.000,loss:1.6611666679382324,entropy:1.6684149503707886,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:16, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00682,lr_multiplier:1.500,loss:1.5983991622924805,entropy:1.5857038497924805,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:17, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00668,lr_multiplier:2.250,loss:1.6317436695098877,entropy:1.6236422061920166,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:18, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00856,lr_multiplier:3.375,loss:1.5990550518035889,entropy:1.603131651878357,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:19, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.08753,lr_multiplier:2.250,loss:1.637933611869812,entropy:1.617417573928833,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:20, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.32866,lr_multiplier:1.500,loss:1.7085442543029785,entropy:1.79393470287323,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:21, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.13789,lr_multiplier:1.000,loss:1.6194510459899902,entropy:1.5692212581634521,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:22, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.07892,lr_multiplier:0.667,loss:1.5918433666229248,entropy:1.5759717226028442,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:23, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02727,lr_multiplier:0.667,loss:1.5750786066055298,entropy:1.5753865242004395,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:24, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00791,lr_multiplier:1.000,loss:1.6123602390289307,entropy:1.6537203788757324,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:25, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00893,lr_multiplier:1.500,loss:1.5790444612503052,entropy:1.5469731092453003,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:26, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00859,lr_multiplier:2.250,loss:1.6144331693649292,entropy:1.6149547100067139,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:27, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00877,lr_multiplier:3.375,loss:1.6116458177566528,entropy:1.6563732624053955,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:28, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00687,lr_multiplier:5.062,loss:1.6193581819534302,entropy:1.6326019763946533,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:29, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03089,lr_multiplier:5.062,loss:1.631264567375183,entropy:1.7251542806625366,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:30, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.04922,lr_multiplier:3.375,loss:1.6100114583969116,entropy:1.5780237913131714,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:31, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01173,lr_multiplier:3.375,loss:1.5965815782546997,entropy:1.61360764503479,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:32, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00892,lr_multiplier:5.062,loss:1.5826137065887451,entropy:1.5897998809814453,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:33, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01153,lr_multiplier:5.062,loss:1.5512416362762451,entropy:1.5553638935089111,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:34, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00868,lr_multiplier:7.594,loss:1.5502851009368896,entropy:1.5531061887741089,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:35, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01337,lr_multiplier:7.594,loss:1.568225383758545,entropy:1.6076711416244507,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:36, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01671,lr_multiplier:7.594,loss:1.5887740850448608,entropy:1.634765386581421,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:37, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01003,lr_multiplier:7.594,loss:1.5859123468399048,entropy:1.5842578411102295,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:38, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01072,lr_multiplier:7.594,loss:1.5958276987075806,entropy:1.6156061887741089,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:39, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01578,lr_multiplier:7.594,loss:1.5879908800125122,entropy:1.5686309337615967,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:40, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01657,lr_multiplier:7.594,loss:1.5132158994674683,entropy:1.552446722984314,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:41, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01330,lr_multiplier:7.594,loss:1.5482243299484253,entropy:1.5809978246688843,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:42, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01091,lr_multiplier:7.594,loss:1.5389280319213867,entropy:1.5433987379074097,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:43, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00969,lr_multiplier:11.391,loss:1.554502248764038,entropy:1.5463130474090576,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:44, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.09542,lr_multiplier:7.594,loss:1.6040692329406738,entropy:1.5240262746810913,explained_var_old:1.000,explained_var_new:0.996
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:45, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.31859,lr_multiplier:5.062,loss:1.8000141382217407,entropy:1.7831286191940308,explained_var_old:0.865,explained_var_new:0.357
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:46, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.22791,lr_multiplier:3.375,loss:3.0169689655303955,entropy:1.6038293838500977,explained_var_old:0.263,explained_var_new:0.733
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:47, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.17467,lr_multiplier:2.250,loss:1.8760194778442383,entropy:1.7450499534606934,explained_var_old:0.772,explained_var_new:0.807
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:48, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.20299,lr_multiplier:1.500,loss:1.9599549770355225,entropy:1.8656412363052368,explained_var_old:0.757,explained_var_new:0.760
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:49, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.13711,lr_multiplier:1.000,loss:1.9388391971588135,entropy:1.5652869939804077,explained_var_old:0.739,explained_var_new:0.743
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:50, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.08440,lr_multiplier:0.667,loss:1.9651224613189697,entropy:1.7133865356445312,explained_var_old:0.733,explained_var_new:0.740
已经训练: 50轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 8, lose: 2, tie:0
相较于MCTS@1000, 截至目前的最佳胜率=0.8 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:51, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.04390,lr_multiplier:0.444,loss:1.8381364345550537,entropy:1.7147778272628784,explained_var_old:0.814,explained_var_new:0.819
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:52, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01719,lr_multiplier:0.444,loss:1.7626928091049194,entropy:1.5504827499389648,explained_var_old:0.798,explained_var_new:0.797
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:53, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00861,lr_multiplier:0.667,loss:1.7999186515808105,entropy:1.578601598739624,explained_var_old:0.775,explained_var_new:0.775
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:54, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00969,lr_multiplier:1.000,loss:1.8162031173706055,entropy:1.6260509490966797,explained_var_old:0.794,explained_var_new:0.798
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:55, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01723,lr_multiplier:1.000,loss:1.8697770833969116,entropy:1.6906238794326782,explained_var_old:0.799,explained_var_new:0.802
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:56, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01460,lr_multiplier:1.000,loss:1.782130479812622,entropy:1.6274843215942383,explained_var_old:0.821,explained_var_new:0.825
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:57, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00804,lr_multiplier:1.500,loss:1.8491992950439453,entropy:1.6644424200057983,explained_var_old:0.817,explained_var_new:0.821
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:58, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00993,lr_multiplier:2.250,loss:1.7429308891296387,entropy:1.6002757549285889,explained_var_old:0.855,explained_var_new:0.854
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:59, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02332,lr_multiplier:2.250,loss:1.7406085729599,entropy:1.6015868186950684,explained_var_old:0.844,explained_var_new:0.851
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:60, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02079,lr_multiplier:2.250,loss:1.7795310020446777,entropy:1.6227035522460938,explained_var_old:0.853,explained_var_new:0.858
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:61, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.05563,lr_multiplier:1.500,loss:1.7828953266143799,entropy:1.6199322938919067,explained_var_old:0.870,explained_var_new:0.871
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:62, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.14258,lr_multiplier:1.000,loss:1.8443279266357422,entropy:1.7901867628097534,explained_var_old:0.819,explained_var_new:0.818
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:63, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.09486,lr_multiplier:0.667,loss:1.877632737159729,entropy:1.5492284297943115,explained_var_old:0.849,explained_var_new:0.852
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:64, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03259,lr_multiplier:0.667,loss:1.7951451539993286,entropy:1.5678660869598389,explained_var_old:0.877,explained_var_new:0.876
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:65, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01607,lr_multiplier:0.667,loss:1.7406153678894043,entropy:1.6917343139648438,explained_var_old:0.916,explained_var_new:0.919
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:66, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01641,lr_multiplier:0.667,loss:1.765595555305481,entropy:1.5870091915130615,explained_var_old:0.834,explained_var_new:0.836
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:67, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01109,lr_multiplier:0.667,loss:1.8438482284545898,entropy:1.6913511753082275,explained_var_old:0.802,explained_var_new:0.805
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:68, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00785,lr_multiplier:1.000,loss:1.7607022523880005,entropy:1.6212563514709473,explained_var_old:0.862,explained_var_new:0.864
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:69, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01285,lr_multiplier:1.000,loss:1.7498055696487427,entropy:1.6165024042129517,explained_var_old:0.870,explained_var_new:0.870
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:70, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01171,lr_multiplier:1.000,loss:1.8511991500854492,entropy:1.650704264640808,explained_var_old:0.804,explained_var_new:0.812
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:71, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00992,lr_multiplier:1.500,loss:1.747969388961792,entropy:1.6525017023086548,explained_var_old:0.888,explained_var_new:0.888
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:72, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01331,lr_multiplier:1.500,loss:1.8740360736846924,entropy:1.7123515605926514,explained_var_old:0.827,explained_var_new:0.833
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:73, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01414,lr_multiplier:1.500,loss:1.7163805961608887,entropy:1.5749974250793457,explained_var_old:0.870,explained_var_new:0.873
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:74, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02159,lr_multiplier:1.500,loss:1.779873013496399,entropy:1.562329649925232,explained_var_old:0.788,explained_var_new:0.796
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:75, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01416,lr_multiplier:1.500,loss:1.87917160987854,entropy:1.644866943359375,explained_var_old:0.800,explained_var_new:0.806
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:76, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.03692,lr_multiplier:1.500,loss:1.9033076763153076,entropy:1.686772346496582,explained_var_old:0.762,explained_var_new:0.750
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:77, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.04032,lr_multiplier:1.000,loss:1.779693365097046,entropy:1.6620186567306519,explained_var_old:0.852,explained_var_new:0.851
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:78, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.04477,lr_multiplier:0.667,loss:1.9658989906311035,entropy:1.7098047733306885,explained_var_old:0.716,explained_var_new:0.719
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:79, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01608,lr_multiplier:0.667,loss:1.8739628791809082,entropy:1.6677902936935425,explained_var_old:0.788,explained_var_new:0.789
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:80, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01642,lr_multiplier:0.667,loss:1.9002127647399902,entropy:1.6773154735565186,explained_var_old:0.768,explained_var_new:0.773
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:81, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01317,lr_multiplier:0.667,loss:1.815287709236145,entropy:1.5924935340881348,explained_var_old:0.777,explained_var_new:0.786
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:82, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01789,lr_multiplier:0.667,loss:1.8107913732528687,entropy:1.6542319059371948,explained_var_old:0.818,explained_var_new:0.820
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:83, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.00805,lr_multiplier:1.000,loss:1.8642255067825317,entropy:1.7016624212265015,explained_var_old:0.816,explained_var_new:0.820
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:84, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02837,lr_multiplier:1.000,loss:1.8335932493209839,entropy:1.639835000038147,explained_var_old:0.783,explained_var_new:0.790
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:85, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02706,lr_multiplier:1.000,loss:1.9753105640411377,entropy:1.7498866319656372,explained_var_old:0.742,explained_var_new:0.754
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:86, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02386,lr_multiplier:1.000,loss:1.9237579107284546,entropy:1.7009351253509521,explained_var_old:0.768,explained_var_new:0.771
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:87, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01965,lr_multiplier:1.000,loss:1.878663420677185,entropy:1.6883294582366943,explained_var_old:0.798,explained_var_new:0.805
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:88, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02262,lr_multiplier:1.000,loss:1.9017163515090942,entropy:1.704439401626587,explained_var_old:0.777,explained_var_new:0.781
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:89, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01619,lr_multiplier:1.000,loss:1.7862536907196045,entropy:1.66555655002594,explained_var_old:0.867,explained_var_new:0.873
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:90, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01734,lr_multiplier:1.000,loss:1.9620760679244995,entropy:1.7641010284423828,explained_var_old:0.752,explained_var_new:0.763
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:91, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.03326,lr_multiplier:1.000,loss:1.8678312301635742,entropy:1.6964094638824463,explained_var_old:0.789,explained_var_new:0.794
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:92, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03008,lr_multiplier:1.000,loss:1.82585608959198,entropy:1.6390360593795776,explained_var_old:0.833,explained_var_new:0.836
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:93, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01633,lr_multiplier:1.000,loss:1.930840015411377,entropy:1.7721009254455566,explained_var_old:0.837,explained_var_new:0.842
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:94, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03151,lr_multiplier:1.000,loss:1.8919519186019897,entropy:1.7542752027511597,explained_var_old:0.800,explained_var_new:0.809
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:95, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01799,lr_multiplier:1.000,loss:1.896798014640808,entropy:1.7411291599273682,explained_var_old:0.804,explained_var_new:0.806
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:96, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02300,lr_multiplier:1.000,loss:1.9184579849243164,entropy:1.680630087852478,explained_var_old:0.743,explained_var_new:0.749
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:97, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02407,lr_multiplier:1.000,loss:1.8736275434494019,entropy:1.7360329627990723,explained_var_old:0.845,explained_var_new:0.852
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:98, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01985,lr_multiplier:1.000,loss:1.8816646337509155,entropy:1.7177157402038574,explained_var_old:0.807,explained_var_new:0.810
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:99, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01631,lr_multiplier:1.000,loss:1.8598122596740723,entropy:1.7498589754104614,explained_var_old:0.855,explained_var_new:0.858
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:100, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02035,lr_multiplier:1.000,loss:1.8400230407714844,entropy:1.6967873573303223,explained_var_old:0.837,explained_var_new:0.841
已经训练: 100轮
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 5, lose: 5, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:101, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01791,lr_multiplier:1.000,loss:1.945052146911621,entropy:1.7282861471176147,explained_var_old:0.798,explained_var_new:0.803
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:102, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02769,lr_multiplier:1.000,loss:1.913818120956421,entropy:1.7236239910125732,explained_var_old:0.776,explained_var_new:0.781
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:103, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02412,lr_multiplier:1.000,loss:1.870287299156189,entropy:1.7538684606552124,explained_var_old:0.842,explained_var_new:0.853
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:104, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01610,lr_multiplier:1.000,loss:1.8370108604431152,entropy:1.6829167604446411,explained_var_old:0.818,explained_var_new:0.821
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:105, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02199,lr_multiplier:1.000,loss:1.8437905311584473,entropy:1.7113828659057617,explained_var_old:0.859,explained_var_new:0.868
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:106, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01138,lr_multiplier:1.000,loss:1.8651652336120605,entropy:1.7117304801940918,explained_var_old:0.843,explained_var_new:0.846
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:107, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02047,lr_multiplier:1.000,loss:1.8834121227264404,entropy:1.722506046295166,explained_var_old:0.816,explained_var_new:0.826
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:108, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01643,lr_multiplier:1.000,loss:1.8230761289596558,entropy:1.6970244646072388,explained_var_old:0.856,explained_var_new:0.860
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:109, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02475,lr_multiplier:1.000,loss:1.8656506538391113,entropy:1.728219985961914,explained_var_old:0.827,explained_var_new:0.831
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:110, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03177,lr_multiplier:1.000,loss:1.796429991722107,entropy:1.6956686973571777,explained_var_old:0.845,explained_var_new:0.850
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:111, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01760,lr_multiplier:1.000,loss:1.8607999086380005,entropy:1.6989612579345703,explained_var_old:0.827,explained_var_new:0.835
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:112, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02124,lr_multiplier:1.000,loss:1.8211696147918701,entropy:1.69187593460083,explained_var_old:0.868,explained_var_new:0.878
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:113, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02134,lr_multiplier:1.000,loss:1.9139723777770996,entropy:1.7549691200256348,explained_var_old:0.811,explained_var_new:0.823
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:114, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01794,lr_multiplier:1.000,loss:1.843672752380371,entropy:1.7138099670410156,explained_var_old:0.857,explained_var_new:0.866
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:115, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01597,lr_multiplier:1.000,loss:1.7824300527572632,entropy:1.6499271392822266,explained_var_old:0.870,explained_var_new:0.877
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:116, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01795,lr_multiplier:1.000,loss:1.7681028842926025,entropy:1.6862359046936035,explained_var_old:0.907,explained_var_new:0.915
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:117, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01982,lr_multiplier:1.000,loss:1.8381413221359253,entropy:1.7102484703063965,explained_var_old:0.854,explained_var_new:0.858
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:118, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02305,lr_multiplier:1.000,loss:1.8071105480194092,entropy:1.6973044872283936,explained_var_old:0.845,explained_var_new:0.855
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:119, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01094,lr_multiplier:1.000,loss:1.7998161315917969,entropy:1.6745460033416748,explained_var_old:0.867,explained_var_new:0.878
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:120, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01771,lr_multiplier:1.000,loss:1.7407642602920532,entropy:1.618682622909546,explained_var_old:0.883,explained_var_new:0.886
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:121, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01796,lr_multiplier:1.000,loss:1.8650661706924438,entropy:1.7568376064300537,explained_var_old:0.850,explained_var_new:0.854
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:122, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01303,lr_multiplier:1.000,loss:1.7725908756256104,entropy:1.6701412200927734,explained_var_old:0.882,explained_var_new:0.884
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:123, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01093,lr_multiplier:1.000,loss:1.7653611898422241,entropy:1.6461514234542847,explained_var_old:0.884,explained_var_new:0.895
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:124, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01218,lr_multiplier:1.000,loss:1.7673218250274658,entropy:1.6410877704620361,explained_var_old:0.869,explained_var_new:0.876
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:125, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01090,lr_multiplier:1.000,loss:1.7880867719650269,entropy:1.6836035251617432,explained_var_old:0.877,explained_var_new:0.884
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:126, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01124,lr_multiplier:1.000,loss:1.7645615339279175,entropy:1.666050910949707,explained_var_old:0.891,explained_var_new:0.899
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:127, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.01269,lr_multiplier:1.000,loss:1.9149454832077026,entropy:1.7419464588165283,explained_var_old:0.800,explained_var_new:0.814
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:128, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01471,lr_multiplier:1.000,loss:1.8166731595993042,entropy:1.6711984872817993,explained_var_old:0.828,explained_var_new:0.842
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:129, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02029,lr_multiplier:1.000,loss:1.84324049949646,entropy:1.6785012483596802,explained_var_old:0.843,explained_var_new:0.863
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:130, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02547,lr_multiplier:1.000,loss:1.8768852949142456,entropy:1.7796685695648193,explained_var_old:0.856,explained_var_new:0.877
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:131, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01924,lr_multiplier:1.000,loss:1.814748764038086,entropy:1.7087396383285522,explained_var_old:0.819,explained_var_new:0.850
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:132, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01210,lr_multiplier:1.000,loss:1.863266944885254,entropy:1.6848481893539429,explained_var_old:0.784,explained_var_new:0.809
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:133, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01295,lr_multiplier:1.000,loss:1.8558932542800903,entropy:1.7133933305740356,explained_var_old:0.823,explained_var_new:0.852
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:134, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01902,lr_multiplier:1.000,loss:1.8604633808135986,entropy:1.7497344017028809,explained_var_old:0.846,explained_var_new:0.870
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:135, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01313,lr_multiplier:1.000,loss:1.826367735862732,entropy:1.6934137344360352,explained_var_old:0.848,explained_var_new:0.866
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:136, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02015,lr_multiplier:1.000,loss:1.8492740392684937,entropy:1.6963392496109009,explained_var_old:0.811,explained_var_new:0.872
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:137, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02235,lr_multiplier:1.000,loss:1.8958675861358643,entropy:1.7855626344680786,explained_var_old:0.842,explained_var_new:0.861
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:138, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01850,lr_multiplier:1.000,loss:1.89518141746521,entropy:1.7779033184051514,explained_var_old:0.832,explained_var_new:0.863
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:139, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01974,lr_multiplier:1.000,loss:1.8662546873092651,entropy:1.7375863790512085,explained_var_old:0.852,explained_var_new:0.876
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:140, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01808,lr_multiplier:1.000,loss:1.8890091180801392,entropy:1.7432606220245361,explained_var_old:0.810,explained_var_new:0.836
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:141, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02668,lr_multiplier:1.000,loss:1.8715476989746094,entropy:1.7826387882232666,explained_var_old:0.862,explained_var_new:0.884
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:142, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01812,lr_multiplier:1.000,loss:1.8637113571166992,entropy:1.70760977268219,explained_var_old:0.813,explained_var_new:0.844
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:143, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02090,lr_multiplier:1.000,loss:1.8821481466293335,entropy:1.7715940475463867,explained_var_old:0.872,explained_var_new:0.906
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:144, episode_len:10
TrainPipeline:run: 开始模型训练
kl:0.01765,lr_multiplier:1.000,loss:1.9192463159561157,entropy:1.831695556640625,explained_var_old:0.846,explained_var_new:0.869
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:145, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02536,lr_multiplier:1.000,loss:1.9427520036697388,entropy:1.7777734994888306,explained_var_old:0.789,explained_var_new:0.821
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:146, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02248,lr_multiplier:1.000,loss:1.800886631011963,entropy:1.6961674690246582,explained_var_old:0.874,explained_var_new:0.907
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:147, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02415,lr_multiplier:1.000,loss:1.857258677482605,entropy:1.703201413154602,explained_var_old:0.766,explained_var_new:0.827
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:148, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02151,lr_multiplier:1.000,loss:1.8780784606933594,entropy:1.758887529373169,explained_var_old:0.828,explained_var_new:0.861
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:149, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02331,lr_multiplier:1.000,loss:1.7904350757598877,entropy:1.671500325202942,explained_var_old:0.866,explained_var_new:0.892
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:150, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02383,lr_multiplier:1.000,loss:1.911725640296936,entropy:1.8229703903198242,explained_var_old:0.857,explained_var_new:0.883
已经训练: 150轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 3, lose: 7, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:151, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02570,lr_multiplier:1.000,loss:1.948604941368103,entropy:1.854650616645813,explained_var_old:0.857,explained_var_new:0.893
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:152, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01962,lr_multiplier:1.000,loss:1.9903032779693604,entropy:1.8409795761108398,explained_var_old:0.822,explained_var_new:0.849
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:153, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02273,lr_multiplier:1.000,loss:1.8249320983886719,entropy:1.7341639995574951,explained_var_old:0.839,explained_var_new:0.884
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:154, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02694,lr_multiplier:1.000,loss:1.9563837051391602,entropy:1.8185203075408936,explained_var_old:0.816,explained_var_new:0.857
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:155, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02325,lr_multiplier:1.000,loss:1.8977603912353516,entropy:1.80485200881958,explained_var_old:0.856,explained_var_new:0.890
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:156, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02003,lr_multiplier:1.000,loss:1.9275916814804077,entropy:1.8135805130004883,explained_var_old:0.860,explained_var_new:0.888
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:157, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02199,lr_multiplier:1.000,loss:1.9834060668945312,entropy:1.8653348684310913,explained_var_old:0.832,explained_var_new:0.859
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:158, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02777,lr_multiplier:1.000,loss:1.978864073753357,entropy:1.8538529872894287,explained_var_old:0.848,explained_var_new:0.891
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:159, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02788,lr_multiplier:1.000,loss:1.8552039861679077,entropy:1.7207074165344238,explained_var_old:0.812,explained_var_new:0.856
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:160, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02023,lr_multiplier:1.000,loss:1.9152648448944092,entropy:1.8699253797531128,explained_var_old:0.876,explained_var_new:0.905
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:161, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03103,lr_multiplier:1.000,loss:1.954813838005066,entropy:1.8319255113601685,explained_var_old:0.856,explained_var_new:0.882
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:162, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02127,lr_multiplier:1.000,loss:1.9473237991333008,entropy:1.8018332719802856,explained_var_old:0.838,explained_var_new:0.850
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:163, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02302,lr_multiplier:1.000,loss:1.9616000652313232,entropy:1.8242547512054443,explained_var_old:0.848,explained_var_new:0.887
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:164, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02198,lr_multiplier:1.000,loss:1.9468669891357422,entropy:1.874215841293335,explained_var_old:0.909,explained_var_new:0.927
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:165, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03699,lr_multiplier:1.000,loss:1.8958463668823242,entropy:1.830810785293579,explained_var_old:0.899,explained_var_new:0.930
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:166, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03456,lr_multiplier:1.000,loss:2.006466865539551,entropy:1.9063682556152344,explained_var_old:0.842,explained_var_new:0.881
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:167, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.03104,lr_multiplier:1.000,loss:1.914805293083191,entropy:1.87486732006073,explained_var_old:0.889,explained_var_new:0.921
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:168, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02528,lr_multiplier:1.000,loss:1.9385302066802979,entropy:1.823731780052185,explained_var_old:0.862,explained_var_new:0.881
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:169, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.03295,lr_multiplier:1.000,loss:1.9095308780670166,entropy:1.8487684726715088,explained_var_old:0.919,explained_var_new:0.929
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:170, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03103,lr_multiplier:1.000,loss:1.9384537935256958,entropy:1.8517919778823853,explained_var_old:0.875,explained_var_new:0.904
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:171, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02367,lr_multiplier:1.000,loss:2.0070409774780273,entropy:1.8868662118911743,explained_var_old:0.840,explained_var_new:0.871
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:172, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02740,lr_multiplier:1.000,loss:1.9799489974975586,entropy:1.8918414115905762,explained_var_old:0.848,explained_var_new:0.880
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:173, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03074,lr_multiplier:1.000,loss:1.999354600906372,entropy:1.910355806350708,explained_var_old:0.903,explained_var_new:0.917
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:174, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02112,lr_multiplier:1.000,loss:1.8986539840698242,entropy:1.768541932106018,explained_var_old:0.862,explained_var_new:0.871
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:175, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02873,lr_multiplier:1.000,loss:1.9545366764068604,entropy:1.770937204360962,explained_var_old:0.809,explained_var_new:0.822
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:176, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02839,lr_multiplier:1.000,loss:1.9665744304656982,entropy:1.8399865627288818,explained_var_old:0.844,explained_var_new:0.858
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:177, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02654,lr_multiplier:1.000,loss:1.9050146341323853,entropy:1.82268488407135,explained_var_old:0.879,explained_var_new:0.903
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:178, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02488,lr_multiplier:1.000,loss:1.9410943984985352,entropy:1.8645031452178955,explained_var_old:0.899,explained_var_new:0.912
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:179, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02361,lr_multiplier:1.000,loss:1.898247480392456,entropy:1.7689803838729858,explained_var_old:0.868,explained_var_new:0.883
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:180, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01816,lr_multiplier:1.000,loss:1.881596326828003,entropy:1.8798027038574219,explained_var_old:0.941,explained_var_new:0.951
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:181, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.01821,lr_multiplier:1.000,loss:2.0384249687194824,entropy:1.9476115703582764,explained_var_old:0.872,explained_var_new:0.880
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:182, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01984,lr_multiplier:1.000,loss:1.9863271713256836,entropy:1.8563299179077148,explained_var_old:0.862,explained_var_new:0.882
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:183, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01837,lr_multiplier:1.000,loss:2.062544822692871,entropy:1.8838709592819214,explained_var_old:0.784,explained_var_new:0.816
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:184, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03183,lr_multiplier:1.000,loss:2.0110836029052734,entropy:1.8801414966583252,explained_var_old:0.811,explained_var_new:0.837
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:185, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02420,lr_multiplier:1.000,loss:1.9941154718399048,entropy:1.8500949144363403,explained_var_old:0.822,explained_var_new:0.844
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:186, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02601,lr_multiplier:1.000,loss:2.0690479278564453,entropy:1.8606094121932983,explained_var_old:0.752,explained_var_new:0.789
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:187, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02997,lr_multiplier:1.000,loss:1.9614280462265015,entropy:1.804085612297058,explained_var_old:0.790,explained_var_new:0.824
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:188, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02761,lr_multiplier:1.000,loss:2.0250790119171143,entropy:1.8784663677215576,explained_var_old:0.827,explained_var_new:0.855
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:189, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02458,lr_multiplier:1.000,loss:2.052626132965088,entropy:1.9030709266662598,explained_var_old:0.771,explained_var_new:0.833
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:190, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03601,lr_multiplier:1.000,loss:1.9961357116699219,entropy:1.8778774738311768,explained_var_old:0.817,explained_var_new:0.858
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:191, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02579,lr_multiplier:1.000,loss:1.930071234703064,entropy:1.8708782196044922,explained_var_old:0.879,explained_var_new:0.911
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:192, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03046,lr_multiplier:1.000,loss:1.9859753847122192,entropy:1.9216046333312988,explained_var_old:0.886,explained_var_new:0.903
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:193, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02552,lr_multiplier:1.000,loss:1.9680848121643066,entropy:1.8737140893936157,explained_var_old:0.879,explained_var_new:0.895
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:194, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02338,lr_multiplier:1.000,loss:1.9324665069580078,entropy:1.84627366065979,explained_var_old:0.910,explained_var_new:0.921
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:195, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02298,lr_multiplier:1.000,loss:1.9055639505386353,entropy:1.8163853883743286,explained_var_old:0.889,explained_var_new:0.900
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:196, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02286,lr_multiplier:1.000,loss:2.02789306640625,entropy:1.9213638305664062,explained_var_old:0.867,explained_var_new:0.885
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:197, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02361,lr_multiplier:1.000,loss:1.9617326259613037,entropy:1.9144219160079956,explained_var_old:0.897,explained_var_new:0.927
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:198, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01996,lr_multiplier:1.000,loss:1.9050967693328857,entropy:1.821736216545105,explained_var_old:0.920,explained_var_new:0.935
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:199, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01512,lr_multiplier:1.000,loss:1.9608644247055054,entropy:1.8503003120422363,explained_var_old:0.861,explained_var_new:0.887
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:200, episode_len:10
TrainPipeline:run: 开始模型训练
kl:0.02259,lr_multiplier:1.000,loss:2.0602974891662598,entropy:1.9510152339935303,explained_var_old:0.863,explained_var_new:0.873
已经训练: 200轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 5, lose: 5, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:201, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02585,lr_multiplier:1.000,loss:2.0419089794158936,entropy:1.9013465642929077,explained_var_old:0.827,explained_var_new:0.840
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:202, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02112,lr_multiplier:1.000,loss:1.9520753622055054,entropy:1.8471171855926514,explained_var_old:0.846,explained_var_new:0.876
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:203, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02522,lr_multiplier:1.000,loss:1.8807451725006104,entropy:1.8413052558898926,explained_var_old:0.908,explained_var_new:0.927
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:204, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02434,lr_multiplier:1.000,loss:2.011707305908203,entropy:1.8749656677246094,explained_var_old:0.844,explained_var_new:0.852
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:205, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.02874,lr_multiplier:1.000,loss:2.0454673767089844,entropy:1.865682601928711,explained_var_old:0.776,explained_var_new:0.825
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:206, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03123,lr_multiplier:1.000,loss:2.107203245162964,entropy:1.957393765449524,explained_var_old:0.756,explained_var_new:0.799
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:207, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02621,lr_multiplier:1.000,loss:2.0482869148254395,entropy:1.9022340774536133,explained_var_old:0.813,explained_var_new:0.833
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:208, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.04579,lr_multiplier:0.667,loss:2.131133794784546,entropy:1.9268605709075928,explained_var_old:0.792,explained_var_new:0.844
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:209, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02058,lr_multiplier:0.667,loss:2.049217462539673,entropy:1.9256439208984375,explained_var_old:0.816,explained_var_new:0.858
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:210, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02566,lr_multiplier:0.667,loss:2.180852174758911,entropy:1.9643769264221191,explained_var_old:0.691,explained_var_new:0.752
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:211, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02627,lr_multiplier:0.667,loss:2.232722759246826,entropy:1.9718217849731445,explained_var_old:0.687,explained_var_new:0.727
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:212, episode_len:10
TrainPipeline:run: 开始模型训练
kl:0.03275,lr_multiplier:0.667,loss:2.231811046600342,entropy:1.9282822608947754,explained_var_old:0.694,explained_var_new:0.728
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:213, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01980,lr_multiplier:0.667,loss:2.1082663536071777,entropy:1.9007757902145386,explained_var_old:0.688,explained_var_new:0.743
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:214, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02824,lr_multiplier:0.667,loss:2.187039852142334,entropy:2.015805244445801,explained_var_old:0.748,explained_var_new:0.790
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:215, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.03662,lr_multiplier:0.667,loss:2.2077858448028564,entropy:1.8790007829666138,explained_var_old:0.645,explained_var_new:0.713
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:216, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.03338,lr_multiplier:0.667,loss:2.129554271697998,entropy:1.9180171489715576,explained_var_old:0.679,explained_var_new:0.747
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:217, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.02858,lr_multiplier:0.667,loss:2.264949083328247,entropy:2.0653982162475586,explained_var_old:0.742,explained_var_new:0.783
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:218, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02068,lr_multiplier:0.667,loss:2.2026939392089844,entropy:1.9627703428268433,explained_var_old:0.722,explained_var_new:0.778
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:219, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02766,lr_multiplier:0.667,loss:2.2281100749969482,entropy:2.0369980335235596,explained_var_old:0.730,explained_var_new:0.772
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:220, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.03128,lr_multiplier:0.667,loss:2.380427122116089,entropy:1.9897525310516357,explained_var_old:0.599,explained_var_new:0.643
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:221, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02475,lr_multiplier:0.667,loss:2.3932149410247803,entropy:2.079740047454834,explained_var_old:0.617,explained_var_new:0.658
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:222, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02129,lr_multiplier:0.667,loss:2.3291361331939697,entropy:1.992377519607544,explained_var_old:0.634,explained_var_new:0.681
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:223, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02344,lr_multiplier:0.667,loss:2.346595287322998,entropy:2.0306177139282227,explained_var_old:0.560,explained_var_new:0.631
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:224, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01940,lr_multiplier:0.667,loss:2.3844680786132812,entropy:2.04109263420105,explained_var_old:0.618,explained_var_new:0.681
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:225, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02721,lr_multiplier:0.667,loss:2.454716205596924,entropy:2.1492066383361816,explained_var_old:0.605,explained_var_new:0.669
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:226, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.04552,lr_multiplier:0.444,loss:2.3308613300323486,entropy:2.0543394088745117,explained_var_old:0.699,explained_var_new:0.749
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:227, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03003,lr_multiplier:0.444,loss:2.512612819671631,entropy:2.2123165130615234,explained_var_old:0.605,explained_var_new:0.654
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:228, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.04899,lr_multiplier:0.296,loss:2.5422520637512207,entropy:2.165201187133789,explained_var_old:0.622,explained_var_new:0.704
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:229, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.03087,lr_multiplier:0.296,loss:2.5764758586883545,entropy:2.2101216316223145,explained_var_old:0.586,explained_var_new:0.634
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:230, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01801,lr_multiplier:0.296,loss:2.4374778270721436,entropy:2.160696506500244,explained_var_old:0.599,explained_var_new:0.658
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:231, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01701,lr_multiplier:0.296,loss:2.6289727687835693,entropy:2.2022011280059814,explained_var_old:0.588,explained_var_new:0.617
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:232, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01158,lr_multiplier:0.296,loss:2.4658234119415283,entropy:2.2114338874816895,explained_var_old:0.695,explained_var_new:0.722
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:233, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00887,lr_multiplier:0.444,loss:2.454623222351074,entropy:2.1612744331359863,explained_var_old:0.671,explained_var_new:0.694
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:234, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01579,lr_multiplier:0.444,loss:2.650942802429199,entropy:2.218320846557617,explained_var_old:0.529,explained_var_new:0.572
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:235, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01723,lr_multiplier:0.444,loss:2.4972105026245117,entropy:2.2118172645568848,explained_var_old:0.651,explained_var_new:0.687
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:236, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01478,lr_multiplier:0.444,loss:2.5501928329467773,entropy:2.1969361305236816,explained_var_old:0.634,explained_var_new:0.657
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:237, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01488,lr_multiplier:0.444,loss:2.500718593597412,entropy:2.1640231609344482,explained_var_old:0.611,explained_var_new:0.645
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:238, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01838,lr_multiplier:0.444,loss:2.5056729316711426,entropy:2.1937172412872314,explained_var_old:0.666,explained_var_new:0.699
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:239, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01099,lr_multiplier:0.444,loss:2.5243589878082275,entropy:2.2436838150024414,explained_var_old:0.645,explained_var_new:0.696
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:240, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02752,lr_multiplier:0.444,loss:2.4784204959869385,entropy:2.229189872741699,explained_var_old:0.623,explained_var_new:0.683
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:241, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02753,lr_multiplier:0.444,loss:2.505681037902832,entropy:2.1544880867004395,explained_var_old:0.634,explained_var_new:0.685
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:242, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01934,lr_multiplier:0.444,loss:2.443876028060913,entropy:2.1567459106445312,explained_var_old:0.630,explained_var_new:0.673
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:243, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01236,lr_multiplier:0.444,loss:2.4213318824768066,entropy:2.154013156890869,explained_var_old:0.696,explained_var_new:0.725
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:244, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.02171,lr_multiplier:0.444,loss:2.5302159786224365,entropy:2.1776349544525146,explained_var_old:0.630,explained_var_new:0.670
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:245, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02411,lr_multiplier:0.444,loss:2.644002676010132,entropy:2.2321667671203613,explained_var_old:0.552,explained_var_new:0.574
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:246, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02053,lr_multiplier:0.444,loss:2.492158889770508,entropy:2.172807455062866,explained_var_old:0.652,explained_var_new:0.693
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:247, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02704,lr_multiplier:0.444,loss:2.486273765563965,entropy:2.191061019897461,explained_var_old:0.656,explained_var_new:0.692
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:248, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01813,lr_multiplier:0.444,loss:2.466254711151123,entropy:2.226417064666748,explained_var_old:0.704,explained_var_new:0.737
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:249, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02462,lr_multiplier:0.444,loss:2.486259698867798,entropy:2.2326231002807617,explained_var_old:0.649,explained_var_new:0.701
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:250, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.02581,lr_multiplier:0.444,loss:2.519138813018799,entropy:2.169689655303955,explained_var_old:0.636,explained_var_new:0.669
已经训练: 250轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
num_playouts:1000, win: 7, lose: 3, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:251, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.02677,lr_multiplier:0.444,loss:2.569053888320923,entropy:2.204946517944336,explained_var_old:0.625,explained_var_new:0.680
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:252, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03639,lr_multiplier:0.444,loss:2.5924458503723145,entropy:2.2774558067321777,explained_var_old:0.592,explained_var_new:0.645
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:253, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02981,lr_multiplier:0.444,loss:2.4906840324401855,entropy:2.2191853523254395,explained_var_old:0.677,explained_var_new:0.724
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:254, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03825,lr_multiplier:0.444,loss:2.649595022201538,entropy:2.3174638748168945,explained_var_old:0.550,explained_var_new:0.612
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:255, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.04167,lr_multiplier:0.296,loss:2.596951484680176,entropy:2.2308521270751953,explained_var_old:0.654,explained_var_new:0.686
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:256, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01642,lr_multiplier:0.296,loss:2.6104543209075928,entropy:2.314516544342041,explained_var_old:0.651,explained_var_new:0.672
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:257, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02058,lr_multiplier:0.296,loss:2.5068933963775635,entropy:2.3153347969055176,explained_var_old:0.746,explained_var_new:0.766
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:258, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.02370,lr_multiplier:0.296,loss:2.6876301765441895,entropy:2.3047120571136475,explained_var_old:0.593,explained_var_new:0.638
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:259, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01514,lr_multiplier:0.296,loss:2.581209421157837,entropy:2.273179531097412,explained_var_old:0.620,explained_var_new:0.646
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:260, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.01198,lr_multiplier:0.296,loss:2.685826301574707,entropy:2.278021812438965,explained_var_old:0.544,explained_var_new:0.578
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:261, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.00895,lr_multiplier:0.444,loss:2.6621193885803223,entropy:2.186203956604004,explained_var_old:0.487,explained_var_new:0.551
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:262, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02599,lr_multiplier:0.444,loss:2.7049388885498047,entropy:2.3290605545043945,explained_var_old:0.523,explained_var_new:0.569
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:263, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02076,lr_multiplier:0.444,loss:2.591106653213501,entropy:2.249208688735962,explained_var_old:0.604,explained_var_new:0.656
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:264, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01621,lr_multiplier:0.444,loss:2.7391819953918457,entropy:2.3104867935180664,explained_var_old:0.525,explained_var_new:0.565
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:265, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01901,lr_multiplier:0.444,loss:2.7201626300811768,entropy:2.319303274154663,explained_var_old:0.565,explained_var_new:0.622
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:266, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02212,lr_multiplier:0.444,loss:2.7738113403320312,entropy:2.348294258117676,explained_var_old:0.568,explained_var_new:0.604
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:267, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02366,lr_multiplier:0.444,loss:2.7238478660583496,entropy:2.3363966941833496,explained_var_old:0.527,explained_var_new:0.585
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:268, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03929,lr_multiplier:0.444,loss:2.7261030673980713,entropy:2.300387382507324,explained_var_old:0.489,explained_var_new:0.570
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:269, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02716,lr_multiplier:0.444,loss:2.7423081398010254,entropy:2.3121039867401123,explained_var_old:0.524,explained_var_new:0.583
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:270, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02555,lr_multiplier:0.444,loss:2.7455785274505615,entropy:2.4078481197357178,explained_var_old:0.578,explained_var_new:0.640
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:271, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.02854,lr_multiplier:0.444,loss:2.6596453189849854,entropy:2.323979377746582,explained_var_old:0.590,explained_var_new:0.645
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:272, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03522,lr_multiplier:0.444,loss:2.820650815963745,entropy:2.397947311401367,explained_var_old:0.506,explained_var_new:0.555
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:273, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02483,lr_multiplier:0.444,loss:2.7920725345611572,entropy:2.3418996334075928,explained_var_old:0.469,explained_var_new:0.550
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:274, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03504,lr_multiplier:0.444,loss:2.7289326190948486,entropy:2.332059621810913,explained_var_old:0.578,explained_var_new:0.623
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:275, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02927,lr_multiplier:0.444,loss:2.8173274993896484,entropy:2.367435932159424,explained_var_old:0.513,explained_var_new:0.558
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:276, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02337,lr_multiplier:0.444,loss:2.806630849838257,entropy:2.438589096069336,explained_var_old:0.558,explained_var_new:0.591
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:277, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.03790,lr_multiplier:0.444,loss:2.75638484954834,entropy:2.3551783561706543,explained_var_old:0.598,explained_var_new:0.634
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:278, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.04610,lr_multiplier:0.296,loss:2.9291110038757324,entropy:2.4456026554107666,explained_var_old:0.426,explained_var_new:0.486
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:279, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01590,lr_multiplier:0.296,loss:2.911757230758667,entropy:2.4160306453704834,explained_var_old:0.478,explained_var_new:0.500
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:280, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01514,lr_multiplier:0.296,loss:2.846625328063965,entropy:2.418893575668335,explained_var_old:0.467,explained_var_new:0.504
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:281, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01794,lr_multiplier:0.296,loss:2.8369758129119873,entropy:2.370999813079834,explained_var_old:0.530,explained_var_new:0.561
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:282, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02618,lr_multiplier:0.296,loss:2.9933204650878906,entropy:2.5126240253448486,explained_var_old:0.455,explained_var_new:0.493
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:283, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.03092,lr_multiplier:0.296,loss:2.917442798614502,entropy:2.3754074573516846,explained_var_old:0.446,explained_var_new:0.490
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:284, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03439,lr_multiplier:0.296,loss:3.004375696182251,entropy:2.4788200855255127,explained_var_old:0.363,explained_var_new:0.410
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:285, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02797,lr_multiplier:0.296,loss:3.0605971813201904,entropy:2.4532642364501953,explained_var_old:0.366,explained_var_new:0.425
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:286, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01672,lr_multiplier:0.296,loss:2.9256081581115723,entropy:2.435734272003174,explained_var_old:0.434,explained_var_new:0.474
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:287, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01182,lr_multiplier:0.296,loss:2.932888984680176,entropy:2.4018940925598145,explained_var_old:0.416,explained_var_new:0.445
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:288, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01875,lr_multiplier:0.296,loss:2.8059961795806885,entropy:2.3578991889953613,explained_var_old:0.509,explained_var_new:0.543
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:289, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01733,lr_multiplier:0.296,loss:2.8273367881774902,entropy:2.3746659755706787,explained_var_old:0.522,explained_var_new:0.549
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:290, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01795,lr_multiplier:0.296,loss:2.878194570541382,entropy:2.3615472316741943,explained_var_old:0.462,explained_var_new:0.501
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:291, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02146,lr_multiplier:0.296,loss:2.8439862728118896,entropy:2.4140071868896484,explained_var_old:0.517,explained_var_new:0.558
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:292, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01374,lr_multiplier:0.296,loss:2.8987889289855957,entropy:2.378164768218994,explained_var_old:0.462,explained_var_new:0.492
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:293, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01731,lr_multiplier:0.296,loss:2.949679374694824,entropy:2.4363396167755127,explained_var_old:0.422,explained_var_new:0.448
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:294, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01765,lr_multiplier:0.296,loss:2.730170965194702,entropy:2.3311469554901123,explained_var_old:0.583,explained_var_new:0.619
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:295, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02113,lr_multiplier:0.296,loss:2.8063771724700928,entropy:2.387246608734131,explained_var_old:0.516,explained_var_new:0.529
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:296, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01698,lr_multiplier:0.296,loss:2.787830114364624,entropy:2.3514089584350586,explained_var_old:0.566,explained_var_new:0.598
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:297, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01560,lr_multiplier:0.296,loss:2.693470001220703,entropy:2.356975555419922,explained_var_old:0.657,explained_var_new:0.672
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:298, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01892,lr_multiplier:0.296,loss:2.707075357437134,entropy:2.431973934173584,explained_var_old:0.629,explained_var_new:0.661
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:299, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01661,lr_multiplier:0.296,loss:2.8110272884368896,entropy:2.398552179336548,explained_var_old:0.551,explained_var_new:0.580
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:300, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01771,lr_multiplier:0.296,loss:2.7715871334075928,entropy:2.33945369720459,explained_var_old:0.559,explained_var_new:0.589
已经训练: 300轮
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
num_playouts:1000, win: 5, lose: 5, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:301, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01415,lr_multiplier:0.296,loss:2.8364510536193848,entropy:2.337967872619629,explained_var_old:0.441,explained_var_new:0.494
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:302, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01519,lr_multiplier:0.296,loss:2.6534416675567627,entropy:2.2891287803649902,explained_var_old:0.577,explained_var_new:0.611
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:303, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01540,lr_multiplier:0.296,loss:2.776120662689209,entropy:2.356343984603882,explained_var_old:0.528,explained_var_new:0.554
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:304, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01630,lr_multiplier:0.296,loss:2.6979799270629883,entropy:2.343876361846924,explained_var_old:0.599,explained_var_new:0.632
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:305, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01944,lr_multiplier:0.296,loss:2.7014312744140625,entropy:2.2877323627471924,explained_var_old:0.587,explained_var_new:0.616
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:306, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01448,lr_multiplier:0.296,loss:2.683734655380249,entropy:2.381892681121826,explained_var_old:0.588,explained_var_new:0.623
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:307, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01714,lr_multiplier:0.296,loss:2.6784098148345947,entropy:2.278489589691162,explained_var_old:0.608,explained_var_new:0.637
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:308, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02616,lr_multiplier:0.296,loss:2.7281014919281006,entropy:2.339982271194458,explained_var_old:0.536,explained_var_new:0.557
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:309, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03055,lr_multiplier:0.296,loss:2.673839807510376,entropy:2.2028398513793945,explained_var_old:0.574,explained_var_new:0.591
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:310, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03419,lr_multiplier:0.296,loss:2.7028439044952393,entropy:2.3759400844573975,explained_var_old:0.556,explained_var_new:0.591
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:311, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02748,lr_multiplier:0.296,loss:2.7026023864746094,entropy:2.263185501098633,explained_var_old:0.611,explained_var_new:0.628
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:312, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01867,lr_multiplier:0.296,loss:2.564293622970581,entropy:2.266430616378784,explained_var_old:0.615,explained_var_new:0.648
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:313, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01745,lr_multiplier:0.296,loss:2.6610000133514404,entropy:2.2538881301879883,explained_var_old:0.579,explained_var_new:0.611
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:314, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01517,lr_multiplier:0.296,loss:2.693490982055664,entropy:2.318150520324707,explained_var_old:0.563,explained_var_new:0.588
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:315, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01797,lr_multiplier:0.296,loss:2.667789936065674,entropy:2.2348339557647705,explained_var_old:0.559,explained_var_new:0.594
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:316, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01429,lr_multiplier:0.296,loss:2.5331835746765137,entropy:2.2600159645080566,explained_var_old:0.678,explained_var_new:0.713
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:317, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01485,lr_multiplier:0.296,loss:2.5833096504211426,entropy:2.2470500469207764,explained_var_old:0.616,explained_var_new:0.636
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:318, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01564,lr_multiplier:0.296,loss:2.63921856880188,entropy:2.2310824394226074,explained_var_old:0.573,explained_var_new:0.601
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:319, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01883,lr_multiplier:0.296,loss:2.598144769668579,entropy:2.232180595397949,explained_var_old:0.597,explained_var_new:0.631
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:320, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01187,lr_multiplier:0.296,loss:2.5588624477386475,entropy:2.225231170654297,explained_var_old:0.633,explained_var_new:0.659
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:321, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01191,lr_multiplier:0.296,loss:2.6227762699127197,entropy:2.2823615074157715,explained_var_old:0.609,explained_var_new:0.628
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:322, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01556,lr_multiplier:0.296,loss:2.6265361309051514,entropy:2.259918212890625,explained_var_old:0.608,explained_var_new:0.641
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:323, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01424,lr_multiplier:0.296,loss:2.5424234867095947,entropy:2.191335916519165,explained_var_old:0.609,explained_var_new:0.637
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:324, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01741,lr_multiplier:0.296,loss:2.500576972961426,entropy:2.2057058811187744,explained_var_old:0.640,explained_var_new:0.676
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:325, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01731,lr_multiplier:0.296,loss:2.5198822021484375,entropy:2.158782482147217,explained_var_old:0.611,explained_var_new:0.630
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:326, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01480,lr_multiplier:0.296,loss:2.535545587539673,entropy:2.247987985610962,explained_var_old:0.633,explained_var_new:0.660
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:327, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00958,lr_multiplier:0.444,loss:2.4487409591674805,entropy:2.1747148036956787,explained_var_old:0.684,explained_var_new:0.712
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:328, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01949,lr_multiplier:0.444,loss:2.5363612174987793,entropy:2.1610448360443115,explained_var_old:0.603,explained_var_new:0.633
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:329, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02909,lr_multiplier:0.444,loss:2.4500925540924072,entropy:2.191218376159668,explained_var_old:0.690,explained_var_new:0.746
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:330, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02137,lr_multiplier:0.444,loss:2.459592342376709,entropy:2.191333770751953,explained_var_old:0.678,explained_var_new:0.708
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:331, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02414,lr_multiplier:0.444,loss:2.418341636657715,entropy:2.113600015640259,explained_var_old:0.675,explained_var_new:0.706
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:332, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01572,lr_multiplier:0.444,loss:2.3881561756134033,entropy:2.136029005050659,explained_var_old:0.722,explained_var_new:0.760
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:333, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01917,lr_multiplier:0.444,loss:2.503607749938965,entropy:2.22404408454895,explained_var_old:0.668,explained_var_new:0.700
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:334, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01632,lr_multiplier:0.444,loss:2.46388578414917,entropy:2.1884679794311523,explained_var_old:0.659,explained_var_new:0.698
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:335, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02018,lr_multiplier:0.444,loss:2.420095920562744,entropy:2.1365628242492676,explained_var_old:0.687,explained_var_new:0.714
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:336, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02876,lr_multiplier:0.444,loss:2.443240165710449,entropy:2.1527013778686523,explained_var_old:0.654,explained_var_new:0.688
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:337, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02547,lr_multiplier:0.444,loss:2.3803467750549316,entropy:2.1207265853881836,explained_var_old:0.686,explained_var_new:0.719
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:338, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02415,lr_multiplier:0.444,loss:2.3381755352020264,entropy:2.067396879196167,explained_var_old:0.716,explained_var_new:0.751
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:339, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02821,lr_multiplier:0.444,loss:2.3214895725250244,entropy:2.1020755767822266,explained_var_old:0.719,explained_var_new:0.751
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:340, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02653,lr_multiplier:0.444,loss:2.2662248611450195,entropy:2.0206384658813477,explained_var_old:0.751,explained_var_new:0.777
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:341, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02757,lr_multiplier:0.444,loss:2.3906331062316895,entropy:2.126716375350952,explained_var_old:0.709,explained_var_new:0.750
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:342, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02432,lr_multiplier:0.444,loss:2.323552370071411,entropy:2.152292490005493,explained_var_old:0.757,explained_var_new:0.783
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:343, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02781,lr_multiplier:0.444,loss:2.338020086288452,entropy:2.064263343811035,explained_var_old:0.694,explained_var_new:0.745
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:344, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02664,lr_multiplier:0.444,loss:2.352471113204956,entropy:2.148136615753174,explained_var_old:0.742,explained_var_new:0.787
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:345, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02854,lr_multiplier:0.444,loss:2.2848455905914307,entropy:2.079235076904297,explained_var_old:0.758,explained_var_new:0.802
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:346, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01263,lr_multiplier:0.444,loss:2.2582268714904785,entropy:2.0821821689605713,explained_var_old:0.785,explained_var_new:0.806
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:347, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02550,lr_multiplier:0.444,loss:2.2817721366882324,entropy:2.052502393722534,explained_var_old:0.734,explained_var_new:0.760
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:348, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02788,lr_multiplier:0.444,loss:2.2871146202087402,entropy:2.0760574340820312,explained_var_old:0.735,explained_var_new:0.775
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:349, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03110,lr_multiplier:0.444,loss:2.2301578521728516,entropy:2.1091716289520264,explained_var_old:0.857,explained_var_new:0.898
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:350, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02145,lr_multiplier:0.444,loss:2.230546236038208,entropy:2.0891079902648926,explained_var_old:0.782,explained_var_new:0.799
已经训练: 350轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 9, lose: 1, tie:0
相较于MCTS@1000, 截至目前的最佳胜率=0.9 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:351, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01929,lr_multiplier:0.444,loss:2.1678454875946045,entropy:2.002401828765869,explained_var_old:0.844,explained_var_new:0.860
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:352, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01686,lr_multiplier:0.444,loss:2.139620065689087,entropy:2.0290350914001465,explained_var_old:0.841,explained_var_new:0.863
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:353, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01295,lr_multiplier:0.444,loss:2.246438980102539,entropy:2.0470046997070312,explained_var_old:0.798,explained_var_new:0.823
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:354, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01467,lr_multiplier:0.444,loss:2.2151522636413574,entropy:2.0422205924987793,explained_var_old:0.766,explained_var_new:0.791
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:355, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01481,lr_multiplier:0.444,loss:2.211014747619629,entropy:2.0437405109405518,explained_var_old:0.829,explained_var_new:0.844
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:356, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02195,lr_multiplier:0.444,loss:2.1494832038879395,entropy:2.0094282627105713,explained_var_old:0.824,explained_var_new:0.841
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:357, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01727,lr_multiplier:0.444,loss:2.175854206085205,entropy:2.0455892086029053,explained_var_old:0.835,explained_var_new:0.854
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:358, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02334,lr_multiplier:0.444,loss:2.204904079437256,entropy:2.0079243183135986,explained_var_old:0.786,explained_var_new:0.806
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:359, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01756,lr_multiplier:0.444,loss:2.1045291423797607,entropy:1.9440374374389648,explained_var_old:0.847,explained_var_new:0.859
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:360, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02417,lr_multiplier:0.444,loss:2.2715377807617188,entropy:2.1446313858032227,explained_var_old:0.825,explained_var_new:0.834
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:361, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01590,lr_multiplier:0.444,loss:2.1823325157165527,entropy:2.044097661972046,explained_var_old:0.825,explained_var_new:0.846
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:362, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01862,lr_multiplier:0.444,loss:2.137633800506592,entropy:1.9871132373809814,explained_var_old:0.817,explained_var_new:0.844
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:363, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01284,lr_multiplier:0.444,loss:2.0521183013916016,entropy:1.9617352485656738,explained_var_old:0.876,explained_var_new:0.889
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:364, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01718,lr_multiplier:0.444,loss:2.1458113193511963,entropy:2.0040578842163086,explained_var_old:0.838,explained_var_new:0.864
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:365, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01076,lr_multiplier:0.444,loss:2.1375679969787598,entropy:1.9760410785675049,explained_var_old:0.822,explained_var_new:0.834
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:366, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01171,lr_multiplier:0.444,loss:2.1632752418518066,entropy:2.0590696334838867,explained_var_old:0.847,explained_var_new:0.866
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:367, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02012,lr_multiplier:0.444,loss:2.1064720153808594,entropy:1.995615005493164,explained_var_old:0.869,explained_var_new:0.883
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:368, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01332,lr_multiplier:0.444,loss:2.1014201641082764,entropy:2.053562879562378,explained_var_old:0.886,explained_var_new:0.903
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:369, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01618,lr_multiplier:0.444,loss:2.0599396228790283,entropy:1.9633655548095703,explained_var_old:0.913,explained_var_new:0.930
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:370, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01526,lr_multiplier:0.444,loss:2.082329750061035,entropy:1.9482394456863403,explained_var_old:0.860,explained_var_new:0.873
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:371, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01428,lr_multiplier:0.444,loss:1.9768816232681274,entropy:1.921921730041504,explained_var_old:0.923,explained_var_new:0.930
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:372, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01447,lr_multiplier:0.444,loss:1.9583064317703247,entropy:1.8633370399475098,explained_var_old:0.911,explained_var_new:0.924
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:373, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01846,lr_multiplier:0.444,loss:2.044055938720703,entropy:1.9984230995178223,explained_var_old:0.902,explained_var_new:0.910
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:374, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02555,lr_multiplier:0.444,loss:1.923898458480835,entropy:1.858629822731018,explained_var_old:0.959,explained_var_new:0.970
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:375, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01665,lr_multiplier:0.444,loss:1.9565989971160889,entropy:1.9556392431259155,explained_var_old:0.973,explained_var_new:0.977
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:376, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01204,lr_multiplier:0.444,loss:1.9027124643325806,entropy:1.898636817932129,explained_var_old:0.972,explained_var_new:0.976
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:377, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01705,lr_multiplier:0.444,loss:1.8945844173431396,entropy:1.8862042427062988,explained_var_old:0.993,explained_var_new:0.999
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:378, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01538,lr_multiplier:0.444,loss:1.8876142501831055,entropy:1.8772176504135132,explained_var_old:0.991,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:379, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01078,lr_multiplier:0.444,loss:1.875027060508728,entropy:1.9092888832092285,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:380, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01571,lr_multiplier:0.444,loss:1.8469431400299072,entropy:1.8410438299179077,explained_var_old:0.999,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:381, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02216,lr_multiplier:0.444,loss:1.8570051193237305,entropy:1.8929194211959839,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:382, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01815,lr_multiplier:0.444,loss:1.8220500946044922,entropy:1.8218464851379395,explained_var_old:0.998,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:383, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01116,lr_multiplier:0.444,loss:1.9118479490280151,entropy:1.8870567083358765,explained_var_old:0.994,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:384, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01361,lr_multiplier:0.444,loss:1.8968875408172607,entropy:1.9280470609664917,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:385, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01174,lr_multiplier:0.444,loss:1.8964723348617554,entropy:1.901628017425537,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:386, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01258,lr_multiplier:0.444,loss:1.9371256828308105,entropy:1.9423854351043701,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:387, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01130,lr_multiplier:0.444,loss:1.887885332107544,entropy:1.9132018089294434,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:388, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01108,lr_multiplier:0.444,loss:1.8185625076293945,entropy:1.8004450798034668,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:389, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01110,lr_multiplier:0.444,loss:1.8145051002502441,entropy:1.8487685918807983,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:390, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01375,lr_multiplier:0.444,loss:1.8516771793365479,entropy:1.8436694145202637,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:391, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01418,lr_multiplier:0.444,loss:1.8882378339767456,entropy:1.883825421333313,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:392, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01129,lr_multiplier:0.444,loss:1.8314170837402344,entropy:1.8535737991333008,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:393, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00926,lr_multiplier:0.667,loss:1.8699616193771362,entropy:1.88767409324646,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:394, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01136,lr_multiplier:0.667,loss:1.8461843729019165,entropy:1.843686819076538,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:395, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00918,lr_multiplier:1.000,loss:1.8826442956924438,entropy:1.8831193447113037,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:396, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01875,lr_multiplier:1.000,loss:1.8235350847244263,entropy:1.829345464706421,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:397, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01425,lr_multiplier:1.000,loss:1.8596198558807373,entropy:1.88510000705719,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:398, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01674,lr_multiplier:1.000,loss:1.8004775047302246,entropy:1.8130779266357422,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:399, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01675,lr_multiplier:1.000,loss:1.7978692054748535,entropy:1.79233980178833,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:400, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01910,lr_multiplier:1.000,loss:1.7835584878921509,entropy:1.7797170877456665,explained_var_old:1.000,explained_var_new:1.000
已经训练: 400轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 7, lose: 3, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:401, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02313,lr_multiplier:1.000,loss:1.80363130569458,entropy:1.8268896341323853,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:402, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02131,lr_multiplier:1.000,loss:1.783210277557373,entropy:1.7660366296768188,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:403, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02657,lr_multiplier:1.000,loss:1.7684612274169922,entropy:1.784580111503601,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:404, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02055,lr_multiplier:1.000,loss:1.8127039670944214,entropy:1.8111473321914673,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:405, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01822,lr_multiplier:1.000,loss:1.8450257778167725,entropy:1.8638465404510498,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:406, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02182,lr_multiplier:1.000,loss:1.8061941862106323,entropy:1.8162271976470947,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:407, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01734,lr_multiplier:1.000,loss:1.848447561264038,entropy:1.8431620597839355,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:408, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01516,lr_multiplier:1.000,loss:1.7951372861862183,entropy:1.805899739265442,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:409, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01499,lr_multiplier:1.000,loss:1.7697720527648926,entropy:1.7688121795654297,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:410, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02261,lr_multiplier:1.000,loss:1.79969322681427,entropy:1.8236591815948486,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:411, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03191,lr_multiplier:1.000,loss:1.7964149713516235,entropy:1.8032734394073486,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:412, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01579,lr_multiplier:1.000,loss:1.8169968128204346,entropy:1.8189226388931274,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:413, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01915,lr_multiplier:1.000,loss:1.8143681287765503,entropy:1.8273115158081055,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:414, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01423,lr_multiplier:1.000,loss:1.8559447526931763,entropy:1.8594908714294434,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:415, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02083,lr_multiplier:1.000,loss:1.7960201501846313,entropy:1.8005021810531616,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:416, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01558,lr_multiplier:1.000,loss:1.882655382156372,entropy:1.8935465812683105,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:417, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01189,lr_multiplier:1.000,loss:1.8097264766693115,entropy:1.8049476146697998,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:418, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01381,lr_multiplier:1.000,loss:1.791526436805725,entropy:1.7911248207092285,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:419, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01271,lr_multiplier:1.000,loss:1.7189449071884155,entropy:1.7293511629104614,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:420, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01372,lr_multiplier:1.000,loss:1.7802186012268066,entropy:1.7884819507598877,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:421, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01514,lr_multiplier:1.000,loss:1.7493312358856201,entropy:1.7545931339263916,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:422, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01359,lr_multiplier:1.000,loss:1.7442187070846558,entropy:1.7339588403701782,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:423, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01183,lr_multiplier:1.000,loss:1.7283908128738403,entropy:1.7442010641098022,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:424, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01473,lr_multiplier:1.000,loss:1.7447624206542969,entropy:1.7487471103668213,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:425, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01065,lr_multiplier:1.000,loss:1.7908213138580322,entropy:1.7935864925384521,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:426, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01189,lr_multiplier:1.000,loss:1.7807461023330688,entropy:1.7768467664718628,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:427, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01306,lr_multiplier:1.000,loss:1.7636500597000122,entropy:1.785671591758728,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:428, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01517,lr_multiplier:1.000,loss:1.7409467697143555,entropy:1.741343379020691,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:429, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01232,lr_multiplier:1.000,loss:1.666425347328186,entropy:1.6696438789367676,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:430, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01844,lr_multiplier:1.000,loss:1.7460362911224365,entropy:1.7505543231964111,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:431, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01690,lr_multiplier:1.000,loss:1.7172582149505615,entropy:1.7208006381988525,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:432, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01698,lr_multiplier:1.000,loss:1.785644769668579,entropy:1.7927709817886353,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:433, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01154,lr_multiplier:1.000,loss:1.7207728624343872,entropy:1.714399814605713,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:434, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02404,lr_multiplier:1.000,loss:1.74170982837677,entropy:1.747603416442871,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:435, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01599,lr_multiplier:1.000,loss:1.7551147937774658,entropy:1.767749547958374,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:436, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01456,lr_multiplier:1.000,loss:1.6810643672943115,entropy:1.673413872718811,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:437, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01460,lr_multiplier:1.000,loss:1.7086504697799683,entropy:1.7235755920410156,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:438, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01126,lr_multiplier:1.000,loss:1.7451304197311401,entropy:1.7579834461212158,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:439, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01775,lr_multiplier:1.000,loss:1.7608848810195923,entropy:1.741194486618042,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:440, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01416,lr_multiplier:1.000,loss:1.78074312210083,entropy:1.8074729442596436,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:441, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01502,lr_multiplier:1.000,loss:1.6818805932998657,entropy:1.6735906600952148,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:442, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01529,lr_multiplier:1.000,loss:1.7435534000396729,entropy:1.7566851377487183,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:443, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00856,lr_multiplier:1.500,loss:1.717267632484436,entropy:1.7135423421859741,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:444, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01453,lr_multiplier:1.500,loss:1.7123416662216187,entropy:1.7210636138916016,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:445, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01263,lr_multiplier:1.500,loss:1.7628686428070068,entropy:1.7846556901931763,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:446, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01374,lr_multiplier:1.500,loss:1.7639468908309937,entropy:1.7517873048782349,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:447, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01898,lr_multiplier:1.500,loss:1.6995185613632202,entropy:1.7085597515106201,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:448, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02439,lr_multiplier:1.500,loss:1.742966651916504,entropy:1.7304799556732178,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:449, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01985,lr_multiplier:1.500,loss:1.751381754875183,entropy:1.751939296722412,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:450, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01617,lr_multiplier:1.500,loss:1.7065342664718628,entropy:1.7203861474990845,explained_var_old:1.000,explained_var_new:1.000
已经训练: 450轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 7, lose: 3, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:451, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02048,lr_multiplier:1.500,loss:1.7206748723983765,entropy:1.728783130645752,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:452, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03027,lr_multiplier:1.500,loss:1.8022373914718628,entropy:1.8127278089523315,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:453, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01894,lr_multiplier:1.500,loss:1.7516955137252808,entropy:1.7482049465179443,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:454, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02468,lr_multiplier:1.500,loss:1.7411819696426392,entropy:1.7434419393539429,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:455, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02483,lr_multiplier:1.500,loss:1.6823740005493164,entropy:1.6829967498779297,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:456, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01816,lr_multiplier:1.500,loss:1.7243949174880981,entropy:1.7561864852905273,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:457, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03074,lr_multiplier:1.500,loss:1.7001800537109375,entropy:1.6855180263519287,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:458, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03542,lr_multiplier:1.500,loss:1.7806131839752197,entropy:1.7706053256988525,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:459, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02756,lr_multiplier:1.500,loss:1.749480962753296,entropy:1.7569048404693604,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:460, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01487,lr_multiplier:1.500,loss:1.7227230072021484,entropy:1.7217893600463867,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:461, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01489,lr_multiplier:1.500,loss:1.7096586227416992,entropy:1.7082624435424805,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:462, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01420,lr_multiplier:1.500,loss:1.7116601467132568,entropy:1.7278528213500977,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:463, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01790,lr_multiplier:1.500,loss:1.7256898880004883,entropy:1.7300201654434204,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:464, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01895,lr_multiplier:1.500,loss:1.7551239728927612,entropy:1.7512105703353882,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:465, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00943,lr_multiplier:2.250,loss:1.6518702507019043,entropy:1.651930809020996,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:466, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01121,lr_multiplier:2.250,loss:1.701621174812317,entropy:1.7097854614257812,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:467, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01909,lr_multiplier:2.250,loss:1.698420763015747,entropy:1.7050169706344604,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:468, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02465,lr_multiplier:2.250,loss:1.727545976638794,entropy:1.7175244092941284,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:469, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02644,lr_multiplier:2.250,loss:1.6872575283050537,entropy:1.666853666305542,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:470, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.06719,lr_multiplier:1.500,loss:1.743914246559143,entropy:1.7518694400787354,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:471, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02811,lr_multiplier:1.500,loss:1.7228480577468872,entropy:1.7332226037979126,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:472, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02092,lr_multiplier:1.500,loss:1.693927526473999,entropy:1.6880111694335938,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:473, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03045,lr_multiplier:1.500,loss:1.7169567346572876,entropy:1.719740390777588,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:474, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02100,lr_multiplier:1.500,loss:1.7041679620742798,entropy:1.697652816772461,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:475, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02402,lr_multiplier:1.500,loss:1.6881263256072998,entropy:1.6953918933868408,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:476, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01721,lr_multiplier:1.500,loss:1.6993887424468994,entropy:1.6984330415725708,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:477, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02588,lr_multiplier:1.500,loss:1.701638102531433,entropy:1.7046960592269897,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:478, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02369,lr_multiplier:1.500,loss:1.6618287563323975,entropy:1.6793403625488281,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:479, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01557,lr_multiplier:1.500,loss:1.7208225727081299,entropy:1.7206013202667236,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:480, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.04351,lr_multiplier:1.000,loss:1.7610750198364258,entropy:1.7765734195709229,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:481, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03351,lr_multiplier:1.000,loss:1.6769392490386963,entropy:1.6883615255355835,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:482, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01856,lr_multiplier:1.000,loss:1.6756455898284912,entropy:1.6708507537841797,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:483, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01234,lr_multiplier:1.000,loss:1.7263669967651367,entropy:1.7384836673736572,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:484, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00779,lr_multiplier:1.500,loss:1.6287587881088257,entropy:1.6322407722473145,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:485, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01042,lr_multiplier:1.500,loss:1.7522215843200684,entropy:1.7444556951522827,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:486, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00888,lr_multiplier:2.250,loss:1.6914044618606567,entropy:1.6954004764556885,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:487, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01615,lr_multiplier:2.250,loss:1.7075220346450806,entropy:1.7044594287872314,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:488, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02028,lr_multiplier:2.250,loss:1.6785306930541992,entropy:1.6751562356948853,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:489, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02216,lr_multiplier:2.250,loss:1.6488295793533325,entropy:1.6580281257629395,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:490, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00992,lr_multiplier:3.375,loss:1.701023817062378,entropy:1.7118666172027588,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:491, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.04122,lr_multiplier:2.250,loss:1.752787470817566,entropy:1.7879918813705444,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:492, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.08080,lr_multiplier:1.500,loss:1.773079514503479,entropy:1.8161637783050537,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:493, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.04826,lr_multiplier:1.000,loss:1.7013216018676758,entropy:1.6772685050964355,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:494, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03019,lr_multiplier:1.000,loss:1.666642665863037,entropy:1.675005555152893,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:495, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01841,lr_multiplier:1.000,loss:1.7109452486038208,entropy:1.7171131372451782,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:496, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01349,lr_multiplier:1.000,loss:1.6776790618896484,entropy:1.680790662765503,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:497, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01097,lr_multiplier:1.000,loss:1.7111167907714844,entropy:1.7192920446395874,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:498, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01670,lr_multiplier:1.000,loss:1.6770027875900269,entropy:1.6679723262786865,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:499, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01549,lr_multiplier:1.000,loss:1.682572841644287,entropy:1.6988657712936401,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:500, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01266,lr_multiplier:1.000,loss:1.7418183088302612,entropy:1.7573965787887573,explained_var_old:1.000,explained_var_new:1.000
已经训练: 500轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
num_playouts:1000, win: 7, lose: 3, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:501, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00951,lr_multiplier:1.500,loss:1.6645740270614624,entropy:1.6528005599975586,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:502, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01769,lr_multiplier:1.500,loss:1.702878475189209,entropy:1.709060788154602,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:503, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01704,lr_multiplier:1.500,loss:1.7064834833145142,entropy:1.7038649320602417,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:504, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01685,lr_multiplier:1.500,loss:1.7244577407836914,entropy:1.731196641921997,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:505, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00784,lr_multiplier:2.250,loss:1.6527501344680786,entropy:1.652658462524414,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:506, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01600,lr_multiplier:2.250,loss:1.6870139837265015,entropy:1.6895360946655273,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:507, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01572,lr_multiplier:2.250,loss:1.6652714014053345,entropy:1.6687768697738647,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:508, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02065,lr_multiplier:2.250,loss:1.6799575090408325,entropy:1.6716639995574951,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:509, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01641,lr_multiplier:2.250,loss:1.6913869380950928,entropy:1.7082335948944092,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:510, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01604,lr_multiplier:2.250,loss:1.6656867265701294,entropy:1.6679892539978027,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:511, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02762,lr_multiplier:2.250,loss:1.6722947359085083,entropy:1.658095359802246,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:512, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01712,lr_multiplier:2.250,loss:1.6880160570144653,entropy:1.685065507888794,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:513, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02953,lr_multiplier:2.250,loss:1.6930431127548218,entropy:1.7023794651031494,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:514, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01467,lr_multiplier:2.250,loss:1.6635850667953491,entropy:1.6557984352111816,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:515, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02187,lr_multiplier:2.250,loss:1.6421507596969604,entropy:1.6521660089492798,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:516, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03163,lr_multiplier:2.250,loss:1.683371901512146,entropy:1.6916176080703735,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:517, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02372,lr_multiplier:2.250,loss:1.6714866161346436,entropy:1.6733330488204956,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:518, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01132,lr_multiplier:2.250,loss:1.7054296731948853,entropy:1.7095431089401245,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:519, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01415,lr_multiplier:2.250,loss:1.7235995531082153,entropy:1.7302623987197876,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:520, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01505,lr_multiplier:2.250,loss:1.6989232301712036,entropy:1.7044413089752197,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:521, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01380,lr_multiplier:2.250,loss:1.681912899017334,entropy:1.6876853704452515,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:522, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01517,lr_multiplier:2.250,loss:1.6534368991851807,entropy:1.65621018409729,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:523, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03416,lr_multiplier:2.250,loss:1.6794110536575317,entropy:1.6608755588531494,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:524, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01940,lr_multiplier:2.250,loss:1.6365742683410645,entropy:1.634605884552002,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:525, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02109,lr_multiplier:2.250,loss:1.6328544616699219,entropy:1.637647032737732,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:526, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02366,lr_multiplier:2.250,loss:1.7085483074188232,entropy:1.7194653749465942,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:527, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01999,lr_multiplier:2.250,loss:1.6335798501968384,entropy:1.6461572647094727,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:528, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01708,lr_multiplier:2.250,loss:1.6440110206604004,entropy:1.6530219316482544,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:529, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01882,lr_multiplier:2.250,loss:1.726941704750061,entropy:1.7151473760604858,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:530, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03026,lr_multiplier:2.250,loss:1.6808195114135742,entropy:1.6748254299163818,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:531, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01685,lr_multiplier:2.250,loss:1.6740483045578003,entropy:1.6631642580032349,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:532, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01433,lr_multiplier:2.250,loss:1.6440242528915405,entropy:1.6349115371704102,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:533, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01106,lr_multiplier:2.250,loss:1.709897756576538,entropy:1.7053399085998535,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:534, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02114,lr_multiplier:2.250,loss:1.7031129598617554,entropy:1.7106809616088867,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:535, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01358,lr_multiplier:2.250,loss:1.6848150491714478,entropy:1.6867055892944336,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:536, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01411,lr_multiplier:2.250,loss:1.683566689491272,entropy:1.6697653532028198,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:537, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01422,lr_multiplier:2.250,loss:1.6603361368179321,entropy:1.6607167720794678,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:538, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01424,lr_multiplier:2.250,loss:1.6610044240951538,entropy:1.6587073802947998,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:539, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01333,lr_multiplier:2.250,loss:1.7282097339630127,entropy:1.7319790124893188,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:540, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01079,lr_multiplier:2.250,loss:1.6914591789245605,entropy:1.6951954364776611,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:541, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00946,lr_multiplier:3.375,loss:1.713335633277893,entropy:1.7096977233886719,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:542, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01883,lr_multiplier:3.375,loss:1.6323877573013306,entropy:1.6274349689483643,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:543, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.04715,lr_multiplier:2.250,loss:1.6779192686080933,entropy:1.7019023895263672,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:544, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02142,lr_multiplier:2.250,loss:1.6913760900497437,entropy:1.7065010070800781,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:545, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01336,lr_multiplier:2.250,loss:1.6638051271438599,entropy:1.6548418998718262,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:546, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01821,lr_multiplier:2.250,loss:1.70722496509552,entropy:1.6925791501998901,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:547, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02651,lr_multiplier:2.250,loss:1.6559258699417114,entropy:1.6621698141098022,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:548, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01761,lr_multiplier:2.250,loss:1.6198906898498535,entropy:1.6192243099212646,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:549, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00977,lr_multiplier:3.375,loss:1.6536281108856201,entropy:1.6512689590454102,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:550, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01469,lr_multiplier:3.375,loss:1.6896109580993652,entropy:1.690992832183838,explained_var_old:1.000,explained_var_new:1.000
已经训练: 550轮
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 6, lose: 4, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:551, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02071,lr_multiplier:3.375,loss:1.665327548980713,entropy:1.671413540840149,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:552, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03118,lr_multiplier:3.375,loss:1.7240376472473145,entropy:1.7353887557983398,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:553, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02126,lr_multiplier:3.375,loss:1.7130547761917114,entropy:1.7204616069793701,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:554, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02779,lr_multiplier:3.375,loss:1.6965070962905884,entropy:1.686547040939331,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:555, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02174,lr_multiplier:3.375,loss:1.7027727365493774,entropy:1.7331080436706543,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:556, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02601,lr_multiplier:3.375,loss:1.647194504737854,entropy:1.649804711341858,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:557, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01897,lr_multiplier:3.375,loss:1.633107304573059,entropy:1.6234058141708374,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:558, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03107,lr_multiplier:3.375,loss:1.6016204357147217,entropy:1.615902066230774,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:559, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02867,lr_multiplier:3.375,loss:1.6719989776611328,entropy:1.6696429252624512,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:560, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01676,lr_multiplier:3.375,loss:1.685652256011963,entropy:1.7107045650482178,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:561, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02133,lr_multiplier:3.375,loss:1.6565369367599487,entropy:1.6506975889205933,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:562, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01343,lr_multiplier:3.375,loss:1.6966872215270996,entropy:1.6973127126693726,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:563, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01586,lr_multiplier:3.375,loss:1.642228603363037,entropy:1.661673903465271,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:564, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01315,lr_multiplier:3.375,loss:1.640425443649292,entropy:1.6242780685424805,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:565, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01172,lr_multiplier:3.375,loss:1.6809072494506836,entropy:1.7113583087921143,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:566, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01544,lr_multiplier:3.375,loss:1.5916887521743774,entropy:1.5975841283798218,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:567, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02256,lr_multiplier:3.375,loss:1.6578998565673828,entropy:1.6412509679794312,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:568, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01499,lr_multiplier:3.375,loss:1.6426994800567627,entropy:1.661444067955017,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:569, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02014,lr_multiplier:3.375,loss:1.6644214391708374,entropy:1.6692384481430054,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:570, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01449,lr_multiplier:3.375,loss:1.6468701362609863,entropy:1.6437861919403076,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:571, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01222,lr_multiplier:3.375,loss:1.6075470447540283,entropy:1.603946566581726,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:572, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01610,lr_multiplier:3.375,loss:1.6615016460418701,entropy:1.6523863077163696,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:573, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03019,lr_multiplier:3.375,loss:1.6532771587371826,entropy:1.6575433015823364,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:574, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02080,lr_multiplier:3.375,loss:1.6202465295791626,entropy:1.6053822040557861,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:575, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01446,lr_multiplier:3.375,loss:1.6658672094345093,entropy:1.6891329288482666,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:576, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02049,lr_multiplier:3.375,loss:1.6380445957183838,entropy:1.6349222660064697,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:577, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01647,lr_multiplier:3.375,loss:1.6562870740890503,entropy:1.6705576181411743,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:578, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01624,lr_multiplier:3.375,loss:1.674049973487854,entropy:1.6750789880752563,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:579, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02644,lr_multiplier:3.375,loss:1.6399481296539307,entropy:1.6314167976379395,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:580, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01877,lr_multiplier:3.375,loss:1.5820008516311646,entropy:1.6052261590957642,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:581, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01126,lr_multiplier:3.375,loss:1.5941249132156372,entropy:1.5788593292236328,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:582, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02295,lr_multiplier:3.375,loss:1.6831152439117432,entropy:1.7162706851959229,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:583, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01812,lr_multiplier:3.375,loss:1.6200839281082153,entropy:1.6008485555648804,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:584, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01452,lr_multiplier:3.375,loss:1.5821560621261597,entropy:1.577901005744934,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:585, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01520,lr_multiplier:3.375,loss:1.608698844909668,entropy:1.623732566833496,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:586, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01366,lr_multiplier:3.375,loss:1.6392792463302612,entropy:1.6351113319396973,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:587, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00800,lr_multiplier:5.062,loss:1.6304296255111694,entropy:1.6304634809494019,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:588, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.06796,lr_multiplier:3.375,loss:1.6705660820007324,entropy:1.5155776739120483,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:589, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.10630,lr_multiplier:2.250,loss:1.6474368572235107,entropy:1.6698702573776245,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:590, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03559,lr_multiplier:2.250,loss:1.6694642305374146,entropy:1.703920602798462,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:591, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03225,lr_multiplier:2.250,loss:1.6581662893295288,entropy:1.6715283393859863,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:592, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02815,lr_multiplier:2.250,loss:1.5962188243865967,entropy:1.5997748374938965,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:593, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01722,lr_multiplier:2.250,loss:1.6392024755477905,entropy:1.6425907611846924,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:594, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01342,lr_multiplier:2.250,loss:1.6868289709091187,entropy:1.6876329183578491,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:595, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01751,lr_multiplier:2.250,loss:1.641577959060669,entropy:1.6357903480529785,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:596, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01144,lr_multiplier:2.250,loss:1.6589285135269165,entropy:1.6751879453659058,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:597, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01412,lr_multiplier:2.250,loss:1.609240174293518,entropy:1.6195975542068481,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:598, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00745,lr_multiplier:3.375,loss:1.6673879623413086,entropy:1.6650947332382202,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:599, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01800,lr_multiplier:3.375,loss:1.6140894889831543,entropy:1.618356704711914,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:600, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01106,lr_multiplier:3.375,loss:1.6120370626449585,entropy:1.5968060493469238,explained_var_old:1.000,explained_var_new:1.000
已经训练: 600轮
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 6, lose: 4, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:601, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01324,lr_multiplier:3.375,loss:1.6128723621368408,entropy:1.6128790378570557,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:602, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01545,lr_multiplier:3.375,loss:1.6014879941940308,entropy:1.5972615480422974,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:603, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01336,lr_multiplier:3.375,loss:1.6401607990264893,entropy:1.6545535326004028,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:604, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01573,lr_multiplier:3.375,loss:1.6272248029708862,entropy:1.6135520935058594,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:605, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01477,lr_multiplier:3.375,loss:1.6290141344070435,entropy:1.6216106414794922,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:606, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01771,lr_multiplier:3.375,loss:1.6013264656066895,entropy:1.6088440418243408,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:607, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00855,lr_multiplier:5.062,loss:1.628373146057129,entropy:1.6287999153137207,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:608, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03142,lr_multiplier:5.062,loss:1.5575170516967773,entropy:1.5596551895141602,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:609, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03879,lr_multiplier:5.062,loss:1.600204348564148,entropy:1.5085912942886353,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:610, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03755,lr_multiplier:5.062,loss:1.654176115989685,entropy:1.6404205560684204,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:611, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02718,lr_multiplier:5.062,loss:1.6708436012268066,entropy:1.7227574586868286,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:612, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02174,lr_multiplier:5.062,loss:1.6406108140945435,entropy:1.6104024648666382,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:613, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02073,lr_multiplier:5.062,loss:1.6234378814697266,entropy:1.6608445644378662,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:614, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03317,lr_multiplier:5.062,loss:1.6787749528884888,entropy:1.6535245180130005,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:615, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03166,lr_multiplier:5.062,loss:1.6239837408065796,entropy:1.6176167726516724,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:616, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01462,lr_multiplier:5.062,loss:1.6134610176086426,entropy:1.6285654306411743,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:617, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02086,lr_multiplier:5.062,loss:1.5981367826461792,entropy:1.5825166702270508,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:618, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01469,lr_multiplier:5.062,loss:1.628036379814148,entropy:1.6172162294387817,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:619, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02140,lr_multiplier:5.062,loss:1.622415542602539,entropy:1.6323879957199097,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:620, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01768,lr_multiplier:5.062,loss:1.6313767433166504,entropy:1.6268478631973267,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:621, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01622,lr_multiplier:5.062,loss:1.578882098197937,entropy:1.5845235586166382,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:622, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01571,lr_multiplier:5.062,loss:1.5861297845840454,entropy:1.6064249277114868,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:623, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01372,lr_multiplier:5.062,loss:1.5689464807510376,entropy:1.5708346366882324,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:624, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01750,lr_multiplier:5.062,loss:1.6478126049041748,entropy:1.6402815580368042,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:625, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01650,lr_multiplier:5.062,loss:1.6082407236099243,entropy:1.6547304391860962,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:626, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01779,lr_multiplier:5.062,loss:1.568215250968933,entropy:1.5383559465408325,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:627, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01980,lr_multiplier:5.062,loss:1.674759864807129,entropy:1.6969355344772339,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:628, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01642,lr_multiplier:5.062,loss:1.6096761226654053,entropy:1.6317789554595947,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:629, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02026,lr_multiplier:5.062,loss:1.6379363536834717,entropy:1.6245465278625488,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:630, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01415,lr_multiplier:5.062,loss:1.5976085662841797,entropy:1.6362740993499756,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:631, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02282,lr_multiplier:5.062,loss:1.6039636135101318,entropy:1.580289602279663,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:632, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02248,lr_multiplier:5.062,loss:1.6411899328231812,entropy:1.645230770111084,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:633, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01648,lr_multiplier:5.062,loss:1.5932914018630981,entropy:1.604783058166504,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:634, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01915,lr_multiplier:5.062,loss:1.6196997165679932,entropy:1.619472622871399,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:635, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01522,lr_multiplier:5.062,loss:1.58171808719635,entropy:1.5879147052764893,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:636, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01314,lr_multiplier:5.062,loss:1.5847115516662598,entropy:1.5856653451919556,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:637, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01313,lr_multiplier:5.062,loss:1.6396816968917847,entropy:1.6556100845336914,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:638, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01679,lr_multiplier:5.062,loss:1.611782431602478,entropy:1.6096863746643066,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:639, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02688,lr_multiplier:5.062,loss:1.5410233736038208,entropy:1.5348159074783325,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:640, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01163,lr_multiplier:5.062,loss:1.5916790962219238,entropy:1.6115056276321411,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:641, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01558,lr_multiplier:5.062,loss:1.5679490566253662,entropy:1.5709806680679321,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:642, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01579,lr_multiplier:5.062,loss:1.6228766441345215,entropy:1.6207844018936157,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:643, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02425,lr_multiplier:5.062,loss:1.6134552955627441,entropy:1.609804630279541,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:644, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02587,lr_multiplier:5.062,loss:1.59638249874115,entropy:1.5996243953704834,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:645, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02010,lr_multiplier:5.062,loss:1.539638638496399,entropy:1.5283973217010498,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:646, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01609,lr_multiplier:5.062,loss:1.613311767578125,entropy:1.6054039001464844,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:647, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01497,lr_multiplier:5.062,loss:1.5894304513931274,entropy:1.6059484481811523,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:648, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02072,lr_multiplier:5.062,loss:1.6008548736572266,entropy:1.613067865371704,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:649, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.06799,lr_multiplier:3.375,loss:1.6197288036346436,entropy:1.4967292547225952,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:650, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03126,lr_multiplier:3.375,loss:1.5748417377471924,entropy:1.6038615703582764,explained_var_old:1.000,explained_var_new:1.000
已经训练: 650轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 6, lose: 4, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:651, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02224,lr_multiplier:3.375,loss:1.6439316272735596,entropy:1.6828300952911377,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:652, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01915,lr_multiplier:3.375,loss:1.5711880922317505,entropy:1.5812270641326904,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:653, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01308,lr_multiplier:3.375,loss:1.6280248165130615,entropy:1.6268523931503296,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:654, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02158,lr_multiplier:3.375,loss:1.5997323989868164,entropy:1.5949327945709229,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:655, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01736,lr_multiplier:3.375,loss:1.6300387382507324,entropy:1.608324646949768,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:656, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02239,lr_multiplier:3.375,loss:1.5505576133728027,entropy:1.5357996225357056,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:657, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01403,lr_multiplier:3.375,loss:1.561439871788025,entropy:1.5442975759506226,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:658, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01817,lr_multiplier:3.375,loss:1.5478624105453491,entropy:1.5315227508544922,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:659, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01602,lr_multiplier:3.375,loss:1.5468095541000366,entropy:1.5587048530578613,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:660, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01502,lr_multiplier:3.375,loss:1.6502071619033813,entropy:1.6692614555358887,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:661, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01193,lr_multiplier:3.375,loss:1.61703360080719,entropy:1.6117687225341797,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:662, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01763,lr_multiplier:3.375,loss:1.5953422784805298,entropy:1.5740172863006592,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:663, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02137,lr_multiplier:3.375,loss:1.5133264064788818,entropy:1.5307813882827759,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:664, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01544,lr_multiplier:3.375,loss:1.5763046741485596,entropy:1.567405104637146,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:665, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01228,lr_multiplier:3.375,loss:1.5775200128555298,entropy:1.5661269426345825,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:666, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01281,lr_multiplier:3.375,loss:1.571794867515564,entropy:1.589775562286377,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:667, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01596,lr_multiplier:3.375,loss:1.567715048789978,entropy:1.5633352994918823,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:668, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01314,lr_multiplier:3.375,loss:1.6546540260314941,entropy:1.6687034368515015,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:669, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02303,lr_multiplier:3.375,loss:1.5657665729522705,entropy:1.5674729347229004,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:670, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00900,lr_multiplier:5.062,loss:1.6185920238494873,entropy:1.6085751056671143,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:671, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01375,lr_multiplier:5.062,loss:1.615911841392517,entropy:1.6258423328399658,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:672, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02525,lr_multiplier:5.062,loss:1.5414729118347168,entropy:1.572926640510559,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:673, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02029,lr_multiplier:5.062,loss:1.5654852390289307,entropy:1.576676368713379,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:674, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02555,lr_multiplier:5.062,loss:1.5758161544799805,entropy:1.594987154006958,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:675, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.04109,lr_multiplier:3.375,loss:1.5565298795700073,entropy:1.5379290580749512,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:676, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01894,lr_multiplier:3.375,loss:1.5591533184051514,entropy:1.554121494293213,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:677, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01588,lr_multiplier:3.375,loss:1.585227131843567,entropy:1.6090664863586426,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:678, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01567,lr_multiplier:3.375,loss:1.5796403884887695,entropy:1.5708427429199219,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:679, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01812,lr_multiplier:3.375,loss:1.5791970491409302,entropy:1.596893310546875,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:680, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01638,lr_multiplier:3.375,loss:1.586192011833191,entropy:1.5780688524246216,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:681, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01431,lr_multiplier:3.375,loss:1.568819284439087,entropy:1.5692367553710938,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:682, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01006,lr_multiplier:3.375,loss:1.6184842586517334,entropy:1.6155496835708618,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:683, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01315,lr_multiplier:3.375,loss:1.5525561571121216,entropy:1.5470222234725952,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:684, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01146,lr_multiplier:3.375,loss:1.5727572441101074,entropy:1.5706766843795776,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:685, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01126,lr_multiplier:3.375,loss:1.555184245109558,entropy:1.5549947023391724,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:686, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01657,lr_multiplier:3.375,loss:1.5263751745224,entropy:1.528573751449585,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:687, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01034,lr_multiplier:3.375,loss:1.5917322635650635,entropy:1.5946662425994873,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:688, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01125,lr_multiplier:3.375,loss:1.559118628501892,entropy:1.5513684749603271,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:689, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01095,lr_multiplier:3.375,loss:1.5317885875701904,entropy:1.5335166454315186,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:690, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00937,lr_multiplier:5.062,loss:1.5680173635482788,entropy:1.5792763233184814,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:691, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01314,lr_multiplier:5.062,loss:1.5714857578277588,entropy:1.592512607574463,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:692, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01760,lr_multiplier:5.062,loss:1.6215636730194092,entropy:1.643193244934082,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:693, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01805,lr_multiplier:5.062,loss:1.5236624479293823,entropy:1.532628059387207,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:694, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03130,lr_multiplier:5.062,loss:1.5979440212249756,entropy:1.6176272630691528,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:695, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01939,lr_multiplier:5.062,loss:1.5644176006317139,entropy:1.5715487003326416,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:696, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02290,lr_multiplier:5.062,loss:1.558063268661499,entropy:1.5728932619094849,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:697, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01893,lr_multiplier:5.062,loss:1.5663058757781982,entropy:1.5833039283752441,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:698, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01534,lr_multiplier:5.062,loss:1.5734916925430298,entropy:1.5781112909317017,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:699, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02072,lr_multiplier:5.062,loss:1.5762187242507935,entropy:1.5567816495895386,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:700, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02211,lr_multiplier:5.062,loss:1.636738657951355,entropy:1.6175451278686523,explained_var_old:1.000,explained_var_new:1.000
已经训练: 700轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
num_playouts:1000, win: 6, lose: 4, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:701, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01915,lr_multiplier:5.062,loss:1.5779870748519897,entropy:1.583891749382019,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:702, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02737,lr_multiplier:5.062,loss:1.5550804138183594,entropy:1.5740551948547363,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:703, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02945,lr_multiplier:5.062,loss:1.6353474855422974,entropy:1.635801076889038,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:704, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03353,lr_multiplier:5.062,loss:1.6422438621520996,entropy:1.7223330736160278,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:705, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03578,lr_multiplier:5.062,loss:1.5746005773544312,entropy:1.58192777633667,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:706, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02153,lr_multiplier:5.062,loss:1.5461270809173584,entropy:1.5345264673233032,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:707, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01460,lr_multiplier:5.062,loss:1.5726842880249023,entropy:1.5855778455734253,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:708, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02343,lr_multiplier:5.062,loss:1.6100003719329834,entropy:1.6057583093643188,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:709, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01796,lr_multiplier:5.062,loss:1.5334750413894653,entropy:1.5516180992126465,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:710, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02131,lr_multiplier:5.062,loss:1.5376309156417847,entropy:1.5170447826385498,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:711, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02541,lr_multiplier:5.062,loss:1.5687555074691772,entropy:1.5974177122116089,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:712, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01811,lr_multiplier:5.062,loss:1.5744996070861816,entropy:1.5572483539581299,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:713, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01741,lr_multiplier:5.062,loss:1.5167466402053833,entropy:1.5263633728027344,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:714, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02198,lr_multiplier:5.062,loss:1.55717933177948,entropy:1.5620968341827393,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:715, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01777,lr_multiplier:5.062,loss:1.6052814722061157,entropy:1.607560634613037,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:716, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01977,lr_multiplier:5.062,loss:1.5367356538772583,entropy:1.5436463356018066,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:717, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02402,lr_multiplier:5.062,loss:1.4889897108078003,entropy:1.4888064861297607,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:718, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03145,lr_multiplier:5.062,loss:1.5374040603637695,entropy:1.5571238994598389,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:719, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02709,lr_multiplier:5.062,loss:1.5280537605285645,entropy:1.547297477722168,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:720, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02655,lr_multiplier:5.062,loss:1.5293378829956055,entropy:1.5443646907806396,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:721, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02063,lr_multiplier:5.062,loss:1.5448002815246582,entropy:1.5531121492385864,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:722, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02421,lr_multiplier:5.062,loss:1.6092272996902466,entropy:1.61562180519104,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:723, episode_len:13
TrainPipeline:run: 开始模型训练
