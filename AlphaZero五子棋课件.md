---
marp: true
theme: default
paginate: true
header: 'AlphaZero äº”å­æ£‹é¡¹ç›®'
footer: 'Â© 2026 AlphaZero Gomoku'
style: |
  section {
    background-color: #ffffff;
    font-family: 'PingFang SC', 'Microsoft YaHei', sans-serif;
  }
  h1 {
    color: #2c3e50;
    border-bottom: 3px solid #3498db;
  }
  h2 {
    color: #34495e;
  }
  code {
    background-color: #f1f3f5;
    color: #e74c3c;
  }
  strong {
    color: #e74c3c;
  }
---

# AlphaZero äº”å­æ£‹é¡¹ç›®

**åŸºäºæ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æ£‹ç±» AI å®ç°**

ğŸ¤– æ— äººç±»å…ˆéªŒçŸ¥è¯†çš„è‡ªæˆ‘è¿›åŒ–
ğŸŒ³ MCTS æœç´¢æ ‘å¯è§†åŒ–
ğŸ¯ è¶…äººæ°´å¹³çš„æ£‹åŠ›

---

## ğŸ“‹ è¯¾ç¨‹å¤§çº²

1. **é¡¹ç›®æ¦‚è¿°** - AlphaZero ç®€ä»‹
2. **æ ¸å¿ƒç®—æ³•** - MCTS + æ·±åº¦å­¦ä¹ 
3. **è®­ç»ƒæµç¨‹** - è‡ªæˆ‘å¯¹å¼ˆå¼ºåŒ–å­¦ä¹ 
4. **å…³é”®æŠ€æœ¯** - Negamax æ¡†æ¶
5. **å·¥ç¨‹å®ç°** - æ¶æ„ä¸ä¼˜åŒ–
6. **å®æˆ˜æ¼”ç¤º** - äººæœºå¯¹å¼ˆ

---

# ç¬¬ä¸€éƒ¨åˆ†ï¼šé¡¹ç›®æ¦‚è¿°

---

## ä»€ä¹ˆæ˜¯ AlphaZeroï¼Ÿ

**AlphaZero** æ˜¯ DeepMind æå‡ºçš„é€šç”¨æ£‹ç±» AI ç®—æ³•

### æ ¸å¿ƒç‰¹ç‚¹

- ğŸš« **æ— äººç±»çŸ¥è¯†**ï¼šä¸ä¾èµ–äººç±»æ£‹è°±
- ğŸ”„ **è‡ªæˆ‘å¯¹å¼ˆ**ï¼šé€šè¿‡ä¸è‡ªå·±ä¸‹æ£‹å­¦ä¹ 
- ğŸ§  **æ·±åº¦å­¦ä¹ **ï¼šç¥ç»ç½‘ç»œè¯„ä¼°å±€é¢
- ğŸŒ³ **MCTS æœç´¢**ï¼šè’™ç‰¹å¡æ´›æ ‘æœç´¢

### æˆå°±

- âœ… å›´æ£‹ï¼š4 å°æ—¶è¶…è¶Š AlphaGo
- âœ… å›½é™…è±¡æ£‹ï¼š2 å°æ—¶è¶…è¶Š Stockfish
- âœ… å°†æ£‹ï¼š2 å°æ—¶è¾¾åˆ°è¶…äººæ°´å¹³

---

## æœ¬é¡¹ç›®ç‰¹è‰²

### ğŸ® å®Œæ•´å®ç°
- AlphaZero ç®—æ³•å®Œæ•´å¤ç°
- PyTorch å®ç°çš„ç¥ç»ç½‘ç»œ
- Pygame å¯è§†åŒ–ç•Œé¢

### ğŸŒ³ å¯è§†åŒ–
- å®æ—¶æ˜¾ç¤º MCTS æœç´¢æ ‘
- èŠ‚ç‚¹è®¿é—®ç»Ÿè®¡
- èƒœç‡è¯„ä¼°å±•ç¤º

### ğŸ“Š å·¥ç¨‹åŒ–
- æ–­ç‚¹ç»­è®­æ”¯æŒ
- æ¨¡å‹è‡ªåŠ¨ä¿å­˜
- å®Œæ•´çš„è®­ç»ƒç›‘æ§

---

# ç¬¬äºŒéƒ¨åˆ†ï¼šæ ¸å¿ƒç®—æ³•

---

## MCTSï¼šè’™ç‰¹å¡æ´›æ ‘æœç´¢

### å››ä¸ªæ ¸å¿ƒæ­¥éª¤

```
1. Selection   (é€‰æ‹©)  - ä»æ ¹èŠ‚ç‚¹å‘ä¸‹é€‰æ‹©æœ€ä¼˜è·¯å¾„
2. Expansion   (æ‰©å±•)  - åˆ°è¾¾å¶èŠ‚ç‚¹åæ‰©å±•å­èŠ‚ç‚¹
3. Evaluation  (è¯„ä¼°)  - ä½¿ç”¨ç¥ç»ç½‘ç»œè¯„ä¼°å±€é¢
4. Backpropagation (å›æº¯) - å°†è¯„ä¼°ç»“æœåå‘ä¼ æ’­
```

### UCT å…¬å¼

```
UCT = Q(s,a) + c_puct Ã— P(s,a) Ã— sqrt(N(s)) / (1 + N(s,a))
       â†‘               â†‘
    åˆ©ç”¨é¡¹          æ¢ç´¢é¡¹
```

---

## AlphaZero = MCTS + æ·±åº¦å­¦ä¹ 

### ä¼ ç»Ÿ MCTS
- éšæœºæ¨¡æ‹Ÿï¼ˆRolloutï¼‰
- éœ€è¦å¤§é‡æ¨¡æ‹Ÿæ¬¡æ•°
- æ•ˆç‡è¾ƒä½

### AlphaZero MCTS
- **ç¥ç»ç½‘ç»œ**ä»£æ›¿éšæœºæ¨¡æ‹Ÿ
- **ç­–ç•¥å¤´**ï¼šæä¾›å…ˆéªŒæ¦‚ç‡ P(s,a)
- **ä»·å€¼å¤´**ï¼šè¯„ä¼°å±€é¢èƒœç‡ V(s)
- æ•ˆç‡æå‡ 10-100 å€

---

## ç¥ç»ç½‘ç»œæ¶æ„

### è¾“å…¥ï¼šæ£‹ç›˜çŠ¶æ€ï¼ˆ4 é€šé“ï¼‰

```
é€šé“1: å½“å‰ç©å®¶çš„æ£‹å­ä½ç½®
é€šé“2: å¯¹æ‰‹çš„æ£‹å­ä½ç½®
é€šé“3: æœ€åä¸€æ¬¡è½å­ä½ç½®
é€šé“4: å½“å‰ç©å®¶æ ‡è¯†
```

### è¾“å‡ºï¼šåŒå¤´ç½‘ç»œ

```python
ç­–ç•¥å¤´ (Policy Head):  P(s,a) - æ‰€æœ‰ä½ç½®çš„æ¦‚ç‡åˆ†å¸ƒ
ä»·å€¼å¤´ (Value Head):   V(s) âˆˆ [-1, 1] - å½“å‰å±€é¢èƒœç‡
```

---

## è®­ç»ƒ vs å®æˆ˜

### ğŸ“ è®­ç»ƒé˜¶æ®µï¼šæ¢ç´¢ä¼˜å…ˆ

```python
# ä½¿ç”¨æ¸©åº¦å‚æ•°å¢åŠ æ¢ç´¢æ€§
temp = 1.0
# æ ¹æ®è®¿é—®æ¬¡æ•°åˆ†å¸ƒè¿›è¡Œæ¦‚ç‡é‡‡æ ·
action = sample(visit_counts, temp)
```

**ç›®æ ‡**ï¼šç”Ÿæˆå¤šæ ·åŒ–çš„è®­ç»ƒæ•°æ®

### âš”ï¸ å®æˆ˜é˜¶æ®µï¼šæœ€ä¼˜å†³ç­–

```python
# ç¡®å®šæ€§é€‰æ‹©
temp = 0
# ç›´æ¥é€‰æ‹©è®¿é—®æ¬¡æ•°æœ€å¤šçš„åŠ¨ä½œ
action = argmax(visit_counts)
```

**ç›®æ ‡**ï¼šä¿è¯å†³ç­–çš„å‡†ç¡®æ€§

---

# ç¬¬ä¸‰éƒ¨åˆ†ï¼šè®­ç»ƒæµç¨‹

---

## è‡ªæˆ‘å¯¹å¼ˆå¼ºåŒ–å­¦ä¹ 

### æ ¸å¿ƒå¾ªç¯

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. è‡ªæˆ‘å¯¹å¼ˆ (Self-Play)        â”‚
â”‚     AI vs AI äº§ç”Ÿå¯¹å±€æ•°æ®       â”‚
â”‚     â†“                            â”‚
â”‚  2. æ•°æ®å¢å¼º (Augmentation)     â”‚
â”‚     æ—‹è½¬+ç¿»è½¬ â†’ 8å€æ•°æ®         â”‚
â”‚     â†“                            â”‚
â”‚  3. ç»éªŒå›æ”¾ (Experience Replay)â”‚
â”‚     å­˜å…¥ç¼“å†²åŒºï¼Œæ‰“ç ´ç›¸å…³æ€§       â”‚
â”‚     â†“                            â”‚
â”‚  4. æ¨¡å‹è®­ç»ƒ (Training)         â”‚
â”‚     æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç¥ç»ç½‘ç»œ         â”‚
â”‚     â†“                            â”‚
â”‚  5. ç­–ç•¥è¯„ä¼° (Evaluation)       â”‚
â”‚     vs çº¯MCTS è¯„ä¼°è¿›æ­¥          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æ•°æ®å¢å¼º

### åˆ©ç”¨å¯¹ç§°æ€§æ‰©å……æ•°æ®

```
åŸå§‹æ£‹ç›˜ â†’ æ—‹è½¬4æ¬¡ â†’ æ¯æ¬¡ç¿»è½¬ = 8å€æ•°æ®

  åŸå§‹      90Â°      180Â°     270Â°
  â—‹â—        â—â—‹       â—â—‹       â—‹â—
  â—â—‹        â—‹â—       â—‹â—       â—â—‹

æ¯ä¸ªå†æ°´å¹³ç¿»è½¬ä¸€æ¬¡ â†’ æ€»å…± 8 ä¸ªç­‰ä»·çŠ¶æ€
```

**æ•ˆæœ**ï¼šä»ä¸€å±€æ¸¸æˆç”Ÿæˆ 8 å€è®­ç»ƒæ ·æœ¬

---

## å…³é”®è¶…å‚æ•°

### è®­ç»ƒé…ç½®

| å‚æ•° | å€¼ | è¯´æ˜ |
|-----|-----|-----|
| `learn_rate` | 5e-5 | å­¦ä¹ ç‡ |
| `n_playout` | 1000 | MCTS æ¨¡æ‹Ÿæ¬¡æ•° |
| `batch_size` | 512 | Mini-batch å¤§å° |
| `buffer_size` | 10000 | ç»éªŒå›æ”¾ç¼“å†²åŒº |
| `game_batch_num` | 2000 | æ€»è®­ç»ƒè½®æ•° |
| `check_freq` | 50 | è¯„ä¼°é¢‘ç‡ |

---

## è®­ç»ƒç›‘æ§æŒ‡æ ‡

### å…³é”®æŒ‡æ ‡

```python
âœ“ KL æ•£åº¦        - ç­–ç•¥æ›´æ–°å¹…åº¦ï¼ˆåº”ä¿æŒåœ¨ 0.02 é™„è¿‘ï¼‰
âœ“ Loss          - æ€»ä½“æŸå¤±ï¼ˆåº”é€æ¸ä¸‹é™ï¼‰
âœ“ Entropy       - ç­–ç•¥ç†µï¼ˆè¡¡é‡æ¢ç´¢ç¨‹åº¦ï¼‰
âœ“ Explained Var - ä»·å€¼ç½‘ç»œæ‹Ÿåˆè´¨é‡ï¼ˆè¶Šæ¥è¿‘1è¶Šå¥½ï¼‰
âœ“ Win Ratio     - å¯¹çº¯MCTSçš„èƒœç‡ï¼ˆåº”æŒç»­æå‡ï¼‰
```

### è®­ç»ƒè¿›åº¦ç¤ºä¾‹

```
batch i:50, episode_len:42
kl:0.01234, lr_multiplier:1.000, loss:2.345, entropy:3.456
explained_var_old:0.543, explained_var_new:0.678
num_playouts:1000, win: 6, lose: 3, tie:1
ç›¸è¾ƒäºMCTS@1000, æˆªè‡³ç›®å‰çš„æœ€ä½³èƒœç‡=0.65
```

---

# ç¬¬å››éƒ¨åˆ†ï¼šå…³é”®æŠ€æœ¯

---

## Negamax æ¡†æ¶

### é—®é¢˜ï¼šä»·å€¼çš„è§†è§’

```
åœ¨æ£‹ç›˜æ¸¸æˆä¸­ï¼š
  ä½ çš„å¥½å±€é¢ = å¯¹æ‰‹çš„åå±€é¢
  ä½ çš„ä»·å€¼ = -å¯¹æ‰‹çš„ä»·å€¼
```

### Negamax è§£å†³æ–¹æ¡ˆ

**æ ¸å¿ƒæ€æƒ³**ï¼šé€šè¿‡ç¬¦å·ç¿»è½¬ç»Ÿä¸€è§†è§’

```python
# å¶å­èŠ‚ç‚¹è¯„ä¼°ï¼ˆç¥ç»ç½‘ç»œè§†è§’ = å¯¹æ‰‹è§†è§’ï¼‰
_, value = policy_value_fn(board)

# è½¬æ¢ä¸ºå½“å‰èŠ‚ç‚¹è§†è§’
leaf_value = -value

# é€’å½’å›æº¯ï¼ˆæ¯å±‚è‡ªåŠ¨ç¿»è½¬ç¬¦å·ï¼‰
node.update_recursive(-leaf_value)
```

---

## Negamax è¯¦ç»†æ¨ç†

### ä¸ºä»€ä¹ˆè¦å–è´Ÿå·ï¼Ÿ

#### æ­¥éª¤ 1ï¼šåˆ°è¾¾å¶å­èŠ‚ç‚¹
```
æ‰§è¡Œäº† board.do_move(action)
â†’ current_player å·²åˆ‡æ¢ä¸ºå¯¹æ‰‹
```

#### æ­¥éª¤ 2ï¼šç¥ç»ç½‘ç»œè¯„ä¼°
```
value = policy_value_fn(board)
â†’ è¿”å›çš„æ˜¯å¯¹æ‰‹è§†è§’çš„ä»·å€¼
```

#### æ­¥éª¤ 3ï¼šè§†è§’è½¬æ¢
```
leaf_value = -value
â†’ è½¬æ¢ä¸ºå½“å‰èŠ‚ç‚¹è§†è§’
```

#### æ­¥éª¤ 4ï¼šé€’å½’å›æº¯
```python
def update_recursive(self, value):
    self.update(value)
    if self.parent:
        self.parent.update_recursive(-value)  # ç¬¦å·ç¿»è½¬
```

---

## Negamax çš„ä¼˜åŠ¿

### âœ… ä¼˜ç‚¹

1. **ç»Ÿä¸€è§†è§’** - æ‰€æœ‰èŠ‚ç‚¹ç”¨ç›¸åŒé€»è¾‘
2. **ç®€åŒ–ä»£ç ** - ä¸éœ€è¦åŒºåˆ†ç©å®¶1/ç©å®¶2
3. **ç¬¦å·ä¼ æ’­** - è‡ªåŠ¨å¤„ç†å¯¹æ‰‹å…³ç³»
4. **æ•°å­¦ä¼˜é›…** - åˆ©ç”¨é›¶å’Œåšå¼ˆå¯¹ç§°æ€§

### ğŸ” å…³é”®ç†è§£

```
çˆ¶èŠ‚ç‚¹è§†è§’ï¼šé€‰æ‹©è¿™ä¸ªåŠ¨ä½œå¥½ä¸å¥½ï¼Ÿ
å­èŠ‚ç‚¹è§†è§’ï¼šå¯¹æ‰‹é¢å¯¹è¿™ä¸ªå±€é¢å¥½ä¸å¥½ï¼Ÿ

çˆ¶èŠ‚ç‚¹ä»·å€¼ = -å­èŠ‚ç‚¹ä»·å€¼
```

---

## æœç´¢æ ‘å…±äº«æœºåˆ¶

### æ˜“æ··æ·†ç‚¹

```
â“ æ£‹ç›˜æ·±æ‹·è´äº†ï¼Œæœç´¢æ ‘ä¹Ÿè§£è€¦äº†å—ï¼Ÿ
âŒ ä¸ï¼æœç´¢æ ‘æ˜¯å…¨å±€å…±äº«çš„ï¼

åŒä¸€è½å­æ—¶é—´æ­¥ï¼š
  æ£‹ç›˜çŠ¶æ€ï¼šæ¯æ¬¡æ¨æ¼”éƒ½æ·±æ‹·è´ âœ“
  æœç´¢æ ‘ï¼šå…¨å±€å…±äº«ï¼Œä¸€ç›´åœ¨åŒä¸€æ£µæ ‘ä¸Šæ¨æ¼” âœ“

ç»“æœï¼š
  ç¬¬ N æ¬¡æ¨æ¼”æ‰©å±•äº†èŠ‚ç‚¹ A
  ç¬¬ N+1 æ¬¡æ¨æ¼”çœ‹åˆ°çš„ A å·²ç»ä¸æ˜¯å¶å­èŠ‚ç‚¹äº†
```

### ä¸ºä»€ä¹ˆè¿™æ ·è®¾è®¡ï¼Ÿ

- **å¢é‡å¼æ¢ç´¢** - é€æ­¥å®Œå–„æœç´¢æ ‘
- **ä¿¡æ¯å¤ç”¨** - åç»­æ¨æ¼”åˆ©ç”¨å·²æœ‰ç»“æœ
- **æ•ˆç‡æå‡** - æ¨æ¼”æ¬¡æ•°è¶Šå¤šï¼Œå†³ç­–è¶Šå‡†ç¡®

---

## ç­–ç•¥è¯„ä¼°æœºåˆ¶

### ä¸ºä»€ä¹ˆéœ€è¦é‡ç½®æœç´¢æ ‘ï¼Ÿ

#### è‡ªæˆ‘å¯¹å¼ˆï¼ˆä¸é‡ç½®ï¼‰
```
ç©å®¶1 vs ç©å®¶2 (åŒä¸€æ¨¡å‹)
â†’ å…ˆéªŒçŸ¥è¯†ç›¸åŒ
â†’ æœç´¢æ ‘å¯ä»¥å¤ç”¨ âœ“
â†’ æé«˜æ•ˆç‡
```

#### ç­–ç•¥è¯„ä¼°ï¼ˆå¿…é¡»é‡ç½®ï¼‰
```
AlphaZero vs Pure MCTS
â†’ å…ˆéªŒçŸ¥è¯†å®Œå…¨ä¸åŒ
â†’ ä¸æ˜¯åŒä¸€ä¸ª"å¸ˆçˆ¶"æ•™çš„
â†’ å¿…é¡»é‡ç½®æœç´¢æ ‘ âœ“
â†’ ç¡®ä¿è¯„ä¼°å‡†ç¡®
```

---

# ç¬¬äº”éƒ¨åˆ†ï¼šå·¥ç¨‹å®ç°

---

## é¡¹ç›®æ¶æ„

```
AlphaZero_Gomoku_Pygame/
â”œâ”€â”€ env/              # æ¸¸æˆç¯å¢ƒ
â”‚   â”œâ”€â”€ board.py     # æ£‹ç›˜é€»è¾‘
â”‚   â”œâ”€â”€ game.py      # æ¸¸æˆæ§åˆ¶
â”‚   â””â”€â”€ pygameDisplay.py  # å¯è§†åŒ–
â”œâ”€â”€ player/           # ç©å®¶æ¨¡å—
â”‚   â”œâ”€â”€ MCTSPlayer.py     # AlphaZeroç©å®¶
â”‚   â”œâ”€â”€ mcts_pure.py      # çº¯MCTS
â”‚   â””â”€â”€ Human.py          # äººç±»ç©å®¶
â”œâ”€â”€ model/            # ç¥ç»ç½‘ç»œ
â”‚   â””â”€â”€ policy_value_net_pytorch.py
â”œâ”€â”€ infer/            # æ¨ç†
â”‚   â””â”€â”€ infer_human_Ai_play.py
â””â”€â”€ train.py          # è®­ç»ƒä¸»ç¨‹åº
```

---

## æ ¸å¿ƒç±»ï¼šTrainPipeline

### ä¸»è¦æ–¹æ³•

```python
class TrainPipeline:
    def __init__(self, init_model=None)
        # åˆå§‹åŒ–ç½‘ç»œã€æ¸¸æˆç¯å¢ƒã€è¶…å‚æ•°

    def get_aug_data(self, play_data)
        # æ•°æ®å¢å¼ºï¼šæ—‹è½¬+ç¿»è½¬

    def collect_selfplay_data(self, n_games=1)
        # è‡ªæˆ‘å¯¹å¼ˆæ”¶é›†æ•°æ®

    def policy_update(self)
        # ç­–ç•¥æ›´æ–°ï¼šæ¢¯åº¦ä¸‹é™è®­ç»ƒ

    def policy_evaluate(self, n_games=10)
        # ç­–ç•¥è¯„ä¼°ï¼švs çº¯MCTS

    def run(self)
        # è®­ç»ƒä¸»å¾ªç¯
```

---

## å…³é”®æŠ€æœ¯å®ç°

### 1. KL æ•£åº¦çº¦æŸ

```python
# è®¡ç®—æ–°æ—§ç­–ç•¥çš„ KL æ•£åº¦
kl = np.mean(np.sum(old_probs *
    (np.log(old_probs + 1e-10) - np.log(new_probs + 1e-10)),
    axis=1))

# æ—©åœï¼šé˜²æ­¢ç­–ç•¥å˜åŒ–è¿‡å¤§
if kl > self.kl_targ * 4:
    break

# è‡ªé€‚åº”å­¦ä¹ ç‡
if kl > self.kl_targ * 2:
    self.lr_multiplier /= 1.5  # é™ä½
elif kl < self.kl_targ / 2:
    self.lr_multiplier *= 1.5  # æé«˜
```

---

## å…³é”®æŠ€æœ¯å®ç°

### 2. è¯¾ç¨‹å­¦ä¹ 

```python
if win_ratio > self.best_win_ratio:
    print(f"æ–°çš„æœ€ä½³èƒœç‡: {win_ratio}")
    self.best_win_ratio = win_ratio
    # ä¿å­˜æœ€ä½³æ¨¡å‹
    self.policy_value_net.save_model('best_policy.model')

    # éš¾åº¦é€’å¢
    if self.best_win_ratio == 1.0 and \
       self.pure_mcts_playout_num < 5000:
        self.pure_mcts_playout_num += 1000  # æå‡å¯¹æ‰‹éš¾åº¦
        self.best_win_ratio = 0.0           # é‡ç½®
```

**æ•ˆæœ**ï¼šé€æ­¥æé«˜å¯¹æ‰‹éš¾åº¦ï¼Œé¿å…è¿‡æ‹Ÿåˆ

---

## æ€§èƒ½ä¼˜åŒ–

### è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–

```python
# å…³é—­å¯è§†åŒ–
is_shown_pygame = 0

# ç¦ç”¨æ¨æ¼”å¯è§†åŒ–
visualize_playout = False

# è°ƒæ•´æ¨¡æ‹Ÿæ¬¡æ•°ï¼ˆè´¨é‡ vs é€Ÿåº¦ï¼‰
n_playout = 400   # å¿«é€Ÿå®éªŒ
n_playout = 1000  # æ ‡å‡†è®­ç»ƒ
n_playout = 1600  # é«˜è´¨é‡è®­ç»ƒ
```

### ç¡¬ä»¶å»ºè®®

- **CPU**ï¼šè¶Šå¼ºè¶Šå¥½ï¼ˆMCTS æ˜¯ CPU å¯†é›†å‹ï¼‰
- **GPU**ï¼šåŠ é€Ÿç¥ç»ç½‘ç»œè®­ç»ƒ
- **å†…å­˜**ï¼š8GB+ ï¼ˆå­˜å‚¨ç»éªŒå›æ”¾ç¼“å†²åŒºï¼‰

---

# ç¬¬å…­éƒ¨åˆ†ï¼šå®æˆ˜æ¼”ç¤º

---

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
pip install torch pygame numpy
```

### 2. äººæœºå¯¹å¼ˆ

```bash
cd infer
python infer_human_Ai_play.py
```

### 3. è®­ç»ƒæ¨¡å‹

```bash
python train.py
```

---

## é…ç½®é€‰é¡¹

### è°ƒæ•´ AI å¼ºåº¦

```python
# åœ¨ infer/infer_human_Ai_play.py ä¸­ä¿®æ”¹

n_playout = 400      # åˆçº§ï¼Œæ€è€ƒå¿«
n_playout = 1000     # ä¸­é«˜çº§ï¼Œæ¨è
n_playout = 1600     # ä¸“ä¸šçº§ï¼Œæ€è€ƒæ…¢ä½†å¼º
```

### è®­ç»ƒé…ç½®

```python
# åœ¨ train.py ä¸­ä¿®æ”¹

# ä»å¤´è®­ç»ƒ
training_pipeline = TrainPipeline()

# æ–­ç‚¹ç»­è®­
training_pipeline = TrainPipeline(
    init_model='best_policy_8_8_5.model'
)
```

---

## æ“ä½œè¯´æ˜

### æ¸¸æˆç•Œé¢

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             â”‚             â”‚
â”‚   æ£‹ç›˜åŒº    â”‚  æœç´¢æ ‘åŒº   â”‚
â”‚  (8Ã—8)     â”‚ (MCTSå¯è§†åŒ–) â”‚
â”‚             â”‚             â”‚
â”‚  ç‚¹å‡»è½å­    â”‚  å®æ—¶æ›´æ–°   â”‚
â”‚             â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ§åˆ¶æ–¹å¼

- **é¼ æ ‡ç‚¹å‡»** - äººç±»è½å­
- **é‡å¼€æŒ‰é’®** - é‡æ–°å¼€å§‹
- **ESC** - é€€å‡ºæ¸¸æˆ

---

## å¯è§†åŒ–è¯´æ˜

### MCTS æœç´¢æ ‘

```
èŠ‚ç‚¹å¤§å° â†’ è®¿é—®æ¬¡æ•°
  å¤§åœ†åœˆ = è®¿é—®æ¬¡æ•°å¤š = é‡è¦åˆ†æ”¯
  å°åœ†åœˆ = è®¿é—®æ¬¡æ•°å°‘ = æ¢ç´¢è¾ƒå°‘

èŠ‚ç‚¹é¢œè‰² â†’ èƒœç‡è¯„ä¼°
  æ·±è‰² = é«˜èƒœç‡ = å¥½ä½ç½®
  æµ…è‰² = ä½èƒœç‡ = å·®ä½ç½®

æ•°å­—æ ‡æ³¨ â†’ è®¿é—®ç»Ÿè®¡
  æ˜¾ç¤ºæ¯ä¸ªå€™é€‰ä½ç½®çš„è®¿é—®æ¬¡æ•°
```

---

# æ€»ç»“ä¸å±•æœ›

---

## æ ¸å¿ƒè¦ç‚¹å›é¡¾

### ğŸ§  ç®—æ³•æ ¸å¿ƒ

1. **MCTS + æ·±åº¦å­¦ä¹ ** - æœç´¢ä¸è¯„ä¼°çš„å®Œç¾ç»“åˆ
2. **Negamax æ¡†æ¶** - ä¼˜é›…çš„ä»·å€¼ä¼ æ’­æœºåˆ¶
3. **è‡ªæˆ‘å¯¹å¼ˆ** - æ— éœ€äººç±»çŸ¥è¯†çš„å­¦ä¹ æ–¹å¼

### ğŸ› ï¸ å·¥ç¨‹äº®ç‚¹

1. **å®Œæ•´å¯è§†åŒ–** - MCTS æ ‘å®æ—¶å±•ç¤º
2. **è®­ç»ƒç›‘æ§** - KL æ•£åº¦ã€è¯¾ç¨‹å­¦ä¹ 
3. **æ¨¡å—åŒ–è®¾è®¡** - æ¸…æ™°çš„æ¶æ„

---

## å­¦ä¹ è·¯å¾„å»ºè®®

### ğŸ“š ç†è®ºå­¦ä¹ 

1. å¼ºåŒ–å­¦ä¹ åŸºç¡€ï¼ˆSutton & Bartoï¼‰
2. MCTS ç®—æ³•åŸç†
3. æ·±åº¦å­¦ä¹ åŸºç¡€ï¼ˆCNNï¼‰
4. AlphaGo/AlphaZero è®ºæ–‡

### ğŸ’» å®è·µå»ºè®®

1. è¿è¡Œé¡¹ç›®ï¼Œè§‚å¯Ÿè®­ç»ƒè¿‡ç¨‹
2. è°ƒæ•´è¶…å‚æ•°ï¼Œè§‚å¯Ÿå½±å“
3. å°è¯•ä¸åŒçš„æ£‹ç›˜å¤§å°
4. å®ç°å…¶ä»–æ£‹ç±»æ¸¸æˆï¼ˆäº”å­æ£‹ â†’ å›´æ£‹ï¼‰

---

## æ‰©å±•æ–¹å‘

### ğŸš€ ç®—æ³•ä¼˜åŒ–

- **å¹¶è¡ŒåŒ–** - å¤šè¿›ç¨‹è‡ªæˆ‘å¯¹å¼ˆ
- **åˆ†å¸ƒå¼è®­ç»ƒ** - å¤šæœºå™¨ååŒ
- **ç¥ç»ç½‘ç»œæ¶æ„** - ResNet â†’ Transformer
- **MCTS æ”¹è¿›** - PUCT â†’ AlphaGo Zero

### ğŸ® åŠŸèƒ½æ‰©å±•

- **åœ¨çº¿å¯¹æˆ˜** - æ”¯æŒè”æœºå¯¹å¼ˆ
- **æ£‹è°±åˆ†æ** - å¤ç›˜ä¸è§£è¯´
- **éš¾åº¦åˆ†çº§** - å¤šä¸ª AI ç­‰çº§
- **ç§»åŠ¨ç«¯é€‚é…** - iOS/Android ç‰ˆæœ¬

---

## Q&A å¸¸è§é—®é¢˜

### Q1: è®­ç»ƒå¤šä¹…èƒ½å¾—åˆ°å¯ç”¨æ¨¡å‹ï¼Ÿ
**A**: å–å†³äºç¡¬ä»¶å’Œé…ç½®ï¼Œä¸€èˆ¬éœ€è¦ 1000 è½®è‡ªæˆ‘å¯¹å¼ˆï¼ˆæ•°å°æ—¶åˆ°æ•°å¤©ï¼‰

### Q2: ä¸ºä»€ä¹ˆæˆ‘çš„æ¨¡å‹ä¸æ”¶æ•›ï¼Ÿ
**A**: æ£€æŸ¥å­¦ä¹ ç‡ã€KL æ•£åº¦ã€æ•°æ®ç¼“å†²åŒºå¤§å°ï¼Œç¡®ä¿è¶…å‚æ•°åˆç†

### Q3: å¦‚ä½•æé«˜ AI å¼ºåº¦ï¼Ÿ
**A**: å¢åŠ è®­ç»ƒè½®æ•°ã€æé«˜ n_playoutã€ä½¿ç”¨æ›´å¤§çš„ç¥ç»ç½‘ç»œ

### Q4: èƒ½ç”¨åœ¨å…¶ä»–æ¸¸æˆå—ï¼Ÿ
**A**: å¯ä»¥ï¼åªéœ€ä¿®æ”¹æ¸¸æˆè§„åˆ™å’Œè¾“å…¥ç‰¹å¾ï¼Œç®—æ³•æ¡†æ¶é€šç”¨

---

## å‚è€ƒèµ„æ–™

### ğŸ“– è®ºæ–‡

1. Mastering Chess and Shogi by Self-Play (AlphaZero, 2017)
2. Mastering the game of Go without human knowledge (AlphaGo Zero, 2017)

### ğŸ”— ç›¸å…³é“¾æ¥

- **é¡¹ç›®ä»“åº“**: [GitHub - AlphaZero_Gomoku_Pygame](https://github.com/helloworld729/AlphaZero_Gomoku_Pygame)
- **è¯¦ç»†æ–‡æ¡£**: README.md, train.md, æ ¸å¿ƒæ¦‚å¿µç¬”è®°.md
- **DeepMind Blog**: https://deepmind.com/blog

### ğŸ“§ è”ç³»æ–¹å¼

æ¬¢è¿æ Issue å’Œ Pull Requestï¼

---

# è°¢è°¢ï¼

## ğŸ¯ å¼€å§‹ä½ çš„ AlphaZero ä¹‹æ—…å§ï¼

```python
if __name__ == '__main__':
    training_pipeline = TrainPipeline()
    training_pipeline.run()

    # é€šå¾€è¶…äºº AI çš„é“è·¯ï¼Œä»è¿™é‡Œå¼€å§‹ï¼
```

**ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼** ğŸš€

---

