pygame 2.6.1 (SDL 2.28.4, Python 3.8.20)
Hello from the pygame community. https://www.pygame.org/contribute.html
TrainPipeline:init: 初始化: TrainPipeline
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1, episode_len:13
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2, episode_len:13
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:3, episode_len:13
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:4, episode_len:13
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:5, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00136,lr_multiplier:1.500,loss:1.8622703552246094,entropy:1.9063247442245483,explained_var_old:0.985,explained_var_new:0.994
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:6, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00226,lr_multiplier:2.250,loss:1.8735005855560303,entropy:1.910720705986023,explained_var_old:0.995,explained_var_new:0.998
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:7, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00242,lr_multiplier:3.375,loss:1.8175592422485352,entropy:1.8643625974655151,explained_var_old:0.998,explained_var_new:0.999
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:8, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00344,lr_multiplier:5.062,loss:1.8152072429656982,entropy:1.8624106645584106,explained_var_old:0.999,explained_var_new:0.999
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:9, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00697,lr_multiplier:7.594,loss:1.8512378931045532,entropy:1.926601529121399,explained_var_old:0.999,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:10, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00807,lr_multiplier:11.391,loss:1.77761971950531,entropy:1.8011869192123413,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:11, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00891,lr_multiplier:11.391,loss:1.7571218013763428,entropy:1.7611005306243896,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:12, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00641,lr_multiplier:11.391,loss:1.787526249885559,entropy:1.7868844270706177,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:13, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00383,lr_multiplier:11.391,loss:1.7431726455688477,entropy:1.7336827516555786,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:14, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00372,lr_multiplier:11.391,loss:1.762284755706787,entropy:1.7638086080551147,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:15, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00273,lr_multiplier:11.391,loss:1.7600984573364258,entropy:1.7590211629867554,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:16, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00312,lr_multiplier:11.391,loss:1.7161400318145752,entropy:1.7059510946273804,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:17, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00244,lr_multiplier:11.391,loss:1.7874020338058472,entropy:1.7970211505889893,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:18, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00219,lr_multiplier:11.391,loss:1.717727780342102,entropy:1.7189750671386719,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:19, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00188,lr_multiplier:11.391,loss:1.7640565633773804,entropy:1.7623577117919922,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:20, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00143,lr_multiplier:11.391,loss:1.7421513795852661,entropy:1.748935580253601,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:21, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00203,lr_multiplier:11.391,loss:1.728899359703064,entropy:1.7365304231643677,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:22, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00204,lr_multiplier:11.391,loss:1.6459383964538574,entropy:1.6530840396881104,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:23, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00128,lr_multiplier:11.391,loss:1.738010287284851,entropy:1.743637204170227,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:24, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00230,lr_multiplier:11.391,loss:1.6831669807434082,entropy:1.6862430572509766,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:25, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00167,lr_multiplier:11.391,loss:1.7134509086608887,entropy:1.7163944244384766,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:26, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00204,lr_multiplier:11.391,loss:1.7354143857955933,entropy:1.7400811910629272,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:27, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00255,lr_multiplier:11.391,loss:1.6833759546279907,entropy:1.6853070259094238,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:28, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00261,lr_multiplier:11.391,loss:1.6635591983795166,entropy:1.6633996963500977,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:29, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00262,lr_multiplier:11.391,loss:1.7136244773864746,entropy:1.7145717144012451,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:30, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00221,lr_multiplier:11.391,loss:1.7220538854599,entropy:1.7318603992462158,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:31, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00191,lr_multiplier:11.391,loss:1.7184686660766602,entropy:1.7143057584762573,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:32, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00222,lr_multiplier:11.391,loss:1.7167904376983643,entropy:1.7186145782470703,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:33, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00196,lr_multiplier:11.391,loss:1.6804031133651733,entropy:1.6842089891433716,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:34, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00194,lr_multiplier:11.391,loss:1.7393831014633179,entropy:1.7412444353103638,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:35, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00178,lr_multiplier:11.391,loss:1.7231677770614624,entropy:1.7264883518218994,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:36, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00149,lr_multiplier:11.391,loss:1.7578150033950806,entropy:1.7605749368667603,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:37, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00177,lr_multiplier:11.391,loss:1.684549331665039,entropy:1.689008355140686,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:38, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00170,lr_multiplier:11.391,loss:1.67815101146698,entropy:1.6817264556884766,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:39, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00246,lr_multiplier:11.391,loss:1.7042055130004883,entropy:1.7063226699829102,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:40, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00174,lr_multiplier:11.391,loss:1.6320840120315552,entropy:1.6313989162445068,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:41, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00169,lr_multiplier:11.391,loss:1.6992930173873901,entropy:1.7060905694961548,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:42, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00216,lr_multiplier:11.391,loss:1.7480111122131348,entropy:1.7464818954467773,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:43, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00148,lr_multiplier:11.391,loss:1.6783456802368164,entropy:1.6793006658554077,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:44, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00156,lr_multiplier:11.391,loss:1.725667953491211,entropy:1.7355271577835083,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:45, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00200,lr_multiplier:11.391,loss:1.7043375968933105,entropy:1.7021135091781616,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:46, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00249,lr_multiplier:11.391,loss:1.6551538705825806,entropy:1.6550151109695435,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:47, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.00230,lr_multiplier:11.391,loss:1.653599500656128,entropy:1.6548571586608887,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:48, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00229,lr_multiplier:11.391,loss:1.6276026964187622,entropy:1.6335327625274658,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:49, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00196,lr_multiplier:11.391,loss:1.6654882431030273,entropy:1.6677019596099854,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:50, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00217,lr_multiplier:11.391,loss:1.7187929153442383,entropy:1.7258226871490479,explained_var_old:1.000,explained_var_new:1.000
已经训练: 50轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 7, lose: 3, tie:0
相较于MCTS@1000, 截至目前的最佳胜率=0.7 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:51, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00187,lr_multiplier:11.391,loss:1.70151686668396,entropy:1.6970936059951782,explained_var_old:0.998,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:52, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00179,lr_multiplier:11.391,loss:1.7313344478607178,entropy:1.7344377040863037,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:53, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00187,lr_multiplier:11.391,loss:1.707025170326233,entropy:1.7091008424758911,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:54, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00198,lr_multiplier:11.391,loss:1.702094554901123,entropy:1.7048993110656738,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:55, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00160,lr_multiplier:11.391,loss:1.6129403114318848,entropy:1.6155223846435547,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:56, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00234,lr_multiplier:11.391,loss:1.6963527202606201,entropy:1.6963837146759033,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:57, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00219,lr_multiplier:11.391,loss:1.6859073638916016,entropy:1.6853983402252197,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:58, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00315,lr_multiplier:11.391,loss:1.6658705472946167,entropy:1.6760472059249878,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:59, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00263,lr_multiplier:11.391,loss:1.6179606914520264,entropy:1.6199811697006226,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:60, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00269,lr_multiplier:11.391,loss:1.6728206872940063,entropy:1.675350308418274,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:61, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00270,lr_multiplier:11.391,loss:1.6373275518417358,entropy:1.6356165409088135,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:62, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00272,lr_multiplier:11.391,loss:1.6916195154190063,entropy:1.69642972946167,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:63, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00231,lr_multiplier:11.391,loss:1.7084976434707642,entropy:1.7221779823303223,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:64, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00288,lr_multiplier:11.391,loss:1.668473482131958,entropy:1.6650819778442383,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:65, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00212,lr_multiplier:11.391,loss:1.6559109687805176,entropy:1.6552499532699585,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:66, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00220,lr_multiplier:11.391,loss:1.6197710037231445,entropy:1.6236768960952759,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:67, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00253,lr_multiplier:11.391,loss:1.676619291305542,entropy:1.6830649375915527,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:68, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00258,lr_multiplier:11.391,loss:1.6259922981262207,entropy:1.6252703666687012,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:69, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00161,lr_multiplier:11.391,loss:1.5695573091506958,entropy:1.574218511581421,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:70, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00167,lr_multiplier:11.391,loss:1.6270747184753418,entropy:1.6315714120864868,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:71, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00148,lr_multiplier:11.391,loss:1.7064740657806396,entropy:1.7038958072662354,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:72, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00192,lr_multiplier:11.391,loss:1.631508231163025,entropy:1.6316596269607544,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:73, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00146,lr_multiplier:11.391,loss:1.696038007736206,entropy:1.6999237537384033,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:74, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00188,lr_multiplier:11.391,loss:1.6700544357299805,entropy:1.671965479850769,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:75, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00216,lr_multiplier:11.391,loss:1.6421194076538086,entropy:1.6472580432891846,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:76, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00157,lr_multiplier:11.391,loss:1.6742308139801025,entropy:1.6713471412658691,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:77, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00216,lr_multiplier:11.391,loss:1.6907949447631836,entropy:1.6952595710754395,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:78, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00185,lr_multiplier:11.391,loss:1.6305184364318848,entropy:1.6338990926742554,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:79, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00202,lr_multiplier:11.391,loss:1.7421053647994995,entropy:1.7466762065887451,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:80, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00179,lr_multiplier:11.391,loss:1.682494044303894,entropy:1.6807273626327515,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:81, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00191,lr_multiplier:11.391,loss:1.6574814319610596,entropy:1.6609830856323242,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:82, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00186,lr_multiplier:11.391,loss:1.6492999792099,entropy:1.6515592336654663,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:83, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00321,lr_multiplier:11.391,loss:1.6294307708740234,entropy:1.637001633644104,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:84, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00292,lr_multiplier:11.391,loss:1.6915143728256226,entropy:1.6912838220596313,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:85, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00290,lr_multiplier:11.391,loss:1.6652264595031738,entropy:1.6665911674499512,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:86, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00240,lr_multiplier:11.391,loss:1.6405850648880005,entropy:1.6516181230545044,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:87, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00185,lr_multiplier:11.391,loss:1.671468734741211,entropy:1.6680185794830322,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:88, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00156,lr_multiplier:11.391,loss:1.6491369009017944,entropy:1.655043363571167,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:89, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00200,lr_multiplier:11.391,loss:1.6554019451141357,entropy:1.6627674102783203,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:90, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00188,lr_multiplier:11.391,loss:1.5867018699645996,entropy:1.5855716466903687,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:91, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00182,lr_multiplier:11.391,loss:1.6368306875228882,entropy:1.6337538957595825,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:92, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00168,lr_multiplier:11.391,loss:1.6358522176742554,entropy:1.6387401819229126,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:93, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00231,lr_multiplier:11.391,loss:1.669655442237854,entropy:1.6722592115402222,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:94, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00316,lr_multiplier:11.391,loss:1.658921241760254,entropy:1.6568653583526611,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:95, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00314,lr_multiplier:11.391,loss:1.7246049642562866,entropy:1.7353684902191162,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:96, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00265,lr_multiplier:11.391,loss:1.6246378421783447,entropy:1.6185158491134644,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:97, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00262,lr_multiplier:11.391,loss:1.6683069467544556,entropy:1.6688439846038818,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:98, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00233,lr_multiplier:11.391,loss:1.6386014223098755,entropy:1.6432757377624512,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:99, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00197,lr_multiplier:11.391,loss:1.6985262632369995,entropy:1.699016809463501,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:100, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00216,lr_multiplier:11.391,loss:1.6924299001693726,entropy:1.6947438716888428,explained_var_old:1.000,explained_var_new:1.000
已经训练: 100轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 7, lose: 3, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:101, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00240,lr_multiplier:11.391,loss:1.615726351737976,entropy:1.6219831705093384,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:102, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00175,lr_multiplier:11.391,loss:1.6685343980789185,entropy:1.6676714420318604,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:103, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00331,lr_multiplier:11.391,loss:1.6900734901428223,entropy:1.6958097219467163,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:104, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00245,lr_multiplier:11.391,loss:1.6461451053619385,entropy:1.6476356983184814,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:105, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00264,lr_multiplier:11.391,loss:1.590942144393921,entropy:1.594283103942871,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:106, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00231,lr_multiplier:11.391,loss:1.6176480054855347,entropy:1.6200134754180908,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:107, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00152,lr_multiplier:11.391,loss:1.6846935749053955,entropy:1.6886547803878784,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:108, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00129,lr_multiplier:11.391,loss:1.6529154777526855,entropy:1.6539695262908936,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:109, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00191,lr_multiplier:11.391,loss:1.6418107748031616,entropy:1.6443272829055786,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:110, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00118,lr_multiplier:11.391,loss:1.6428755521774292,entropy:1.6449652910232544,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:111, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00206,lr_multiplier:11.391,loss:1.695294737815857,entropy:1.6977320909500122,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:112, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00190,lr_multiplier:11.391,loss:1.5942860841751099,entropy:1.5964397192001343,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:113, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00178,lr_multiplier:11.391,loss:1.6325238943099976,entropy:1.634671688079834,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:114, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00151,lr_multiplier:11.391,loss:1.7049527168273926,entropy:1.7104922533035278,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:115, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00204,lr_multiplier:11.391,loss:1.595592975616455,entropy:1.5963724851608276,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:116, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00173,lr_multiplier:11.391,loss:1.618462085723877,entropy:1.6195027828216553,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:117, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00184,lr_multiplier:11.391,loss:1.6416274309158325,entropy:1.6464247703552246,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:118, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00129,lr_multiplier:11.391,loss:1.6290233135223389,entropy:1.6305629014968872,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:119, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00172,lr_multiplier:11.391,loss:1.6751105785369873,entropy:1.6798075437545776,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:120, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00143,lr_multiplier:11.391,loss:1.5863449573516846,entropy:1.5870494842529297,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:121, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00163,lr_multiplier:11.391,loss:1.6548517942428589,entropy:1.6561542749404907,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:122, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00110,lr_multiplier:11.391,loss:1.6058850288391113,entropy:1.6081688404083252,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:123, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00165,lr_multiplier:11.391,loss:1.6228135824203491,entropy:1.620943546295166,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:124, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00131,lr_multiplier:11.391,loss:1.6940126419067383,entropy:1.6958837509155273,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:125, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00136,lr_multiplier:11.391,loss:1.692188024520874,entropy:1.692823052406311,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:126, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00125,lr_multiplier:11.391,loss:1.652502179145813,entropy:1.6532360315322876,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:127, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00145,lr_multiplier:11.391,loss:1.6385222673416138,entropy:1.630144715309143,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:128, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00130,lr_multiplier:11.391,loss:1.6937121152877808,entropy:1.6902554035186768,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:129, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00137,lr_multiplier:11.391,loss:1.6292316913604736,entropy:1.6295232772827148,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:130, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00120,lr_multiplier:11.391,loss:1.5992695093154907,entropy:1.6010972261428833,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:131, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00103,lr_multiplier:11.391,loss:1.7103521823883057,entropy:1.7164462804794312,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:132, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00143,lr_multiplier:11.391,loss:1.6250312328338623,entropy:1.6268702745437622,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:133, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00114,lr_multiplier:11.391,loss:1.6787314414978027,entropy:1.6788750886917114,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:134, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00120,lr_multiplier:11.391,loss:1.682604193687439,entropy:1.6846598386764526,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:135, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00136,lr_multiplier:11.391,loss:1.6270771026611328,entropy:1.626808762550354,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:136, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00201,lr_multiplier:11.391,loss:1.6359328031539917,entropy:1.6441255807876587,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:137, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00222,lr_multiplier:11.391,loss:1.6300963163375854,entropy:1.6330655813217163,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:138, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00157,lr_multiplier:11.391,loss:1.6308438777923584,entropy:1.63887619972229,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:139, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00122,lr_multiplier:11.391,loss:1.6588338613510132,entropy:1.6674554347991943,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:140, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00132,lr_multiplier:11.391,loss:1.579236626625061,entropy:1.579715371131897,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:141, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00149,lr_multiplier:11.391,loss:1.5803234577178955,entropy:1.5750865936279297,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:142, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00160,lr_multiplier:11.391,loss:1.6697182655334473,entropy:1.67401123046875,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:143, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00199,lr_multiplier:11.391,loss:1.654629111289978,entropy:1.6588141918182373,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:144, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00181,lr_multiplier:11.391,loss:1.6129846572875977,entropy:1.610034704208374,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:145, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00129,lr_multiplier:11.391,loss:1.6465221643447876,entropy:1.645809292793274,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:146, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00127,lr_multiplier:11.391,loss:1.625133991241455,entropy:1.63052499294281,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:147, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00097,lr_multiplier:11.391,loss:1.6263153553009033,entropy:1.6305484771728516,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:148, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00106,lr_multiplier:11.391,loss:1.6313462257385254,entropy:1.634467363357544,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:149, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00103,lr_multiplier:11.391,loss:1.6440526247024536,entropy:1.6525194644927979,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:150, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00091,lr_multiplier:11.391,loss:1.658869743347168,entropy:1.66573965549469,explained_var_old:1.000,explained_var_new:1.000
已经训练: 150轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 7, lose: 3, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:151, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00121,lr_multiplier:11.391,loss:1.665745735168457,entropy:1.6685380935668945,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:152, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00124,lr_multiplier:11.391,loss:1.5965067148208618,entropy:1.5980303287506104,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:153, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00150,lr_multiplier:11.391,loss:1.6992254257202148,entropy:1.699933648109436,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:154, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00111,lr_multiplier:11.391,loss:1.663838505744934,entropy:1.6663920879364014,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:155, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00097,lr_multiplier:11.391,loss:1.6690864562988281,entropy:1.6715675592422485,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:156, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00140,lr_multiplier:11.391,loss:1.6392501592636108,entropy:1.638260006904602,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:157, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00107,lr_multiplier:11.391,loss:1.5711965560913086,entropy:1.5713870525360107,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:158, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00094,lr_multiplier:11.391,loss:1.6016660928726196,entropy:1.6035267114639282,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:159, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00116,lr_multiplier:11.391,loss:1.6256673336029053,entropy:1.6261216402053833,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:160, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00164,lr_multiplier:11.391,loss:1.6376701593399048,entropy:1.6410112380981445,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:161, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00199,lr_multiplier:11.391,loss:1.6232106685638428,entropy:1.6275091171264648,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:162, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00188,lr_multiplier:11.391,loss:1.6162816286087036,entropy:1.622445821762085,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:163, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00142,lr_multiplier:11.391,loss:1.581679105758667,entropy:1.5813742876052856,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:164, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00163,lr_multiplier:11.391,loss:1.6473268270492554,entropy:1.6438411474227905,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:165, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00192,lr_multiplier:11.391,loss:1.6705046892166138,entropy:1.6737487316131592,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:166, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00217,lr_multiplier:11.391,loss:1.666538119316101,entropy:1.667935848236084,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:167, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00150,lr_multiplier:11.391,loss:1.6525578498840332,entropy:1.6570398807525635,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:168, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00311,lr_multiplier:11.391,loss:1.652456283569336,entropy:1.5958030223846436,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:169, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00611,lr_multiplier:11.391,loss:1.6757385730743408,entropy:1.7113033533096313,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:170, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.00795,lr_multiplier:11.391,loss:1.6417018175125122,entropy:1.6701240539550781,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:171, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00229,lr_multiplier:11.391,loss:1.6817450523376465,entropy:1.7031605243682861,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:172, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00286,lr_multiplier:11.391,loss:1.6282167434692383,entropy:1.6521644592285156,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:173, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00183,lr_multiplier:11.391,loss:1.5753105878829956,entropy:1.5807403326034546,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:174, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00186,lr_multiplier:11.391,loss:1.6158380508422852,entropy:1.6326569318771362,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:175, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00112,lr_multiplier:11.391,loss:1.6433134078979492,entropy:1.6499658823013306,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:176, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00107,lr_multiplier:11.391,loss:1.6211391687393188,entropy:1.6251211166381836,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:177, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00135,lr_multiplier:11.391,loss:1.5853244066238403,entropy:1.5936298370361328,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:178, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00127,lr_multiplier:11.391,loss:1.6640801429748535,entropy:1.6674383878707886,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:179, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00236,lr_multiplier:11.391,loss:1.6097062826156616,entropy:1.6100400686264038,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:180, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00189,lr_multiplier:11.391,loss:1.6023614406585693,entropy:1.6079044342041016,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:181, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00146,lr_multiplier:11.391,loss:1.6004666090011597,entropy:1.6052381992340088,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:182, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00103,lr_multiplier:11.391,loss:1.6448180675506592,entropy:1.6460826396942139,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:183, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00112,lr_multiplier:11.391,loss:1.5851081609725952,entropy:1.585993766784668,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:184, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00127,lr_multiplier:11.391,loss:1.6394339799880981,entropy:1.6449791193008423,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:185, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00092,lr_multiplier:11.391,loss:1.6623907089233398,entropy:1.6669330596923828,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:186, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00097,lr_multiplier:11.391,loss:1.6740443706512451,entropy:1.6761575937271118,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:187, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00154,lr_multiplier:11.391,loss:1.6237505674362183,entropy:1.6294960975646973,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:188, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00228,lr_multiplier:11.391,loss:1.6563197374343872,entropy:1.6553199291229248,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:189, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00208,lr_multiplier:11.391,loss:1.584240198135376,entropy:1.5923508405685425,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:190, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00203,lr_multiplier:11.391,loss:1.708053469657898,entropy:1.707637071609497,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:191, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00135,lr_multiplier:11.391,loss:1.6537377834320068,entropy:1.6569963693618774,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:192, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00127,lr_multiplier:11.391,loss:1.5991135835647583,entropy:1.6021589040756226,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:193, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00181,lr_multiplier:11.391,loss:1.5726640224456787,entropy:1.5776716470718384,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:194, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00123,lr_multiplier:11.391,loss:1.6322319507598877,entropy:1.6300972700119019,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:195, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00136,lr_multiplier:11.391,loss:1.6966384649276733,entropy:1.697717308998108,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:196, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00110,lr_multiplier:11.391,loss:1.609288215637207,entropy:1.6117606163024902,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:197, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00139,lr_multiplier:11.391,loss:1.661714792251587,entropy:1.6634622812271118,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:198, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00189,lr_multiplier:11.391,loss:1.615764856338501,entropy:1.6157212257385254,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:199, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00147,lr_multiplier:11.391,loss:1.596877932548523,entropy:1.5984463691711426,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:200, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00143,lr_multiplier:11.391,loss:1.5778952836990356,entropy:1.5842865705490112,explained_var_old:1.000,explained_var_new:1.000
已经训练: 200轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
num_playouts:1000, win: 6, lose: 4, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:201, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00110,lr_multiplier:11.391,loss:1.534791111946106,entropy:1.5366946458816528,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:202, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00119,lr_multiplier:11.391,loss:1.5927927494049072,entropy:1.5942882299423218,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:203, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00139,lr_multiplier:11.391,loss:1.66255784034729,entropy:1.6647007465362549,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:204, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00102,lr_multiplier:11.391,loss:1.594759464263916,entropy:1.5997483730316162,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:205, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00134,lr_multiplier:11.391,loss:1.6132575273513794,entropy:1.6176197528839111,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:206, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00150,lr_multiplier:11.391,loss:1.622531771659851,entropy:1.6225234270095825,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:207, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00116,lr_multiplier:11.391,loss:1.571889042854309,entropy:1.5750988721847534,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:208, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00148,lr_multiplier:11.391,loss:1.649949312210083,entropy:1.6511059999465942,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:209, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00149,lr_multiplier:11.391,loss:1.5450592041015625,entropy:1.5489012002944946,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:210, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00137,lr_multiplier:11.391,loss:1.6578619480133057,entropy:1.6611721515655518,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:211, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00138,lr_multiplier:11.391,loss:1.6340068578720093,entropy:1.6333768367767334,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:212, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00135,lr_multiplier:11.391,loss:1.5905325412750244,entropy:1.5925869941711426,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:213, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00165,lr_multiplier:11.391,loss:1.6390235424041748,entropy:1.641301155090332,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:214, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00141,lr_multiplier:11.391,loss:1.622690200805664,entropy:1.6294342279434204,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:215, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00118,lr_multiplier:11.391,loss:1.6207642555236816,entropy:1.6216078996658325,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:216, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00100,lr_multiplier:11.391,loss:1.5672246217727661,entropy:1.566575050354004,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:217, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00121,lr_multiplier:11.391,loss:1.5593565702438354,entropy:1.5625152587890625,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:218, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00125,lr_multiplier:11.391,loss:1.6092251539230347,entropy:1.6092466115951538,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:219, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.6640034914016724,entropy:1.6649742126464844,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:220, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00092,lr_multiplier:11.391,loss:1.651273250579834,entropy:1.6571650505065918,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:221, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00098,lr_multiplier:11.391,loss:1.6195237636566162,entropy:1.6221330165863037,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:222, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00088,lr_multiplier:11.391,loss:1.6393282413482666,entropy:1.6427853107452393,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:223, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00104,lr_multiplier:11.391,loss:1.570526361465454,entropy:1.5735814571380615,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:224, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00119,lr_multiplier:11.391,loss:1.6397762298583984,entropy:1.6393274068832397,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:225, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00112,lr_multiplier:11.391,loss:1.5547704696655273,entropy:1.5556106567382812,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:226, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00100,lr_multiplier:11.391,loss:1.5864191055297852,entropy:1.5907764434814453,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:227, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00128,lr_multiplier:11.391,loss:1.6266357898712158,entropy:1.626267433166504,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:228, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00110,lr_multiplier:11.391,loss:1.6143295764923096,entropy:1.6167303323745728,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:229, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00087,lr_multiplier:11.391,loss:1.626575231552124,entropy:1.6333582401275635,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:230, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00130,lr_multiplier:11.391,loss:1.582538366317749,entropy:1.5818376541137695,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:231, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00120,lr_multiplier:11.391,loss:1.5748121738433838,entropy:1.5759421586990356,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:232, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00120,lr_multiplier:11.391,loss:1.599370002746582,entropy:1.6003369092941284,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:233, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00149,lr_multiplier:11.391,loss:1.5463701486587524,entropy:1.5501426458358765,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:234, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00119,lr_multiplier:11.391,loss:1.5619157552719116,entropy:1.5660374164581299,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:235, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00113,lr_multiplier:11.391,loss:1.6033920049667358,entropy:1.6055805683135986,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:236, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00111,lr_multiplier:11.391,loss:1.5627659559249878,entropy:1.5653514862060547,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:237, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00123,lr_multiplier:11.391,loss:1.6314040422439575,entropy:1.6323392391204834,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:238, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00106,lr_multiplier:11.391,loss:1.6072509288787842,entropy:1.609541654586792,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:239, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00136,lr_multiplier:11.391,loss:1.6410801410675049,entropy:1.6450936794281006,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:240, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00091,lr_multiplier:11.391,loss:1.5992745161056519,entropy:1.600619912147522,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:241, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00118,lr_multiplier:11.391,loss:1.6161235570907593,entropy:1.6179078817367554,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:242, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00113,lr_multiplier:11.391,loss:1.5951436758041382,entropy:1.5974615812301636,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:243, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00108,lr_multiplier:11.391,loss:1.6136282682418823,entropy:1.6144872903823853,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:244, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00101,lr_multiplier:11.391,loss:1.584409475326538,entropy:1.5845324993133545,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:245, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00072,lr_multiplier:11.391,loss:1.615989089012146,entropy:1.617278814315796,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:246, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00099,lr_multiplier:11.391,loss:1.6378213167190552,entropy:1.6413155794143677,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:247, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00107,lr_multiplier:11.391,loss:1.6061689853668213,entropy:1.605325698852539,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:248, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00105,lr_multiplier:11.391,loss:1.5771489143371582,entropy:1.581487774848938,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:249, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00095,lr_multiplier:11.391,loss:1.597474217414856,entropy:1.5964322090148926,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:250, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00109,lr_multiplier:11.391,loss:1.5734920501708984,entropy:1.5729893445968628,explained_var_old:1.000,explained_var_new:1.000
已经训练: 250轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 5, lose: 5, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:251, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00114,lr_multiplier:11.391,loss:1.660606861114502,entropy:1.6624770164489746,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:252, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00111,lr_multiplier:11.391,loss:1.6429768800735474,entropy:1.642676830291748,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:253, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00112,lr_multiplier:11.391,loss:1.6116703748703003,entropy:1.615363597869873,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:254, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00084,lr_multiplier:11.391,loss:1.622188687324524,entropy:1.6251589059829712,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:255, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00073,lr_multiplier:11.391,loss:1.6054219007492065,entropy:1.6093122959136963,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:256, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.5447907447814941,entropy:1.5481821298599243,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:257, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00094,lr_multiplier:11.391,loss:1.5661208629608154,entropy:1.56691575050354,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:258, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00108,lr_multiplier:11.391,loss:1.5851353406906128,entropy:1.586033821105957,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:259, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00128,lr_multiplier:11.391,loss:1.5270435810089111,entropy:1.529613971710205,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:260, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00112,lr_multiplier:11.391,loss:1.5920183658599854,entropy:1.5920424461364746,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:261, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00081,lr_multiplier:11.391,loss:1.644906759262085,entropy:1.6489684581756592,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:262, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00088,lr_multiplier:11.391,loss:1.6021367311477661,entropy:1.6039577722549438,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:263, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00074,lr_multiplier:11.391,loss:1.5719019174575806,entropy:1.5746941566467285,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:264, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00084,lr_multiplier:11.391,loss:1.6073180437088013,entropy:1.6104649305343628,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:265, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00073,lr_multiplier:11.391,loss:1.5769002437591553,entropy:1.5796535015106201,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:266, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.6055783033370972,entropy:1.6072794198989868,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:267, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00075,lr_multiplier:11.391,loss:1.577437162399292,entropy:1.5817756652832031,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:268, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.597511887550354,entropy:1.5986950397491455,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:269, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00065,lr_multiplier:11.391,loss:1.6192419528961182,entropy:1.6206979751586914,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:270, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.7287918329238892,entropy:1.7320728302001953,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:271, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00100,lr_multiplier:11.391,loss:1.5673478841781616,entropy:1.5650678873062134,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:272, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00073,lr_multiplier:11.391,loss:1.5586621761322021,entropy:1.5628081560134888,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:273, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00069,lr_multiplier:11.391,loss:1.6634879112243652,entropy:1.6638778448104858,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:274, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00081,lr_multiplier:11.391,loss:1.5896550416946411,entropy:1.5896159410476685,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:275, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00072,lr_multiplier:11.391,loss:1.667109727859497,entropy:1.6716771125793457,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:276, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.6056121587753296,entropy:1.6074304580688477,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:277, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00099,lr_multiplier:11.391,loss:1.5936541557312012,entropy:1.597711205482483,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:278, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00091,lr_multiplier:11.391,loss:1.5570881366729736,entropy:1.5612887144088745,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:279, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.598262906074524,entropy:1.599600076675415,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:280, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00093,lr_multiplier:11.391,loss:1.5831881761550903,entropy:1.585325002670288,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:281, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00093,lr_multiplier:11.391,loss:1.6057133674621582,entropy:1.606025218963623,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:282, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00099,lr_multiplier:11.391,loss:1.5551873445510864,entropy:1.5573370456695557,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:283, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.5971944332122803,entropy:1.599320411682129,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:284, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00078,lr_multiplier:11.391,loss:1.629058837890625,entropy:1.6344414949417114,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:285, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00064,lr_multiplier:11.391,loss:1.592747449874878,entropy:1.5926942825317383,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:286, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00102,lr_multiplier:11.391,loss:1.6644953489303589,entropy:1.6670610904693604,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:287, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00103,lr_multiplier:11.391,loss:1.6113131046295166,entropy:1.611803412437439,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:288, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00094,lr_multiplier:11.391,loss:1.5696624517440796,entropy:1.564846158027649,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:289, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00097,lr_multiplier:11.391,loss:1.5670859813690186,entropy:1.5673812627792358,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:290, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00087,lr_multiplier:11.391,loss:1.5272670984268188,entropy:1.53135347366333,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:291, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00060,lr_multiplier:11.391,loss:1.6467069387435913,entropy:1.6498820781707764,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:292, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00067,lr_multiplier:11.391,loss:1.6374059915542603,entropy:1.6421945095062256,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:293, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00074,lr_multiplier:11.391,loss:1.6131672859191895,entropy:1.6151340007781982,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:294, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.586772084236145,entropy:1.5868396759033203,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:295, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00104,lr_multiplier:11.391,loss:1.5730953216552734,entropy:1.5745913982391357,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:296, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00062,lr_multiplier:11.391,loss:1.5618772506713867,entropy:1.5674933195114136,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:297, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00091,lr_multiplier:11.391,loss:1.5566556453704834,entropy:1.5554176568984985,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:298, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00127,lr_multiplier:11.391,loss:1.6064261198043823,entropy:1.6051452159881592,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:299, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00141,lr_multiplier:11.391,loss:1.6155431270599365,entropy:1.6194119453430176,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:300, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00126,lr_multiplier:11.391,loss:1.5960969924926758,entropy:1.5949084758758545,explained_var_old:1.000,explained_var_new:1.000
已经训练: 300轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
num_playouts:1000, win: 4, lose: 6, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:301, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00126,lr_multiplier:11.391,loss:1.6138266324996948,entropy:1.611745834350586,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:302, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00130,lr_multiplier:11.391,loss:1.62409245967865,entropy:1.6331900358200073,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:303, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00081,lr_multiplier:11.391,loss:1.5535686016082764,entropy:1.5534855127334595,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:304, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.6098906993865967,entropy:1.6095563173294067,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:305, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.6562881469726562,entropy:1.658578634262085,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:306, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00077,lr_multiplier:11.391,loss:1.576989769935608,entropy:1.5804109573364258,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:307, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00076,lr_multiplier:11.391,loss:1.5935204029083252,entropy:1.5976670980453491,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:308, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00083,lr_multiplier:11.391,loss:1.6178489923477173,entropy:1.6219114065170288,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:309, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00103,lr_multiplier:11.391,loss:1.6160410642623901,entropy:1.6186376810073853,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:310, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00073,lr_multiplier:11.391,loss:1.5778367519378662,entropy:1.5774670839309692,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:311, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.6000542640686035,entropy:1.601393461227417,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:312, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00066,lr_multiplier:11.391,loss:1.5638614892959595,entropy:1.5669214725494385,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:313, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.566892385482788,entropy:1.5680196285247803,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:314, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00070,lr_multiplier:11.391,loss:1.5800288915634155,entropy:1.5824568271636963,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:315, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00081,lr_multiplier:11.391,loss:1.5620077848434448,entropy:1.565197229385376,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:316, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00075,lr_multiplier:11.391,loss:1.5808624029159546,entropy:1.5823092460632324,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:317, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00073,lr_multiplier:11.391,loss:1.6119654178619385,entropy:1.6177493333816528,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:318, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.5581696033477783,entropy:1.5622748136520386,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:319, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00105,lr_multiplier:11.391,loss:1.5993537902832031,entropy:1.6005327701568604,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:320, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00114,lr_multiplier:11.391,loss:1.6076349020004272,entropy:1.6102694272994995,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:321, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00093,lr_multiplier:11.391,loss:1.6191147565841675,entropy:1.6236757040023804,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:322, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00178,lr_multiplier:11.391,loss:1.5897237062454224,entropy:1.5976014137268066,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:323, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00098,lr_multiplier:11.391,loss:1.6095463037490845,entropy:1.614363193511963,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:324, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00098,lr_multiplier:11.391,loss:1.5972113609313965,entropy:1.5999040603637695,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:325, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.4810441732406616,entropy:1.4812344312667847,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:326, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00090,lr_multiplier:11.391,loss:1.5998812913894653,entropy:1.6035641431808472,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:327, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00090,lr_multiplier:11.391,loss:1.6445585489273071,entropy:1.646302342414856,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:328, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00101,lr_multiplier:11.391,loss:1.5786504745483398,entropy:1.5799793004989624,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:329, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00092,lr_multiplier:11.391,loss:1.631982684135437,entropy:1.6338341236114502,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:330, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.58195161819458,entropy:1.5840357542037964,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:331, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00076,lr_multiplier:11.391,loss:1.6445661783218384,entropy:1.6469368934631348,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:332, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00077,lr_multiplier:11.391,loss:1.6201281547546387,entropy:1.6221425533294678,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:333, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00066,lr_multiplier:11.391,loss:1.5917099714279175,entropy:1.590081810951233,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:334, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00075,lr_multiplier:11.391,loss:1.5792713165283203,entropy:1.5782655477523804,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:335, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00607,lr_multiplier:11.391,loss:1.5482680797576904,entropy:1.564838171005249,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:336, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00450,lr_multiplier:11.391,loss:1.5224779844284058,entropy:1.531528115272522,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:337, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00126,lr_multiplier:11.391,loss:1.604068636894226,entropy:1.5965962409973145,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:338, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00100,lr_multiplier:11.391,loss:1.5847477912902832,entropy:1.588782548904419,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:339, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.5448170900344849,entropy:1.5411368608474731,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:340, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00087,lr_multiplier:11.391,loss:1.5813541412353516,entropy:1.589266300201416,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:341, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00118,lr_multiplier:11.391,loss:1.605570673942566,entropy:1.6077284812927246,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:342, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00112,lr_multiplier:11.391,loss:1.637130618095398,entropy:1.6421291828155518,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:343, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00110,lr_multiplier:11.391,loss:1.5575859546661377,entropy:1.5629935264587402,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:344, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00083,lr_multiplier:11.391,loss:1.600487232208252,entropy:1.6031736135482788,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:345, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00089,lr_multiplier:11.391,loss:1.5730643272399902,entropy:1.5735642910003662,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:346, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00078,lr_multiplier:11.391,loss:1.5960111618041992,entropy:1.5996044874191284,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:347, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00069,lr_multiplier:11.391,loss:1.5327630043029785,entropy:1.5317877531051636,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:348, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00094,lr_multiplier:11.391,loss:1.5460506677627563,entropy:1.5504425764083862,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:349, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00065,lr_multiplier:11.391,loss:1.5986238718032837,entropy:1.6020337343215942,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:350, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00056,lr_multiplier:11.391,loss:1.6679556369781494,entropy:1.6703540086746216,explained_var_old:1.000,explained_var_new:1.000
已经训练: 350轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 3, lose: 7, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:351, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00077,lr_multiplier:11.391,loss:1.61939537525177,entropy:1.6154987812042236,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:352, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.5527278184890747,entropy:1.5557541847229004,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:353, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00086,lr_multiplier:11.391,loss:1.6013799905776978,entropy:1.6039206981658936,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:354, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.5667216777801514,entropy:1.5670208930969238,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:355, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00096,lr_multiplier:11.391,loss:1.586668848991394,entropy:1.5862371921539307,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:356, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00097,lr_multiplier:11.391,loss:1.6295852661132812,entropy:1.6356841325759888,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:357, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00096,lr_multiplier:11.391,loss:1.4884836673736572,entropy:1.4871127605438232,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:358, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00093,lr_multiplier:11.391,loss:1.614095687866211,entropy:1.6188961267471313,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:359, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00107,lr_multiplier:11.391,loss:1.622246265411377,entropy:1.6167974472045898,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:360, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00091,lr_multiplier:11.391,loss:1.5297150611877441,entropy:1.5352935791015625,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:361, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00095,lr_multiplier:11.391,loss:1.635959267616272,entropy:1.6427334547042847,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:362, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00061,lr_multiplier:11.391,loss:1.6196788549423218,entropy:1.6226404905319214,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:363, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00094,lr_multiplier:11.391,loss:1.6098226308822632,entropy:1.6054940223693848,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:364, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00093,lr_multiplier:11.391,loss:1.505779504776001,entropy:1.5077108144760132,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:365, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00110,lr_multiplier:11.391,loss:1.58121657371521,entropy:1.5777688026428223,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:366, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00113,lr_multiplier:11.391,loss:1.5562089681625366,entropy:1.557867169380188,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:367, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00078,lr_multiplier:11.391,loss:1.534987449645996,entropy:1.5369164943695068,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:368, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00086,lr_multiplier:11.391,loss:1.5416370630264282,entropy:1.5467509031295776,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:369, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00064,lr_multiplier:11.391,loss:1.5803617238998413,entropy:1.58017897605896,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:370, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00065,lr_multiplier:11.391,loss:1.6282814741134644,entropy:1.6290277242660522,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:371, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00068,lr_multiplier:11.391,loss:1.581638216972351,entropy:1.5848939418792725,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:372, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00070,lr_multiplier:11.391,loss:1.605669617652893,entropy:1.606858253479004,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:373, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00089,lr_multiplier:11.391,loss:1.5651503801345825,entropy:1.564091444015503,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:374, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.603898525238037,entropy:1.6035058498382568,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:375, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.5520014762878418,entropy:1.5534088611602783,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:376, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00081,lr_multiplier:11.391,loss:1.5662429332733154,entropy:1.567657232284546,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:377, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00070,lr_multiplier:11.391,loss:1.6176543235778809,entropy:1.6191141605377197,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:378, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00072,lr_multiplier:11.391,loss:1.5956506729125977,entropy:1.597861886024475,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:379, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00076,lr_multiplier:11.391,loss:1.5878266096115112,entropy:1.5885086059570312,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:380, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00074,lr_multiplier:11.391,loss:1.5591984987258911,entropy:1.5599864721298218,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:381, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00063,lr_multiplier:11.391,loss:1.5383566617965698,entropy:1.5426799058914185,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:382, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00083,lr_multiplier:11.391,loss:1.5430121421813965,entropy:1.5457468032836914,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:383, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00066,lr_multiplier:11.391,loss:1.5938817262649536,entropy:1.5964434146881104,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:384, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00070,lr_multiplier:11.391,loss:1.5857295989990234,entropy:1.5865675210952759,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:385, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.553147315979004,entropy:1.5554516315460205,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:386, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00077,lr_multiplier:11.391,loss:1.578884482383728,entropy:1.5804355144500732,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:387, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00055,lr_multiplier:11.391,loss:1.5728484392166138,entropy:1.574378490447998,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:388, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00060,lr_multiplier:11.391,loss:1.600264310836792,entropy:1.6027946472167969,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:389, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00051,lr_multiplier:11.391,loss:1.5529990196228027,entropy:1.5564550161361694,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:390, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00059,lr_multiplier:11.391,loss:1.5670899152755737,entropy:1.5664751529693604,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:391, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00068,lr_multiplier:11.391,loss:1.5215338468551636,entropy:1.5220848321914673,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:392, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00062,lr_multiplier:11.391,loss:1.5777482986450195,entropy:1.5810954570770264,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:393, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00064,lr_multiplier:11.391,loss:1.5605541467666626,entropy:1.5629597902297974,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:394, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.5152888298034668,entropy:1.5200639963150024,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:395, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00126,lr_multiplier:11.391,loss:1.519036889076233,entropy:1.5137641429901123,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:396, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00065,lr_multiplier:11.391,loss:1.5114213228225708,entropy:1.5097243785858154,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:397, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00064,lr_multiplier:11.391,loss:1.5349373817443848,entropy:1.5371615886688232,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:398, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.5063632726669312,entropy:1.509053349494934,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:399, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00060,lr_multiplier:11.391,loss:1.5919908285140991,entropy:1.595086693763733,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:400, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00063,lr_multiplier:11.391,loss:1.5187684297561646,entropy:1.5205128192901611,explained_var_old:1.000,explained_var_new:1.000
已经训练: 400轮
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
num_playouts:1000, win: 1, lose: 9, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:401, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00075,lr_multiplier:11.391,loss:1.5525699853897095,entropy:1.5548961162567139,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:402, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00091,lr_multiplier:11.391,loss:1.561269998550415,entropy:1.5639017820358276,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:403, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00093,lr_multiplier:11.391,loss:1.6059160232543945,entropy:1.6092764139175415,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:404, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.5769093036651611,entropy:1.5795867443084717,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:405, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00087,lr_multiplier:11.391,loss:1.611876130104065,entropy:1.6139469146728516,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:406, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00112,lr_multiplier:11.391,loss:1.5704984664916992,entropy:1.5753252506256104,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:407, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00139,lr_multiplier:11.391,loss:1.4998811483383179,entropy:1.5006561279296875,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:408, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00120,lr_multiplier:11.391,loss:1.598101019859314,entropy:1.602426290512085,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:409, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00089,lr_multiplier:11.391,loss:1.5467320680618286,entropy:1.5490351915359497,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:410, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00100,lr_multiplier:11.391,loss:1.5464866161346436,entropy:1.5482293367385864,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:411, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00083,lr_multiplier:11.391,loss:1.6051777601242065,entropy:1.6077228784561157,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:412, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00101,lr_multiplier:11.391,loss:1.538973093032837,entropy:1.5419236421585083,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:413, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.5636391639709473,entropy:1.5693047046661377,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:414, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00087,lr_multiplier:11.391,loss:1.5802888870239258,entropy:1.5837128162384033,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:415, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00139,lr_multiplier:11.391,loss:1.60909903049469,entropy:1.604195237159729,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:416, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00095,lr_multiplier:11.391,loss:1.5626164674758911,entropy:1.5623034238815308,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:417, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00074,lr_multiplier:11.391,loss:1.6190097332000732,entropy:1.6181036233901978,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:418, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.560976505279541,entropy:1.5609676837921143,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:419, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00106,lr_multiplier:11.391,loss:1.601453423500061,entropy:1.599775791168213,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:420, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00475,lr_multiplier:11.391,loss:1.5614800453186035,entropy:1.5756635665893555,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:421, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00152,lr_multiplier:11.391,loss:1.5321018695831299,entropy:1.5462124347686768,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:422, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00197,lr_multiplier:11.391,loss:1.5600273609161377,entropy:1.5623314380645752,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:423, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00090,lr_multiplier:11.391,loss:1.5609074831008911,entropy:1.5548343658447266,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:424, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00104,lr_multiplier:11.391,loss:1.5260742902755737,entropy:1.5261269807815552,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:425, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00084,lr_multiplier:11.391,loss:1.461349368095398,entropy:1.4620938301086426,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:426, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00079,lr_multiplier:11.391,loss:1.6160322427749634,entropy:1.621638536453247,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:427, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00073,lr_multiplier:11.391,loss:1.6255967617034912,entropy:1.6267231702804565,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:428, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00083,lr_multiplier:11.391,loss:1.6925245523452759,entropy:1.6954424381256104,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:429, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00095,lr_multiplier:11.391,loss:1.5501397848129272,entropy:1.5535340309143066,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:430, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00086,lr_multiplier:11.391,loss:1.5854653120040894,entropy:1.5857285261154175,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:431, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00076,lr_multiplier:11.391,loss:1.5912989377975464,entropy:1.5912553071975708,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:432, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00096,lr_multiplier:11.391,loss:1.5648192167282104,entropy:1.5681921243667603,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:433, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00085,lr_multiplier:11.391,loss:1.5997358560562134,entropy:1.6031895875930786,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:434, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00076,lr_multiplier:11.391,loss:1.5746536254882812,entropy:1.575647234916687,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:435, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00071,lr_multiplier:11.391,loss:1.5511616468429565,entropy:1.5548189878463745,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:436, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00072,lr_multiplier:11.391,loss:1.550791621208191,entropy:1.554858922958374,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:437, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.562796950340271,entropy:1.5680607557296753,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:438, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00086,lr_multiplier:11.391,loss:1.5968594551086426,entropy:1.596710205078125,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:439, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00100,lr_multiplier:11.391,loss:1.5484449863433838,entropy:1.5532259941101074,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:440, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00056,lr_multiplier:11.391,loss:1.5717133283615112,entropy:1.571871280670166,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:441, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00078,lr_multiplier:11.391,loss:1.5312727689743042,entropy:1.5331567525863647,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:442, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00057,lr_multiplier:11.391,loss:1.4934380054473877,entropy:1.4965920448303223,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:443, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.5668625831604004,entropy:1.5692155361175537,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:444, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00077,lr_multiplier:11.391,loss:1.5891119241714478,entropy:1.591233253479004,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:445, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00103,lr_multiplier:11.391,loss:1.5927479267120361,entropy:1.598192572593689,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:446, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00080,lr_multiplier:11.391,loss:1.5612998008728027,entropy:1.5633269548416138,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:447, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00077,lr_multiplier:11.391,loss:1.5942630767822266,entropy:1.5969769954681396,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:448, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00082,lr_multiplier:11.391,loss:1.5718200206756592,entropy:1.5766284465789795,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:449, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00090,lr_multiplier:11.391,loss:1.604514241218567,entropy:1.6074447631835938,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:450, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00101,lr_multiplier:11.391,loss:1.5789270401000977,entropy:1.581667423248291,explained_var_old:1.000,explained_var_new:1.000
已经训练: 450轮
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
num_playouts:1000, win: 4, lose: 6, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:451, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00113,lr_multiplier:11.391,loss:1.5674681663513184,entropy:1.572543978691101,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:452, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00103,lr_multiplier:11.391,loss:1.5843298435211182,entropy:1.586343765258789,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:453, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00062,lr_multiplier:11.391,loss:1.5606878995895386,entropy:1.5609326362609863,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:454, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00065,lr_multiplier:11.391,loss:1.606493592262268,entropy:1.6067842245101929,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:455, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00088,lr_multiplier:11.391,loss:1.5383118391036987,entropy:1.53416109085083,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:456, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00113,lr_multiplier:11.391,loss:1.5528000593185425,entropy:1.5540921688079834,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:457, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00098,lr_multiplier:11.391,loss:1.5162327289581299,entropy:1.5171337127685547,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:458, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00110,lr_multiplier:11.391,loss:1.547927737236023,entropy:1.5525763034820557,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:459, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00106,lr_multiplier:11.391,loss:1.530717134475708,entropy:1.530296802520752,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:460, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00090,lr_multiplier:11.391,loss:1.5591472387313843,entropy:1.5630226135253906,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:461, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00669,lr_multiplier:11.391,loss:1.5796775817871094,entropy:1.5532653331756592,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:462, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02819,lr_multiplier:11.391,loss:1.536900281906128,entropy:1.5140347480773926,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:463, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00633,lr_multiplier:11.391,loss:1.5530158281326294,entropy:1.574709415435791,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:464, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.00626,lr_multiplier:11.391,loss:1.5325088500976562,entropy:1.5177268981933594,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:465, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01454,lr_multiplier:11.391,loss:1.5427192449569702,entropy:1.556524634361267,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:466, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01175,lr_multiplier:11.391,loss:1.5343680381774902,entropy:1.5312353372573853,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:467, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02481,lr_multiplier:11.391,loss:1.5975748300552368,entropy:1.622464895248413,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:468, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01037,lr_multiplier:11.391,loss:1.5776475667953491,entropy:1.572348713874817,explained_var_old:1.000,explained_var_new:1.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:469, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.02146,lr_multiplier:11.391,loss:1.6680517196655273,entropy:1.5917397737503052,explained_var_old:0.922,explained_var_new:0.929
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:470, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02157,lr_multiplier:11.391,loss:1.6681846380233765,entropy:1.5579664707183838,explained_var_old:0.895,explained_var_new:0.907
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:471, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03477,lr_multiplier:11.391,loss:1.678840160369873,entropy:1.6123194694519043,explained_var_old:0.911,explained_var_new:0.914
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:472, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02140,lr_multiplier:11.391,loss:1.664994716644287,entropy:1.5945543050765991,explained_var_old:0.920,explained_var_new:0.921
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:473, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.03262,lr_multiplier:11.391,loss:1.8260966539382935,entropy:1.6400692462921143,explained_var_old:0.749,explained_var_new:0.794
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:474, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.04303,lr_multiplier:7.594,loss:1.8325947523117065,entropy:1.6743438243865967,explained_var_old:0.831,explained_var_new:0.832
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:475, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02000,lr_multiplier:7.594,loss:1.6606204509735107,entropy:1.606850028038025,explained_var_old:0.936,explained_var_new:0.940
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:476, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03667,lr_multiplier:7.594,loss:1.7537306547164917,entropy:1.591805338859558,explained_var_old:0.817,explained_var_new:0.818
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:477, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01384,lr_multiplier:7.594,loss:1.6745655536651611,entropy:1.590411901473999,explained_var_old:0.906,explained_var_new:0.910
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:478, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01502,lr_multiplier:7.594,loss:1.7077213525772095,entropy:1.570237398147583,explained_var_old:0.855,explained_var_new:0.862
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:479, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01465,lr_multiplier:7.594,loss:1.7758831977844238,entropy:1.5986943244934082,explained_var_old:0.811,explained_var_new:0.815
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:480, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01334,lr_multiplier:7.594,loss:1.7334831953048706,entropy:1.5419917106628418,explained_var_old:0.792,explained_var_new:0.801
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:481, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01278,lr_multiplier:7.594,loss:1.73793363571167,entropy:1.6089366674423218,explained_var_old:0.855,explained_var_new:0.857
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:482, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02104,lr_multiplier:7.594,loss:1.72224760055542,entropy:1.5754611492156982,explained_var_old:0.858,explained_var_new:0.868
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:483, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01676,lr_multiplier:7.594,loss:1.7920652627944946,entropy:1.6242932081222534,explained_var_old:0.807,explained_var_new:0.819
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:484, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01624,lr_multiplier:7.594,loss:1.7546286582946777,entropy:1.6313600540161133,explained_var_old:0.837,explained_var_new:0.869
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:485, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01286,lr_multiplier:7.594,loss:1.722296118736267,entropy:1.606298804283142,explained_var_old:0.862,explained_var_new:0.887
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:486, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01740,lr_multiplier:7.594,loss:1.6657652854919434,entropy:1.586181402206421,explained_var_old:0.912,explained_var_new:0.923
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:487, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01311,lr_multiplier:7.594,loss:1.7577608823776245,entropy:1.6799005270004272,explained_var_old:0.886,explained_var_new:0.901
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:488, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01380,lr_multiplier:7.594,loss:1.6992179155349731,entropy:1.5924121141433716,explained_var_old:0.872,explained_var_new:0.880
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:489, episode_len:46
TrainPipeline:run: 开始模型训练
kl:0.02444,lr_multiplier:7.594,loss:1.8559045791625977,entropy:1.6273674964904785,explained_var_old:0.745,explained_var_new:0.770
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:490, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01985,lr_multiplier:7.594,loss:1.7692662477493286,entropy:1.6361422538757324,explained_var_old:0.840,explained_var_new:0.855
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:491, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02642,lr_multiplier:7.594,loss:1.7392628192901611,entropy:1.6276748180389404,explained_var_old:0.846,explained_var_new:0.873
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:492, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02045,lr_multiplier:7.594,loss:1.8201868534088135,entropy:1.6843979358673096,explained_var_old:0.848,explained_var_new:0.876
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:493, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.02400,lr_multiplier:7.594,loss:1.8248264789581299,entropy:1.6979618072509766,explained_var_old:0.823,explained_var_new:0.857
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:494, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02748,lr_multiplier:7.594,loss:1.8962976932525635,entropy:1.697798728942871,explained_var_old:0.778,explained_var_new:0.808
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:495, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02243,lr_multiplier:7.594,loss:1.800652027130127,entropy:1.659798502922058,explained_var_old:0.814,explained_var_new:0.856
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:496, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.03096,lr_multiplier:7.594,loss:1.8098876476287842,entropy:1.6591715812683105,explained_var_old:0.789,explained_var_new:0.834
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:497, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.03487,lr_multiplier:7.594,loss:1.968873381614685,entropy:1.775390386581421,explained_var_old:0.716,explained_var_new:0.792
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:498, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.03428,lr_multiplier:7.594,loss:2.0274858474731445,entropy:1.727855920791626,explained_var_old:0.679,explained_var_new:0.717
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:499, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.03495,lr_multiplier:7.594,loss:2.0989906787872314,entropy:1.8020188808441162,explained_var_old:0.628,explained_var_new:0.680
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:500, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.03449,lr_multiplier:7.594,loss:2.090970039367676,entropy:1.8217414617538452,explained_var_old:0.644,explained_var_new:0.692
已经训练: 500轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 4, lose: 6, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:501, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.03451,lr_multiplier:7.594,loss:2.1472275257110596,entropy:1.816693902015686,explained_var_old:0.645,explained_var_new:0.689
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:502, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.04251,lr_multiplier:5.062,loss:2.1560397148132324,entropy:1.81009840965271,explained_var_old:0.556,explained_var_new:0.632
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:503, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02921,lr_multiplier:5.062,loss:2.19740629196167,entropy:1.861501693725586,explained_var_old:0.626,explained_var_new:0.677
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:504, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02357,lr_multiplier:5.062,loss:2.1615898609161377,entropy:1.7860740423202515,explained_var_old:0.594,explained_var_new:0.638
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:505, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02150,lr_multiplier:5.062,loss:2.233461380004883,entropy:1.8003350496292114,explained_var_old:0.531,explained_var_new:0.588
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:506, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.01865,lr_multiplier:5.062,loss:2.4171853065490723,entropy:2.0020272731781006,explained_var_old:0.525,explained_var_new:0.582
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:507, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.02279,lr_multiplier:5.062,loss:2.2870900630950928,entropy:1.8916748762130737,explained_var_old:0.566,explained_var_new:0.623
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:508, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02559,lr_multiplier:5.062,loss:2.450914144515991,entropy:2.0023396015167236,explained_var_old:0.462,explained_var_new:0.536
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:509, episode_len:44
TrainPipeline:run: 开始模型训练
kl:0.02253,lr_multiplier:5.062,loss:2.5020689964294434,entropy:2.057114601135254,explained_var_old:0.484,explained_var_new:0.554
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:510, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.02530,lr_multiplier:5.062,loss:2.4785616397857666,entropy:2.0055718421936035,explained_var_old:0.498,explained_var_new:0.571
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:511, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.02055,lr_multiplier:5.062,loss:2.3705525398254395,entropy:1.9412373304367065,explained_var_old:0.553,explained_var_new:0.583
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:512, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02069,lr_multiplier:5.062,loss:2.5632266998291016,entropy:2.129021406173706,explained_var_old:0.487,explained_var_new:0.544
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:513, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01134,lr_multiplier:5.062,loss:2.5101072788238525,entropy:2.0479660034179688,explained_var_old:0.481,explained_var_new:0.526
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:514, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03552,lr_multiplier:5.062,loss:2.5712316036224365,entropy:2.115814685821533,explained_var_old:0.470,explained_var_new:0.550
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:515, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.03183,lr_multiplier:5.062,loss:2.5777125358581543,entropy:2.0528907775878906,explained_var_old:0.469,explained_var_new:0.520
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:516, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01549,lr_multiplier:5.062,loss:2.643505573272705,entropy:2.0708954334259033,explained_var_old:0.338,explained_var_new:0.430
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:517, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.02113,lr_multiplier:5.062,loss:2.6760647296905518,entropy:2.1807785034179688,explained_var_old:0.416,explained_var_new:0.468
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:518, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02731,lr_multiplier:5.062,loss:2.6967902183532715,entropy:2.221200466156006,explained_var_old:0.421,explained_var_new:0.501
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:519, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02550,lr_multiplier:5.062,loss:2.639706611633301,entropy:2.0979349613189697,explained_var_old:0.447,explained_var_new:0.488
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:520, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02716,lr_multiplier:5.062,loss:2.6875216960906982,entropy:2.120046377182007,explained_var_old:0.406,explained_var_new:0.451
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:521, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01359,lr_multiplier:5.062,loss:2.6935787200927734,entropy:2.137798309326172,explained_var_old:0.384,explained_var_new:0.429
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:522, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01611,lr_multiplier:5.062,loss:2.6822242736816406,entropy:2.1404201984405518,explained_var_old:0.373,explained_var_new:0.445
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:523, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01587,lr_multiplier:5.062,loss:2.662646770477295,entropy:2.1554622650146484,explained_var_old:0.461,explained_var_new:0.485
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:524, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01701,lr_multiplier:5.062,loss:2.67899227142334,entropy:2.142622232437134,explained_var_old:0.424,explained_var_new:0.472
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:525, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01383,lr_multiplier:5.062,loss:2.7263264656066895,entropy:2.1891493797302246,explained_var_old:0.401,explained_var_new:0.463
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:526, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.01200,lr_multiplier:5.062,loss:2.694072961807251,entropy:2.178598165512085,explained_var_old:0.412,explained_var_new:0.467
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:527, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01565,lr_multiplier:5.062,loss:2.8182313442230225,entropy:2.215444326400757,explained_var_old:0.346,explained_var_new:0.408
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:528, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01546,lr_multiplier:5.062,loss:2.8537168502807617,entropy:2.3057851791381836,explained_var_old:0.353,explained_var_new:0.415
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:529, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.01772,lr_multiplier:5.062,loss:2.7749059200286865,entropy:2.1983370780944824,explained_var_old:0.373,explained_var_new:0.417
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:530, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01227,lr_multiplier:5.062,loss:2.8260793685913086,entropy:2.2105424404144287,explained_var_old:0.382,explained_var_new:0.424
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:531, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02336,lr_multiplier:5.062,loss:2.8961873054504395,entropy:2.335324764251709,explained_var_old:0.290,explained_var_new:0.394
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:532, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02961,lr_multiplier:5.062,loss:2.826686382293701,entropy:2.251901149749756,explained_var_old:0.364,explained_var_new:0.402
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:533, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.02213,lr_multiplier:5.062,loss:2.8437461853027344,entropy:2.2308270931243896,explained_var_old:0.322,explained_var_new:0.411
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:534, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.01690,lr_multiplier:5.062,loss:2.9425058364868164,entropy:2.285051107406616,explained_var_old:0.265,explained_var_new:0.315
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:535, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.02115,lr_multiplier:5.062,loss:2.952235221862793,entropy:2.346914291381836,explained_var_old:0.355,explained_var_new:0.405
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:536, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01549,lr_multiplier:5.062,loss:3.02433443069458,entropy:2.3964946269989014,explained_var_old:0.326,explained_var_new:0.375
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:537, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02028,lr_multiplier:5.062,loss:2.908811569213867,entropy:2.3412067890167236,explained_var_old:0.328,explained_var_new:0.393
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:538, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.00979,lr_multiplier:7.594,loss:2.985590696334839,entropy:2.396916389465332,explained_var_old:0.331,explained_var_new:0.397
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:539, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03059,lr_multiplier:7.594,loss:3.013089656829834,entropy:2.4366722106933594,explained_var_old:0.322,explained_var_new:0.406
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:540, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.04359,lr_multiplier:5.062,loss:2.957608938217163,entropy:2.3712778091430664,explained_var_old:0.342,explained_var_new:0.414
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:541, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02740,lr_multiplier:5.062,loss:3.0135841369628906,entropy:2.4406495094299316,explained_var_old:0.298,explained_var_new:0.368
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:542, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.02313,lr_multiplier:5.062,loss:3.136925220489502,entropy:2.482682704925537,explained_var_old:0.245,explained_var_new:0.318
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:543, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01405,lr_multiplier:5.062,loss:3.1416871547698975,entropy:2.4458463191986084,explained_var_old:0.254,explained_var_new:0.318
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:544, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02572,lr_multiplier:5.062,loss:3.120305061340332,entropy:2.5151116847991943,explained_var_old:0.252,explained_var_new:0.316
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:545, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01384,lr_multiplier:5.062,loss:3.2329976558685303,entropy:2.5879690647125244,explained_var_old:0.204,explained_var_new:0.273
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:546, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02052,lr_multiplier:5.062,loss:3.21970534324646,entropy:2.533745765686035,explained_var_old:0.258,explained_var_new:0.306
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:547, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01837,lr_multiplier:5.062,loss:3.3074374198913574,entropy:2.560990333557129,explained_var_old:0.184,explained_var_new:0.258
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:548, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01544,lr_multiplier:5.062,loss:3.189260959625244,entropy:2.5471980571746826,explained_var_old:0.235,explained_var_new:0.302
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:549, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.01331,lr_multiplier:5.062,loss:3.2772955894470215,entropy:2.6512436866760254,explained_var_old:0.188,explained_var_new:0.269
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:550, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01813,lr_multiplier:5.062,loss:3.185023784637451,entropy:2.5822839736938477,explained_var_old:0.262,explained_var_new:0.331
已经训练: 550轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 8, lose: 2, tie:0
相较于MCTS@1000, 截至目前的最佳胜率=0.8 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:551, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01199,lr_multiplier:5.062,loss:3.290128231048584,entropy:2.59881329536438,explained_var_old:0.248,explained_var_new:0.308
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:552, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01244,lr_multiplier:5.062,loss:3.282243490219116,entropy:2.5818474292755127,explained_var_old:0.212,explained_var_new:0.273
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:553, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01542,lr_multiplier:5.062,loss:3.3067047595977783,entropy:2.602560520172119,explained_var_old:0.252,explained_var_new:0.311
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:554, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01237,lr_multiplier:5.062,loss:3.2486181259155273,entropy:2.626013994216919,explained_var_old:0.257,explained_var_new:0.301
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:555, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.00985,lr_multiplier:7.594,loss:3.292447090148926,entropy:2.648298740386963,explained_var_old:0.232,explained_var_new:0.297
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:556, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01840,lr_multiplier:7.594,loss:3.1961801052093506,entropy:2.6041059494018555,explained_var_old:0.241,explained_var_new:0.320
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:557, episode_len:14
TrainPipeline:run: 开始模型训练
kl:0.01708,lr_multiplier:7.594,loss:3.2642571926116943,entropy:2.6126291751861572,explained_var_old:0.227,explained_var_new:0.303
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:558, episode_len:10
TrainPipeline:run: 开始模型训练
kl:0.02760,lr_multiplier:7.594,loss:3.2646055221557617,entropy:2.6027612686157227,explained_var_old:0.218,explained_var_new:0.306
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:559, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.03084,lr_multiplier:7.594,loss:3.282193899154663,entropy:2.6483211517333984,explained_var_old:0.269,explained_var_new:0.367
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:560, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.02500,lr_multiplier:7.594,loss:3.3061294555664062,entropy:2.625840663909912,explained_var_old:0.161,explained_var_new:0.251
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:561, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.02726,lr_multiplier:7.594,loss:3.2561094760894775,entropy:2.625722885131836,explained_var_old:0.219,explained_var_new:0.279
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:562, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.03734,lr_multiplier:7.594,loss:3.2118096351623535,entropy:2.587336301803589,explained_var_old:0.234,explained_var_new:0.344
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:563, episode_len:10
TrainPipeline:run: 开始模型训练
kl:0.02549,lr_multiplier:7.594,loss:3.1697046756744385,entropy:2.5753605365753174,explained_var_old:0.254,explained_var_new:0.338
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:564, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03084,lr_multiplier:7.594,loss:3.2530407905578613,entropy:2.6568899154663086,explained_var_old:0.245,explained_var_new:0.320
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:565, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02893,lr_multiplier:7.594,loss:3.2614543437957764,entropy:2.584643840789795,explained_var_old:0.258,explained_var_new:0.330
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:566, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.03753,lr_multiplier:7.594,loss:3.250753879547119,entropy:2.6302504539489746,explained_var_old:0.231,explained_var_new:0.300
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:567, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.03757,lr_multiplier:7.594,loss:3.239830732345581,entropy:2.596982479095459,explained_var_old:0.237,explained_var_new:0.337
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:568, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.05473,lr_multiplier:5.062,loss:3.2047924995422363,entropy:2.589096784591675,explained_var_old:0.226,explained_var_new:0.326
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:569, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02261,lr_multiplier:5.062,loss:3.2869741916656494,entropy:2.569695472717285,explained_var_old:0.219,explained_var_new:0.303
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:570, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02653,lr_multiplier:5.062,loss:3.3334829807281494,entropy:2.630441665649414,explained_var_old:0.193,explained_var_new:0.261
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:571, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01992,lr_multiplier:5.062,loss:3.2660601139068604,entropy:2.69104266166687,explained_var_old:0.237,explained_var_new:0.305
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:572, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01309,lr_multiplier:5.062,loss:3.3239505290985107,entropy:2.6634135246276855,explained_var_old:0.246,explained_var_new:0.310
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:573, episode_len:12
TrainPipeline:run: 开始模型训练
kl:0.01492,lr_multiplier:5.062,loss:3.2520651817321777,entropy:2.591898202896118,explained_var_old:0.221,explained_var_new:0.285
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:574, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.01157,lr_multiplier:5.062,loss:3.1993985176086426,entropy:2.552751064300537,explained_var_old:0.269,explained_var_new:0.321
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:575, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01603,lr_multiplier:5.062,loss:3.2972755432128906,entropy:2.622546672821045,explained_var_old:0.259,explained_var_new:0.322
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:576, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01994,lr_multiplier:5.062,loss:3.1884381771087646,entropy:2.6188812255859375,explained_var_old:0.294,explained_var_new:0.366
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:577, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01145,lr_multiplier:5.062,loss:3.2130014896392822,entropy:2.617846965789795,explained_var_old:0.236,explained_var_new:0.298
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:578, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01236,lr_multiplier:5.062,loss:3.20378041267395,entropy:2.634317636489868,explained_var_old:0.313,explained_var_new:0.383
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:579, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01771,lr_multiplier:5.062,loss:3.2649388313293457,entropy:2.5779366493225098,explained_var_old:0.277,explained_var_new:0.319
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:580, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01207,lr_multiplier:5.062,loss:3.247647762298584,entropy:2.614043951034546,explained_var_old:0.240,explained_var_new:0.303
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:581, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.00949,lr_multiplier:7.594,loss:3.290891647338867,entropy:2.615476131439209,explained_var_old:0.257,explained_var_new:0.310
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:582, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01823,lr_multiplier:7.594,loss:3.2078144550323486,entropy:2.6211962699890137,explained_var_old:0.323,explained_var_new:0.370
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:583, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01811,lr_multiplier:7.594,loss:3.1880321502685547,entropy:2.559697389602661,explained_var_old:0.253,explained_var_new:0.329
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:584, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01820,lr_multiplier:7.594,loss:3.1636149883270264,entropy:2.562704086303711,explained_var_old:0.317,explained_var_new:0.385
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:585, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02294,lr_multiplier:7.594,loss:3.1859419345855713,entropy:2.6688783168792725,explained_var_old:0.334,explained_var_new:0.427
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:586, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02099,lr_multiplier:7.594,loss:3.1289594173431396,entropy:2.6176111698150635,explained_var_old:0.313,explained_var_new:0.395
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:587, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02233,lr_multiplier:7.594,loss:3.1678590774536133,entropy:2.5965237617492676,explained_var_old:0.307,explained_var_new:0.400
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:588, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02994,lr_multiplier:7.594,loss:3.1981263160705566,entropy:2.6186835765838623,explained_var_old:0.286,explained_var_new:0.382
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:589, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02833,lr_multiplier:7.594,loss:3.1594748497009277,entropy:2.6366896629333496,explained_var_old:0.345,explained_var_new:0.432
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:590, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01420,lr_multiplier:7.594,loss:3.2227561473846436,entropy:2.636443614959717,explained_var_old:0.294,explained_var_new:0.373
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:591, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03091,lr_multiplier:7.594,loss:3.0925862789154053,entropy:2.517963409423828,explained_var_old:0.291,explained_var_new:0.399
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:592, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.03895,lr_multiplier:7.594,loss:3.0942461490631104,entropy:2.6139795780181885,explained_var_old:0.395,explained_var_new:0.464
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:593, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02651,lr_multiplier:7.594,loss:3.136153221130371,entropy:2.5852608680725098,explained_var_old:0.338,explained_var_new:0.397
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:594, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02623,lr_multiplier:7.594,loss:3.0296409130096436,entropy:2.5776069164276123,explained_var_old:0.343,explained_var_new:0.443
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:595, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02291,lr_multiplier:7.594,loss:3.1093013286590576,entropy:2.554236888885498,explained_var_old:0.357,explained_var_new:0.414
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:596, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03177,lr_multiplier:7.594,loss:3.052823543548584,entropy:2.5846760272979736,explained_var_old:0.358,explained_var_new:0.444
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:597, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03920,lr_multiplier:7.594,loss:3.101109266281128,entropy:2.651170492172241,explained_var_old:0.341,explained_var_new:0.414
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:598, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02957,lr_multiplier:7.594,loss:3.038991689682007,entropy:2.57312273979187,explained_var_old:0.415,explained_var_new:0.482
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:599, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03422,lr_multiplier:7.594,loss:3.0517704486846924,entropy:2.5873687267303467,explained_var_old:0.380,explained_var_new:0.469
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:600, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02350,lr_multiplier:7.594,loss:3.0739381313323975,entropy:2.572309732437134,explained_var_old:0.367,explained_var_new:0.443
已经训练: 600轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 5, lose: 5, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:601, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03262,lr_multiplier:7.594,loss:3.0101656913757324,entropy:2.5543041229248047,explained_var_old:0.429,explained_var_new:0.486
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:602, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01897,lr_multiplier:7.594,loss:3.055492877960205,entropy:2.585679054260254,explained_var_old:0.401,explained_var_new:0.472
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:603, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02205,lr_multiplier:7.594,loss:2.9715588092803955,entropy:2.585096597671509,explained_var_old:0.451,explained_var_new:0.493
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:604, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02669,lr_multiplier:7.594,loss:2.981313467025757,entropy:2.580678701400757,explained_var_old:0.407,explained_var_new:0.495
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:605, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02140,lr_multiplier:7.594,loss:3.067110300064087,entropy:2.5624895095825195,explained_var_old:0.364,explained_var_new:0.416
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:606, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03463,lr_multiplier:7.594,loss:3.0057966709136963,entropy:2.5762274265289307,explained_var_old:0.423,explained_var_new:0.499
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:607, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02250,lr_multiplier:7.594,loss:2.9173996448516846,entropy:2.5352425575256348,explained_var_old:0.510,explained_var_new:0.550
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:608, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03395,lr_multiplier:7.594,loss:2.965806007385254,entropy:2.535576105117798,explained_var_old:0.453,explained_var_new:0.513
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:609, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01584,lr_multiplier:7.594,loss:2.8711133003234863,entropy:2.538024425506592,explained_var_old:0.562,explained_var_new:0.607
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:610, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02462,lr_multiplier:7.594,loss:2.9501309394836426,entropy:2.4923746585845947,explained_var_old:0.421,explained_var_new:0.483
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:611, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02720,lr_multiplier:7.594,loss:2.86068058013916,entropy:2.4959936141967773,explained_var_old:0.550,explained_var_new:0.600
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:612, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.03374,lr_multiplier:7.594,loss:3.0493249893188477,entropy:2.4819676876068115,explained_var_old:0.356,explained_var_new:0.430
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:613, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02110,lr_multiplier:7.594,loss:3.0534915924072266,entropy:2.5516719818115234,explained_var_old:0.384,explained_var_new:0.421
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:614, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01840,lr_multiplier:7.594,loss:2.94699764251709,entropy:2.499683141708374,explained_var_old:0.464,explained_var_new:0.520
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:615, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01321,lr_multiplier:7.594,loss:2.9554779529571533,entropy:2.502401828765869,explained_var_old:0.449,explained_var_new:0.496
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:616, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02381,lr_multiplier:7.594,loss:2.9641900062561035,entropy:2.5048086643218994,explained_var_old:0.416,explained_var_new:0.490
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:617, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02267,lr_multiplier:7.594,loss:2.870516300201416,entropy:2.449235677719116,explained_var_old:0.499,explained_var_new:0.539
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:618, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02009,lr_multiplier:7.594,loss:2.9009461402893066,entropy:2.48620867729187,explained_var_old:0.474,explained_var_new:0.510
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:619, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.01940,lr_multiplier:7.594,loss:3.0330405235290527,entropy:2.471189260482788,explained_var_old:0.325,explained_var_new:0.384
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:620, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02234,lr_multiplier:7.594,loss:3.0003297328948975,entropy:2.4868037700653076,explained_var_old:0.395,explained_var_new:0.437
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:621, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02040,lr_multiplier:7.594,loss:3.017538070678711,entropy:2.5213212966918945,explained_var_old:0.341,explained_var_new:0.406
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:622, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02261,lr_multiplier:7.594,loss:2.98718523979187,entropy:2.534499168395996,explained_var_old:0.407,explained_var_new:0.466
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:623, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01486,lr_multiplier:7.594,loss:2.9790267944335938,entropy:2.481786012649536,explained_var_old:0.408,explained_var_new:0.457
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:624, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02044,lr_multiplier:7.594,loss:2.918999671936035,entropy:2.453848123550415,explained_var_old:0.385,explained_var_new:0.442
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:625, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01841,lr_multiplier:7.594,loss:2.952526330947876,entropy:2.4816067218780518,explained_var_old:0.392,explained_var_new:0.440
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:626, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02066,lr_multiplier:7.594,loss:2.984398126602173,entropy:2.459427833557129,explained_var_old:0.385,explained_var_new:0.437
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:627, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02061,lr_multiplier:7.594,loss:2.8402352333068848,entropy:2.4436769485473633,explained_var_old:0.443,explained_var_new:0.489
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:628, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02483,lr_multiplier:7.594,loss:2.7701590061187744,entropy:2.3729796409606934,explained_var_old:0.495,explained_var_new:0.535
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:629, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01824,lr_multiplier:7.594,loss:2.943636894226074,entropy:2.4808897972106934,explained_var_old:0.390,explained_var_new:0.456
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:630, episode_len:50
TrainPipeline:run: 开始模型训练
kl:0.02388,lr_multiplier:7.594,loss:2.8517441749572754,entropy:2.4258244037628174,explained_var_old:0.449,explained_var_new:0.492
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:631, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02511,lr_multiplier:7.594,loss:2.971383571624756,entropy:2.4351389408111572,explained_var_old:0.359,explained_var_new:0.392
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:632, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02063,lr_multiplier:7.594,loss:2.9054207801818848,entropy:2.497211456298828,explained_var_old:0.429,explained_var_new:0.481
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:633, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02029,lr_multiplier:7.594,loss:2.9113826751708984,entropy:2.4498372077941895,explained_var_old:0.363,explained_var_new:0.410
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:634, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02577,lr_multiplier:7.594,loss:2.9246044158935547,entropy:2.4212841987609863,explained_var_old:0.352,explained_var_new:0.410
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:635, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.04142,lr_multiplier:5.062,loss:2.9920754432678223,entropy:2.472846508026123,explained_var_old:0.336,explained_var_new:0.402
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:636, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.01548,lr_multiplier:5.062,loss:2.9703221321105957,entropy:2.4924917221069336,explained_var_old:0.374,explained_var_new:0.411
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:637, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.01368,lr_multiplier:5.062,loss:2.9915928840637207,entropy:2.422412872314453,explained_var_old:0.363,explained_var_new:0.406
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:638, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02009,lr_multiplier:5.062,loss:2.9036061763763428,entropy:2.4307336807250977,explained_var_old:0.390,explained_var_new:0.427
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:639, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01179,lr_multiplier:5.062,loss:2.946180820465088,entropy:2.4345571994781494,explained_var_old:0.314,explained_var_new:0.356
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:640, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01100,lr_multiplier:5.062,loss:2.903960943222046,entropy:2.4194159507751465,explained_var_old:0.346,explained_var_new:0.389
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:641, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01281,lr_multiplier:5.062,loss:2.8620502948760986,entropy:2.3873367309570312,explained_var_old:0.330,explained_var_new:0.367
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:642, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01816,lr_multiplier:5.062,loss:2.8685216903686523,entropy:2.444305419921875,explained_var_old:0.408,explained_var_new:0.443
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:643, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01053,lr_multiplier:5.062,loss:2.9119009971618652,entropy:2.4377660751342773,explained_var_old:0.342,explained_var_new:0.382
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:644, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01333,lr_multiplier:5.062,loss:2.976907730102539,entropy:2.4369726181030273,explained_var_old:0.325,explained_var_new:0.353
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:645, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.00890,lr_multiplier:7.594,loss:2.97309947013855,entropy:2.4438724517822266,explained_var_old:0.387,explained_var_new:0.412
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:646, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02608,lr_multiplier:7.594,loss:2.9076004028320312,entropy:2.4071874618530273,explained_var_old:0.347,explained_var_new:0.395
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:647, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02379,lr_multiplier:7.594,loss:2.8080625534057617,entropy:2.409446954727173,explained_var_old:0.444,explained_var_new:0.503
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:648, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02184,lr_multiplier:7.594,loss:2.8830389976501465,entropy:2.418008327484131,explained_var_old:0.369,explained_var_new:0.428
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:649, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01451,lr_multiplier:7.594,loss:2.8303706645965576,entropy:2.4323134422302246,explained_var_old:0.450,explained_var_new:0.493
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:650, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01697,lr_multiplier:7.594,loss:2.8380892276763916,entropy:2.401533603668213,explained_var_old:0.434,explained_var_new:0.489
已经训练: 650轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 5, lose: 5, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:651, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01753,lr_multiplier:7.594,loss:2.797344923019409,entropy:2.346754789352417,explained_var_old:0.418,explained_var_new:0.483
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:652, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01941,lr_multiplier:7.594,loss:2.7818052768707275,entropy:2.3857884407043457,explained_var_old:0.446,explained_var_new:0.491
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:653, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01737,lr_multiplier:7.594,loss:2.789803981781006,entropy:2.3857319355010986,explained_var_old:0.458,explained_var_new:0.495
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:654, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02338,lr_multiplier:7.594,loss:2.823474407196045,entropy:2.4183757305145264,explained_var_old:0.462,explained_var_new:0.503
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:655, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.04383,lr_multiplier:5.062,loss:2.757565498352051,entropy:2.3622138500213623,explained_var_old:0.483,explained_var_new:0.516
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:656, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01195,lr_multiplier:5.062,loss:2.710366725921631,entropy:2.3000926971435547,explained_var_old:0.548,explained_var_new:0.587
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:657, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01856,lr_multiplier:5.062,loss:2.7395823001861572,entropy:2.3485894203186035,explained_var_old:0.501,explained_var_new:0.543
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:658, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.01683,lr_multiplier:5.062,loss:2.7655272483825684,entropy:2.390547752380371,explained_var_old:0.500,explained_var_new:0.530
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:659, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.01394,lr_multiplier:5.062,loss:2.746199607849121,entropy:2.379023790359497,explained_var_old:0.550,explained_var_new:0.585
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:660, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01736,lr_multiplier:5.062,loss:2.791317939758301,entropy:2.420785427093506,explained_var_old:0.518,explained_var_new:0.546
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:661, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01417,lr_multiplier:5.062,loss:2.7396559715270996,entropy:2.337402820587158,explained_var_old:0.506,explained_var_new:0.546
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:662, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.00701,lr_multiplier:7.594,loss:2.7355074882507324,entropy:2.3261878490448,explained_var_old:0.548,explained_var_new:0.573
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:663, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.02154,lr_multiplier:7.594,loss:2.757882833480835,entropy:2.3942043781280518,explained_var_old:0.469,explained_var_new:0.527
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:664, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02428,lr_multiplier:7.594,loss:2.6757869720458984,entropy:2.3129048347473145,explained_var_old:0.534,explained_var_new:0.583
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:665, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02088,lr_multiplier:7.594,loss:2.6801488399505615,entropy:2.294422149658203,explained_var_old:0.545,explained_var_new:0.587
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:666, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02226,lr_multiplier:7.594,loss:2.698651075363159,entropy:2.3458733558654785,explained_var_old:0.559,explained_var_new:0.613
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:667, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02055,lr_multiplier:7.594,loss:2.6721086502075195,entropy:2.340327739715576,explained_var_old:0.531,explained_var_new:0.584
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:668, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02417,lr_multiplier:7.594,loss:2.674271583557129,entropy:2.3538670539855957,explained_var_old:0.562,explained_var_new:0.614
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:669, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02471,lr_multiplier:7.594,loss:2.6951053142547607,entropy:2.2879438400268555,explained_var_old:0.525,explained_var_new:0.582
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:670, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02910,lr_multiplier:7.594,loss:2.6822073459625244,entropy:2.3241872787475586,explained_var_old:0.548,explained_var_new:0.608
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:671, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03067,lr_multiplier:7.594,loss:2.6795260906219482,entropy:2.3148281574249268,explained_var_old:0.538,explained_var_new:0.606
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:672, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02502,lr_multiplier:7.594,loss:2.6077117919921875,entropy:2.3233892917633057,explained_var_old:0.628,explained_var_new:0.675
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:673, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02697,lr_multiplier:7.594,loss:2.6481595039367676,entropy:2.3553225994110107,explained_var_old:0.625,explained_var_new:0.662
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:674, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.03295,lr_multiplier:7.594,loss:2.6481478214263916,entropy:2.35341739654541,explained_var_old:0.541,explained_var_new:0.626
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:675, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02197,lr_multiplier:7.594,loss:2.597337245941162,entropy:2.281599283218384,explained_var_old:0.572,explained_var_new:0.633
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:676, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.03442,lr_multiplier:7.594,loss:2.598484754562378,entropy:2.29668927192688,explained_var_old:0.623,explained_var_new:0.669
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:677, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02666,lr_multiplier:7.594,loss:2.7083818912506104,entropy:2.354478120803833,explained_var_old:0.532,explained_var_new:0.592
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:678, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01482,lr_multiplier:7.594,loss:2.7147011756896973,entropy:2.3425416946411133,explained_var_old:0.488,explained_var_new:0.557
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:679, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.01752,lr_multiplier:7.594,loss:2.625880718231201,entropy:2.275573492050171,explained_var_old:0.528,explained_var_new:0.590
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:680, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.02689,lr_multiplier:7.594,loss:2.7371878623962402,entropy:2.36335825920105,explained_var_old:0.517,explained_var_new:0.554
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:681, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.02972,lr_multiplier:7.594,loss:2.777277708053589,entropy:2.3361258506774902,explained_var_old:0.439,explained_var_new:0.509
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:682, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.02094,lr_multiplier:7.594,loss:2.724341630935669,entropy:2.3490688800811768,explained_var_old:0.542,explained_var_new:0.594
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:683, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02053,lr_multiplier:7.594,loss:2.7511603832244873,entropy:2.3524417877197266,explained_var_old:0.541,explained_var_new:0.591
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:684, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01602,lr_multiplier:7.594,loss:2.758418083190918,entropy:2.3533267974853516,explained_var_old:0.502,explained_var_new:0.570
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:685, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01938,lr_multiplier:7.594,loss:2.682197093963623,entropy:2.3645682334899902,explained_var_old:0.571,explained_var_new:0.614
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:686, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02296,lr_multiplier:7.594,loss:2.750870704650879,entropy:2.3388290405273438,explained_var_old:0.506,explained_var_new:0.572
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:687, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03315,lr_multiplier:7.594,loss:2.730088949203491,entropy:2.3398256301879883,explained_var_old:0.563,explained_var_new:0.620
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:688, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02797,lr_multiplier:7.594,loss:2.752084493637085,entropy:2.391777515411377,explained_var_old:0.590,explained_var_new:0.631
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:689, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.02144,lr_multiplier:7.594,loss:2.733275890350342,entropy:2.3682451248168945,explained_var_old:0.535,explained_var_new:0.596
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:690, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01317,lr_multiplier:7.594,loss:2.714848518371582,entropy:2.3383758068084717,explained_var_old:0.521,explained_var_new:0.587
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:691, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02022,lr_multiplier:7.594,loss:2.779566764831543,entropy:2.429910659790039,explained_var_old:0.543,explained_var_new:0.586
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:692, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01396,lr_multiplier:7.594,loss:2.6791481971740723,entropy:2.3410074710845947,explained_var_old:0.596,explained_var_new:0.650
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:693, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01681,lr_multiplier:7.594,loss:2.681929111480713,entropy:2.3256890773773193,explained_var_old:0.582,explained_var_new:0.622
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:694, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01405,lr_multiplier:7.594,loss:2.641745090484619,entropy:2.3450798988342285,explained_var_old:0.640,explained_var_new:0.675
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:695, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01760,lr_multiplier:7.594,loss:2.6903390884399414,entropy:2.3797526359558105,explained_var_old:0.612,explained_var_new:0.659
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:696, episode_len:53
TrainPipeline:run: 开始模型训练
kl:0.02788,lr_multiplier:7.594,loss:2.680361270904541,entropy:2.361142158508301,explained_var_old:0.627,explained_var_new:0.683
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:697, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02178,lr_multiplier:7.594,loss:2.649271011352539,entropy:2.313403367996216,explained_var_old:0.582,explained_var_new:0.649
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:698, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02432,lr_multiplier:7.594,loss:2.7192304134368896,entropy:2.3546175956726074,explained_var_old:0.532,explained_var_new:0.588
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:699, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.03337,lr_multiplier:7.594,loss:2.639707326889038,entropy:2.383723497390747,explained_var_old:0.645,explained_var_new:0.697
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:700, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02101,lr_multiplier:7.594,loss:2.654658555984497,entropy:2.384244680404663,explained_var_old:0.645,explained_var_new:0.680
已经训练: 700轮
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 6, lose: 4, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:701, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01995,lr_multiplier:7.594,loss:2.6562347412109375,entropy:2.3483190536499023,explained_var_old:0.584,explained_var_new:0.661
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:702, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.03673,lr_multiplier:7.594,loss:2.6286680698394775,entropy:2.351639986038208,explained_var_old:0.651,explained_var_new:0.699
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:703, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02270,lr_multiplier:7.594,loss:2.656391143798828,entropy:2.301541328430176,explained_var_old:0.629,explained_var_new:0.671
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:704, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02994,lr_multiplier:7.594,loss:2.72636342048645,entropy:2.402308464050293,explained_var_old:0.561,explained_var_new:0.616
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:705, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03645,lr_multiplier:7.594,loss:2.6827688217163086,entropy:2.360438585281372,explained_var_old:0.580,explained_var_new:0.642
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:706, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.03306,lr_multiplier:7.594,loss:2.7228379249572754,entropy:2.3469271659851074,explained_var_old:0.564,explained_var_new:0.603
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:707, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02321,lr_multiplier:7.594,loss:2.713040351867676,entropy:2.2826597690582275,explained_var_old:0.544,explained_var_new:0.585
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:708, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02373,lr_multiplier:7.594,loss:2.666285514831543,entropy:2.3069570064544678,explained_var_old:0.515,explained_var_new:0.568
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:709, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01584,lr_multiplier:7.594,loss:2.6877012252807617,entropy:2.358333110809326,explained_var_old:0.625,explained_var_new:0.653
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:710, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01882,lr_multiplier:7.594,loss:2.6973166465759277,entropy:2.343554973602295,explained_var_old:0.601,explained_var_new:0.648
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:711, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02157,lr_multiplier:7.594,loss:2.6917836666107178,entropy:2.3315091133117676,explained_var_old:0.578,explained_var_new:0.643
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:712, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02501,lr_multiplier:7.594,loss:2.6085495948791504,entropy:2.331836700439453,explained_var_old:0.641,explained_var_new:0.679
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:713, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02363,lr_multiplier:7.594,loss:2.587890863418579,entropy:2.252450942993164,explained_var_old:0.613,explained_var_new:0.645
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:714, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02038,lr_multiplier:7.594,loss:2.700854778289795,entropy:2.327648401260376,explained_var_old:0.579,explained_var_new:0.610
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:715, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01330,lr_multiplier:7.594,loss:2.7242913246154785,entropy:2.304307460784912,explained_var_old:0.468,explained_var_new:0.514
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:716, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02211,lr_multiplier:7.594,loss:2.6913208961486816,entropy:2.2742831707000732,explained_var_old:0.546,explained_var_new:0.597
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:717, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02471,lr_multiplier:7.594,loss:2.6873250007629395,entropy:2.320234775543213,explained_var_old:0.542,explained_var_new:0.584
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:718, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02250,lr_multiplier:7.594,loss:2.5419793128967285,entropy:2.2286643981933594,explained_var_old:0.621,explained_var_new:0.650
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:719, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.01873,lr_multiplier:7.594,loss:2.7394423484802246,entropy:2.3229613304138184,explained_var_old:0.535,explained_var_new:0.591
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:720, episode_len:42
TrainPipeline:run: 开始模型训练
kl:0.02118,lr_multiplier:7.594,loss:2.80775785446167,entropy:2.3698949813842773,explained_var_old:0.435,explained_var_new:0.513
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:721, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02558,lr_multiplier:7.594,loss:2.8044323921203613,entropy:2.321707010269165,explained_var_old:0.445,explained_var_new:0.486
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:722, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03210,lr_multiplier:7.594,loss:2.738657236099243,entropy:2.290736436843872,explained_var_old:0.478,explained_var_new:0.515
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:723, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.04403,lr_multiplier:5.062,loss:2.7043216228485107,entropy:2.271411180496216,explained_var_old:0.481,explained_var_new:0.564
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:724, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.03270,lr_multiplier:5.062,loss:2.832559108734131,entropy:2.391118049621582,explained_var_old:0.490,explained_var_new:0.520
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:725, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02841,lr_multiplier:5.062,loss:2.7074036598205566,entropy:2.2926719188690186,explained_var_old:0.488,explained_var_new:0.525
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:726, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01503,lr_multiplier:5.062,loss:2.769540786743164,entropy:2.3350367546081543,explained_var_old:0.495,explained_var_new:0.555
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:727, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.00906,lr_multiplier:7.594,loss:2.775723934173584,entropy:2.3696677684783936,explained_var_old:0.510,explained_var_new:0.552
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:728, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01771,lr_multiplier:7.594,loss:2.705425262451172,entropy:2.3195271492004395,explained_var_old:0.505,explained_var_new:0.549
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:729, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01252,lr_multiplier:7.594,loss:2.7863991260528564,entropy:2.387777090072632,explained_var_old:0.544,explained_var_new:0.586
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:730, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01870,lr_multiplier:7.594,loss:2.773347854614258,entropy:2.3420279026031494,explained_var_old:0.495,explained_var_new:0.562
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:731, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02427,lr_multiplier:7.594,loss:2.70993709564209,entropy:2.370239734649658,explained_var_old:0.520,explained_var_new:0.569
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:732, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02256,lr_multiplier:7.594,loss:2.7028467655181885,entropy:2.278360605239868,explained_var_old:0.504,explained_var_new:0.566
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:733, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.02251,lr_multiplier:7.594,loss:2.6450953483581543,entropy:2.3250348567962646,explained_var_old:0.616,explained_var_new:0.661
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:734, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02151,lr_multiplier:7.594,loss:2.6422691345214844,entropy:2.297605514526367,explained_var_old:0.608,explained_var_new:0.656
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:735, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02432,lr_multiplier:7.594,loss:2.6970043182373047,entropy:2.338496685028076,explained_var_old:0.571,explained_var_new:0.611
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:736, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03625,lr_multiplier:7.594,loss:2.645216703414917,entropy:2.3390913009643555,explained_var_old:0.621,explained_var_new:0.667
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:737, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02775,lr_multiplier:7.594,loss:2.606443405151367,entropy:2.286837577819824,explained_var_old:0.585,explained_var_new:0.622
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:738, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02219,lr_multiplier:7.594,loss:2.5582656860351562,entropy:2.2777671813964844,explained_var_old:0.636,explained_var_new:0.678
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:739, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02574,lr_multiplier:7.594,loss:2.5664260387420654,entropy:2.2532854080200195,explained_var_old:0.611,explained_var_new:0.649
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:740, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02477,lr_multiplier:7.594,loss:2.5460164546966553,entropy:2.3027079105377197,explained_var_old:0.730,explained_var_new:0.764
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:741, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02480,lr_multiplier:7.594,loss:2.4615166187286377,entropy:2.25053334236145,explained_var_old:0.720,explained_var_new:0.751
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:742, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02698,lr_multiplier:7.594,loss:2.6008753776550293,entropy:2.346679210662842,explained_var_old:0.643,explained_var_new:0.695
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:743, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02461,lr_multiplier:7.594,loss:2.5089151859283447,entropy:2.2885513305664062,explained_var_old:0.706,explained_var_new:0.737
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:744, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02029,lr_multiplier:7.594,loss:2.5377044677734375,entropy:2.2554526329040527,explained_var_old:0.618,explained_var_new:0.661
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:745, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02708,lr_multiplier:7.594,loss:2.5519118309020996,entropy:2.201228618621826,explained_var_old:0.569,explained_var_new:0.628
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:746, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02465,lr_multiplier:7.594,loss:2.5066208839416504,entropy:2.3057162761688232,explained_var_old:0.656,explained_var_new:0.701
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:747, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02151,lr_multiplier:7.594,loss:2.530578136444092,entropy:2.2745072841644287,explained_var_old:0.666,explained_var_new:0.690
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:748, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.02308,lr_multiplier:7.594,loss:2.5432753562927246,entropy:2.2929396629333496,explained_var_old:0.673,explained_var_new:0.705
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:749, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02827,lr_multiplier:7.594,loss:2.526801586151123,entropy:2.301746368408203,explained_var_old:0.698,explained_var_new:0.731
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:750, episode_len:36
TrainPipeline:run: 开始模型训练
kl:0.03405,lr_multiplier:7.594,loss:2.59476900100708,entropy:2.289792537689209,explained_var_old:0.591,explained_var_new:0.641
已经训练: 750轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 8, lose: 2, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:751, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.02850,lr_multiplier:7.594,loss:2.5222041606903076,entropy:2.260502576828003,explained_var_old:0.645,explained_var_new:0.680
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:752, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02185,lr_multiplier:7.594,loss:2.4708945751190186,entropy:2.2555508613586426,explained_var_old:0.696,explained_var_new:0.732
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:753, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02737,lr_multiplier:7.594,loss:2.5207223892211914,entropy:2.289904832839966,explained_var_old:0.668,explained_var_new:0.703
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:754, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02354,lr_multiplier:7.594,loss:2.485050916671753,entropy:2.261632204055786,explained_var_old:0.704,explained_var_new:0.735
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:755, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02610,lr_multiplier:7.594,loss:2.672396183013916,entropy:2.3089518547058105,explained_var_old:0.558,explained_var_new:0.605
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:756, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02270,lr_multiplier:7.594,loss:2.5545969009399414,entropy:2.288099765777588,explained_var_old:0.619,explained_var_new:0.669
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:757, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03005,lr_multiplier:7.594,loss:2.6429660320281982,entropy:2.2624740600585938,explained_var_old:0.503,explained_var_new:0.553
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:758, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.03236,lr_multiplier:7.594,loss:2.5219337940216064,entropy:2.2958292961120605,explained_var_old:0.683,explained_var_new:0.710
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:759, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02625,lr_multiplier:7.594,loss:2.5484747886657715,entropy:2.2997660636901855,explained_var_old:0.688,explained_var_new:0.727
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:760, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03478,lr_multiplier:7.594,loss:2.470357656478882,entropy:2.2793335914611816,explained_var_old:0.680,explained_var_new:0.714
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:761, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.04297,lr_multiplier:5.062,loss:2.532205581665039,entropy:2.2255334854125977,explained_var_old:0.639,explained_var_new:0.676
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:762, episode_len:48
TrainPipeline:run: 开始模型训练
kl:0.02599,lr_multiplier:5.062,loss:2.6410295963287354,entropy:2.2721946239471436,explained_var_old:0.533,explained_var_new:0.569
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:763, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01807,lr_multiplier:5.062,loss:2.6273550987243652,entropy:2.2983150482177734,explained_var_old:0.563,explained_var_new:0.598
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:764, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01351,lr_multiplier:5.062,loss:2.599123239517212,entropy:2.3074045181274414,explained_var_old:0.611,explained_var_new:0.656
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:765, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01600,lr_multiplier:5.062,loss:2.4612319469451904,entropy:2.2348546981811523,explained_var_old:0.658,explained_var_new:0.684
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:766, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01263,lr_multiplier:5.062,loss:2.4094183444976807,entropy:2.242386817932129,explained_var_old:0.754,explained_var_new:0.774
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:767, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01314,lr_multiplier:5.062,loss:2.4741592407226562,entropy:2.227346897125244,explained_var_old:0.660,explained_var_new:0.690
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:768, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.00885,lr_multiplier:7.594,loss:2.60634708404541,entropy:2.2695229053497314,explained_var_old:0.598,explained_var_new:0.633
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:769, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02776,lr_multiplier:7.594,loss:2.635449171066284,entropy:2.283860206604004,explained_var_old:0.538,explained_var_new:0.587
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:770, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02462,lr_multiplier:7.594,loss:2.458178997039795,entropy:2.2415883541107178,explained_var_old:0.659,explained_var_new:0.690
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:771, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.03912,lr_multiplier:7.594,loss:2.46621036529541,entropy:2.173004627227783,explained_var_old:0.603,explained_var_new:0.634
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:772, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03248,lr_multiplier:7.594,loss:2.5819289684295654,entropy:2.181314468383789,explained_var_old:0.546,explained_var_new:0.585
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:773, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02834,lr_multiplier:7.594,loss:2.449755907058716,entropy:2.1539132595062256,explained_var_old:0.627,explained_var_new:0.648
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:774, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.03438,lr_multiplier:7.594,loss:2.5500102043151855,entropy:2.1909806728363037,explained_var_old:0.580,explained_var_new:0.599
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:775, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02250,lr_multiplier:7.594,loss:2.3697023391723633,entropy:2.1579649448394775,explained_var_old:0.642,explained_var_new:0.669
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:776, episode_len:45
TrainPipeline:run: 开始模型训练
kl:0.02860,lr_multiplier:7.594,loss:2.4947683811187744,entropy:2.202608346939087,explained_var_old:0.609,explained_var_new:0.632
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:777, episode_len:49
TrainPipeline:run: 开始模型训练
kl:0.01763,lr_multiplier:7.594,loss:2.483673572540283,entropy:2.164421796798706,explained_var_old:0.609,explained_var_new:0.636
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:778, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02903,lr_multiplier:7.594,loss:2.4804346561431885,entropy:2.1620450019836426,explained_var_old:0.598,explained_var_new:0.634
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:779, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.03735,lr_multiplier:7.594,loss:2.5704877376556396,entropy:2.1979968547821045,explained_var_old:0.536,explained_var_new:0.560
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:780, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03390,lr_multiplier:7.594,loss:2.5403294563293457,entropy:2.2569386959075928,explained_var_old:0.579,explained_var_new:0.608
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:781, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03792,lr_multiplier:7.594,loss:2.5500946044921875,entropy:2.198789119720459,explained_var_old:0.517,explained_var_new:0.542
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:782, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03695,lr_multiplier:7.594,loss:2.5906124114990234,entropy:2.198720932006836,explained_var_old:0.408,explained_var_new:0.451
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:783, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03713,lr_multiplier:7.594,loss:2.5290842056274414,entropy:2.1687750816345215,explained_var_old:0.454,explained_var_new:0.506
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:784, episode_len:9
TrainPipeline:run: 开始模型训练
kl:0.05051,lr_multiplier:5.062,loss:2.6030492782592773,entropy:2.2570135593414307,explained_var_old:0.410,explained_var_new:0.456
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:785, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01855,lr_multiplier:5.062,loss:2.562652349472046,entropy:2.1905083656311035,explained_var_old:0.468,explained_var_new:0.512
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:786, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02322,lr_multiplier:5.062,loss:2.580536127090454,entropy:2.193584442138672,explained_var_old:0.405,explained_var_new:0.442
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:787, episode_len:49
TrainPipeline:run: 开始模型训练
kl:0.01773,lr_multiplier:5.062,loss:2.4965662956237793,entropy:2.1656391620635986,explained_var_old:0.486,explained_var_new:0.519
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:788, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01760,lr_multiplier:5.062,loss:2.536189556121826,entropy:2.180541515350342,explained_var_old:0.412,explained_var_new:0.442
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:789, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01670,lr_multiplier:5.062,loss:2.5217933654785156,entropy:2.198507070541382,explained_var_old:0.497,explained_var_new:0.530
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:790, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01348,lr_multiplier:5.062,loss:2.424268960952759,entropy:2.132276773452759,explained_var_old:0.538,explained_var_new:0.563
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:791, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01689,lr_multiplier:5.062,loss:2.4887161254882812,entropy:2.166412115097046,explained_var_old:0.542,explained_var_new:0.573
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:792, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01633,lr_multiplier:5.062,loss:2.517929792404175,entropy:2.2055253982543945,explained_var_old:0.573,explained_var_new:0.593
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:793, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01514,lr_multiplier:5.062,loss:2.3740861415863037,entropy:2.1467199325561523,explained_var_old:0.584,explained_var_new:0.601
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:794, episode_len:49
TrainPipeline:run: 开始模型训练
kl:0.01631,lr_multiplier:5.062,loss:2.474801540374756,entropy:2.167490243911743,explained_var_old:0.544,explained_var_new:0.559
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:795, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.01519,lr_multiplier:5.062,loss:2.446463108062744,entropy:2.125734567642212,explained_var_old:0.526,explained_var_new:0.546
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:796, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.01829,lr_multiplier:5.062,loss:2.3484947681427,entropy:2.1020619869232178,explained_var_old:0.601,explained_var_new:0.613
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:797, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01511,lr_multiplier:5.062,loss:2.5005853176116943,entropy:2.2048866748809814,explained_var_old:0.565,explained_var_new:0.583
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:798, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02630,lr_multiplier:5.062,loss:2.4966793060302734,entropy:2.176877975463867,explained_var_old:0.546,explained_var_new:0.577
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:799, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01458,lr_multiplier:5.062,loss:2.4091014862060547,entropy:2.115022659301758,explained_var_old:0.615,explained_var_new:0.623
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:800, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02092,lr_multiplier:5.062,loss:2.4210429191589355,entropy:2.1677749156951904,explained_var_old:0.567,explained_var_new:0.589
已经训练: 800轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 9, lose: 1, tie:0
相较于MCTS@1000, 截至目前的最佳胜率=0.9 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:801, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01970,lr_multiplier:5.062,loss:2.419914722442627,entropy:2.1830215454101562,explained_var_old:0.539,explained_var_new:0.559
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:802, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01692,lr_multiplier:5.062,loss:2.339897632598877,entropy:2.0587472915649414,explained_var_old:0.531,explained_var_new:0.564
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:803, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01948,lr_multiplier:5.062,loss:2.425192356109619,entropy:2.1525909900665283,explained_var_old:0.589,explained_var_new:0.606
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:804, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01249,lr_multiplier:5.062,loss:2.402177095413208,entropy:2.160715103149414,explained_var_old:0.578,explained_var_new:0.592
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:805, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01543,lr_multiplier:5.062,loss:2.399583339691162,entropy:2.158750295639038,explained_var_old:0.596,explained_var_new:0.611
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:806, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01669,lr_multiplier:5.062,loss:2.407565116882324,entropy:2.138958215713501,explained_var_old:0.584,explained_var_new:0.593
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:807, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01663,lr_multiplier:5.062,loss:2.391246795654297,entropy:2.209930181503296,explained_var_old:0.686,explained_var_new:0.711
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:808, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02805,lr_multiplier:5.062,loss:2.411281108856201,entropy:2.219902992248535,explained_var_old:0.674,explained_var_new:0.685
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:809, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01886,lr_multiplier:5.062,loss:2.329392194747925,entropy:2.146450996398926,explained_var_old:0.666,explained_var_new:0.683
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:810, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03539,lr_multiplier:5.062,loss:2.3978662490844727,entropy:2.2447454929351807,explained_var_old:0.685,explained_var_new:0.702
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:811, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02733,lr_multiplier:5.062,loss:2.4402832984924316,entropy:2.2895476818084717,explained_var_old:0.700,explained_var_new:0.722
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:812, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02566,lr_multiplier:5.062,loss:2.370389223098755,entropy:2.238858222961426,explained_var_old:0.701,explained_var_new:0.715
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:813, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02321,lr_multiplier:5.062,loss:2.357243061065674,entropy:2.198354721069336,explained_var_old:0.714,explained_var_new:0.723
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:814, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02295,lr_multiplier:5.062,loss:2.3475022315979004,entropy:2.2184131145477295,explained_var_old:0.750,explained_var_new:0.767
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:815, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.02331,lr_multiplier:5.062,loss:2.3213274478912354,entropy:2.175828695297241,explained_var_old:0.689,explained_var_new:0.699
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:816, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01381,lr_multiplier:5.062,loss:2.3642265796661377,entropy:2.232081174850464,explained_var_old:0.672,explained_var_new:0.693
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:817, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01765,lr_multiplier:5.062,loss:2.378251552581787,entropy:2.269759178161621,explained_var_old:0.770,explained_var_new:0.779
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:818, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01334,lr_multiplier:5.062,loss:2.2379438877105713,entropy:2.1188454627990723,explained_var_old:0.750,explained_var_new:0.760
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:819, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01293,lr_multiplier:5.062,loss:2.2193729877471924,entropy:2.100342273712158,explained_var_old:0.745,explained_var_new:0.760
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:820, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02123,lr_multiplier:5.062,loss:2.2926483154296875,entropy:2.161990165710449,explained_var_old:0.756,explained_var_new:0.769
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:821, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01560,lr_multiplier:5.062,loss:2.2843997478485107,entropy:2.157461404800415,explained_var_old:0.754,explained_var_new:0.765
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:822, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01782,lr_multiplier:5.062,loss:2.231886386871338,entropy:2.1478588581085205,explained_var_old:0.799,explained_var_new:0.810
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:823, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01038,lr_multiplier:5.062,loss:2.259915351867676,entropy:2.1343131065368652,explained_var_old:0.775,explained_var_new:0.782
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:824, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01539,lr_multiplier:5.062,loss:2.2209558486938477,entropy:2.1410727500915527,explained_var_old:0.806,explained_var_new:0.815
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:825, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01724,lr_multiplier:5.062,loss:2.2144830226898193,entropy:2.101865530014038,explained_var_old:0.833,explained_var_new:0.839
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:826, episode_len:45
TrainPipeline:run: 开始模型训练
kl:0.01378,lr_multiplier:5.062,loss:2.290055513381958,entropy:2.1550841331481934,explained_var_old:0.821,explained_var_new:0.827
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:827, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01182,lr_multiplier:5.062,loss:2.2835423946380615,entropy:2.2052457332611084,explained_var_old:0.819,explained_var_new:0.828
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:828, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01275,lr_multiplier:5.062,loss:2.1888556480407715,entropy:2.137382984161377,explained_var_old:0.856,explained_var_new:0.865
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:829, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01729,lr_multiplier:5.062,loss:2.16650128364563,entropy:2.1125149726867676,explained_var_old:0.871,explained_var_new:0.877
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:830, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01269,lr_multiplier:5.062,loss:2.1867270469665527,entropy:2.1241207122802734,explained_var_old:0.869,explained_var_new:0.874
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:831, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01539,lr_multiplier:5.062,loss:2.2290539741516113,entropy:2.1299350261688232,explained_var_old:0.852,explained_var_new:0.860
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:832, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01421,lr_multiplier:5.062,loss:2.17594575881958,entropy:2.104217290878296,explained_var_old:0.878,explained_var_new:0.884
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:833, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01678,lr_multiplier:5.062,loss:2.190762758255005,entropy:2.092437505722046,explained_var_old:0.869,explained_var_new:0.874
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:834, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01534,lr_multiplier:5.062,loss:2.187617301940918,entropy:2.0853469371795654,explained_var_old:0.846,explained_var_new:0.851
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:835, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01031,lr_multiplier:5.062,loss:2.2337725162506104,entropy:2.144908905029297,explained_var_old:0.839,explained_var_new:0.848
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:836, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.01214,lr_multiplier:5.062,loss:2.163759469985962,entropy:2.0766563415527344,explained_var_old:0.862,explained_var_new:0.864
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:837, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.00889,lr_multiplier:7.594,loss:2.168792247772217,entropy:2.114013195037842,explained_var_old:0.879,explained_var_new:0.885
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:838, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01711,lr_multiplier:7.594,loss:2.13283109664917,entropy:2.069303035736084,explained_var_old:0.886,explained_var_new:0.890
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:839, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01892,lr_multiplier:7.594,loss:2.145812749862671,entropy:2.073538064956665,explained_var_old:0.896,explained_var_new:0.898
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:840, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01817,lr_multiplier:7.594,loss:2.13039231300354,entropy:2.0220677852630615,explained_var_old:0.868,explained_var_new:0.875
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:841, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01847,lr_multiplier:7.594,loss:2.1115341186523438,entropy:2.0576541423797607,explained_var_old:0.907,explained_var_new:0.910
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:842, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02172,lr_multiplier:7.594,loss:2.1291117668151855,entropy:2.044807195663452,explained_var_old:0.867,explained_var_new:0.875
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:843, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02780,lr_multiplier:7.594,loss:2.1437089443206787,entropy:2.107465982437134,explained_var_old:0.905,explained_var_new:0.908
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:844, episode_len:61
TrainPipeline:run: 开始模型训练
kl:0.02325,lr_multiplier:7.594,loss:2.0850982666015625,entropy:2.020463228225708,explained_var_old:0.874,explained_var_new:0.888
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:845, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03836,lr_multiplier:7.594,loss:2.0520927906036377,entropy:1.9542267322540283,explained_var_old:0.845,explained_var_new:0.863
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:846, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02447,lr_multiplier:7.594,loss:2.123962163925171,entropy:2.0576934814453125,explained_var_old:0.883,explained_var_new:0.891
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:847, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02322,lr_multiplier:7.594,loss:2.045976161956787,entropy:1.9986273050308228,explained_var_old:0.897,explained_var_new:0.902
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:848, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02118,lr_multiplier:7.594,loss:2.1382062435150146,entropy:2.0647294521331787,explained_var_old:0.883,explained_var_new:0.888
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:849, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02659,lr_multiplier:7.594,loss:2.1639678478240967,entropy:2.118830680847168,explained_var_old:0.887,explained_var_new:0.892
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:850, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02650,lr_multiplier:7.594,loss:2.096553087234497,entropy:2.0522913932800293,explained_var_old:0.920,explained_var_new:0.925
已经训练: 850轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 8, lose: 2, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:851, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02849,lr_multiplier:7.594,loss:2.0802528858184814,entropy:2.031937599182129,explained_var_old:0.925,explained_var_new:0.929
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:852, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03106,lr_multiplier:7.594,loss:2.0332348346710205,entropy:1.9508285522460938,explained_var_old:0.924,explained_var_new:0.928
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:853, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02356,lr_multiplier:7.594,loss:2.04263973236084,entropy:2.021657705307007,explained_var_old:0.928,explained_var_new:0.932
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:854, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01657,lr_multiplier:7.594,loss:2.035245895385742,entropy:1.9917974472045898,explained_var_old:0.938,explained_var_new:0.942
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:855, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01850,lr_multiplier:7.594,loss:2.1040592193603516,entropy:2.0587828159332275,explained_var_old:0.914,explained_var_new:0.918
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:856, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01860,lr_multiplier:7.594,loss:2.050468921661377,entropy:2.0034191608428955,explained_var_old:0.925,explained_var_new:0.928
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:857, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02300,lr_multiplier:7.594,loss:2.0157933235168457,entropy:1.9725719690322876,explained_var_old:0.936,explained_var_new:0.941
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:858, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02189,lr_multiplier:7.594,loss:2.081540584564209,entropy:2.038731813430786,explained_var_old:0.930,explained_var_new:0.936
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:859, episode_len:47
TrainPipeline:run: 开始模型训练
kl:0.01821,lr_multiplier:7.594,loss:2.085035562515259,entropy:2.0366878509521484,explained_var_old:0.922,explained_var_new:0.926
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:860, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01637,lr_multiplier:7.594,loss:2.065913677215576,entropy:2.0392534732818604,explained_var_old:0.945,explained_var_new:0.951
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:861, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01478,lr_multiplier:7.594,loss:1.9995582103729248,entropy:1.9861520528793335,explained_var_old:0.934,explained_var_new:0.941
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:862, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02268,lr_multiplier:7.594,loss:1.9365726709365845,entropy:1.9053623676300049,explained_var_old:0.950,explained_var_new:0.952
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:863, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01852,lr_multiplier:7.594,loss:1.9843130111694336,entropy:1.9560952186584473,explained_var_old:0.948,explained_var_new:0.952
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:864, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02129,lr_multiplier:7.594,loss:2.003300189971924,entropy:1.977402925491333,explained_var_old:0.964,explained_var_new:0.966
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:865, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01555,lr_multiplier:7.594,loss:1.94895601272583,entropy:1.9428246021270752,explained_var_old:0.967,explained_var_new:0.970
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:866, episode_len:46
TrainPipeline:run: 开始模型训练
kl:0.01608,lr_multiplier:7.594,loss:2.056095600128174,entropy:1.9446685314178467,explained_var_old:0.857,explained_var_new:0.867
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:867, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01375,lr_multiplier:7.594,loss:2.046349048614502,entropy:1.9445080757141113,explained_var_old:0.892,explained_var_new:0.901
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:868, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01505,lr_multiplier:7.594,loss:2.081822156906128,entropy:1.9489693641662598,explained_var_old:0.821,explained_var_new:0.833
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:869, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01212,lr_multiplier:7.594,loss:2.057655096054077,entropy:1.962227463722229,explained_var_old:0.871,explained_var_new:0.882
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:870, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01369,lr_multiplier:7.594,loss:2.024761438369751,entropy:1.93197762966156,explained_var_old:0.879,explained_var_new:0.886
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:871, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01970,lr_multiplier:7.594,loss:2.1019833087921143,entropy:2.0024027824401855,explained_var_old:0.860,explained_var_new:0.871
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:872, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01698,lr_multiplier:7.594,loss:2.0448784828186035,entropy:1.957061767578125,explained_var_old:0.856,explained_var_new:0.883
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:873, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01915,lr_multiplier:7.594,loss:1.963128924369812,entropy:1.8999309539794922,explained_var_old:0.889,explained_var_new:0.897
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:874, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01126,lr_multiplier:7.594,loss:1.9933836460113525,entropy:1.898648977279663,explained_var_old:0.892,explained_var_new:0.901
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:875, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02086,lr_multiplier:7.594,loss:2.0473673343658447,entropy:1.936499834060669,explained_var_old:0.860,explained_var_new:0.873
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:876, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01542,lr_multiplier:7.594,loss:1.956371784210205,entropy:1.8719208240509033,explained_var_old:0.881,explained_var_new:0.891
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:877, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.02465,lr_multiplier:7.594,loss:2.0322279930114746,entropy:1.892418622970581,explained_var_old:0.802,explained_var_new:0.818
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:878, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02008,lr_multiplier:7.594,loss:1.9894033670425415,entropy:1.875913381576538,explained_var_old:0.853,explained_var_new:0.874
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:879, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02175,lr_multiplier:7.594,loss:2.0822136402130127,entropy:1.9025459289550781,explained_var_old:0.797,explained_var_new:0.814
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:880, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01701,lr_multiplier:7.594,loss:2.0679595470428467,entropy:1.975847601890564,explained_var_old:0.847,explained_var_new:0.864
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:881, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01774,lr_multiplier:7.594,loss:2.052400588989258,entropy:1.9020787477493286,explained_var_old:0.809,explained_var_new:0.824
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:882, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01898,lr_multiplier:7.594,loss:1.9733688831329346,entropy:1.858778715133667,explained_var_old:0.825,explained_var_new:0.857
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:883, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01929,lr_multiplier:7.594,loss:2.0079681873321533,entropy:1.883920431137085,explained_var_old:0.886,explained_var_new:0.896
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:884, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01620,lr_multiplier:7.594,loss:1.9978954792022705,entropy:1.9241528511047363,explained_var_old:0.897,explained_var_new:0.914
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:885, episode_len:52
TrainPipeline:run: 开始模型训练
kl:0.01896,lr_multiplier:7.594,loss:2.1109347343444824,entropy:1.924580454826355,explained_var_old:0.750,explained_var_new:0.786
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:886, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01457,lr_multiplier:7.594,loss:2.068124771118164,entropy:1.9040045738220215,explained_var_old:0.770,explained_var_new:0.799
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:887, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02014,lr_multiplier:7.594,loss:2.022977590560913,entropy:1.8919196128845215,explained_var_old:0.841,explained_var_new:0.862
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:888, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02248,lr_multiplier:7.594,loss:2.032921552658081,entropy:1.8782850503921509,explained_var_old:0.774,explained_var_new:0.803
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:889, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02130,lr_multiplier:7.594,loss:2.1099467277526855,entropy:1.957059383392334,explained_var_old:0.813,explained_var_new:0.835
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:890, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02134,lr_multiplier:7.594,loss:2.0828728675842285,entropy:1.8720628023147583,explained_var_old:0.781,explained_var_new:0.809
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:891, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01961,lr_multiplier:7.594,loss:2.0432581901550293,entropy:1.8948675394058228,explained_var_old:0.811,explained_var_new:0.839
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:892, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01885,lr_multiplier:7.594,loss:2.0024425983428955,entropy:1.871052622795105,explained_var_old:0.818,explained_var_new:0.841
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:893, episode_len:46
TrainPipeline:run: 开始模型训练
kl:0.03071,lr_multiplier:7.594,loss:2.059692621231079,entropy:1.8951843976974487,explained_var_old:0.766,explained_var_new:0.799
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:894, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02054,lr_multiplier:7.594,loss:2.1686267852783203,entropy:1.9329736232757568,explained_var_old:0.753,explained_var_new:0.791
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:895, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02316,lr_multiplier:7.594,loss:2.0895721912384033,entropy:1.9254499673843384,explained_var_old:0.766,explained_var_new:0.818
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:896, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02312,lr_multiplier:7.594,loss:2.1030526161193848,entropy:1.9348056316375732,explained_var_old:0.787,explained_var_new:0.816
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:897, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02568,lr_multiplier:7.594,loss:2.1804370880126953,entropy:1.943049669265747,explained_var_old:0.696,explained_var_new:0.739
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:898, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02459,lr_multiplier:7.594,loss:2.1020359992980957,entropy:1.9088187217712402,explained_var_old:0.749,explained_var_new:0.787
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:899, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02361,lr_multiplier:7.594,loss:2.0583431720733643,entropy:1.9061720371246338,explained_var_old:0.770,explained_var_new:0.801
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:900, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03063,lr_multiplier:7.594,loss:2.1274805068969727,entropy:1.944563388824463,explained_var_old:0.734,explained_var_new:0.779
已经训练: 900轮
Game end. Tie
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:1000, win: 5, lose: 4, tie:1
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:901, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03714,lr_multiplier:7.594,loss:2.1163063049316406,entropy:1.9702452421188354,explained_var_old:0.835,explained_var_new:0.860
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:902, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.03450,lr_multiplier:7.594,loss:2.167137861251831,entropy:1.9412699937820435,explained_var_old:0.735,explained_var_new:0.785
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:903, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03419,lr_multiplier:7.594,loss:2.0799942016601562,entropy:1.9670158624649048,explained_var_old:0.790,explained_var_new:0.824
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:904, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02989,lr_multiplier:7.594,loss:2.057101249694824,entropy:1.878102421760559,explained_var_old:0.777,explained_var_new:0.806
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:905, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03238,lr_multiplier:7.594,loss:2.08123779296875,entropy:1.9281455278396606,explained_var_old:0.795,explained_var_new:0.823
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:906, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02580,lr_multiplier:7.594,loss:2.0849533081054688,entropy:1.8911371231079102,explained_var_old:0.724,explained_var_new:0.770
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:907, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02064,lr_multiplier:7.594,loss:2.0939009189605713,entropy:1.899454951286316,explained_var_old:0.777,explained_var_new:0.808
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:908, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02875,lr_multiplier:7.594,loss:2.032227039337158,entropy:1.9754459857940674,explained_var_old:0.836,explained_var_new:0.872
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:909, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02173,lr_multiplier:7.594,loss:2.156407594680786,entropy:1.946412444114685,explained_var_old:0.734,explained_var_new:0.770
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:910, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02337,lr_multiplier:7.594,loss:2.063472270965576,entropy:1.8795969486236572,explained_var_old:0.771,explained_var_new:0.818
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:911, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02883,lr_multiplier:7.594,loss:2.0555360317230225,entropy:1.9164934158325195,explained_var_old:0.798,explained_var_new:0.824
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:912, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03680,lr_multiplier:7.594,loss:2.0726187229156494,entropy:1.8862574100494385,explained_var_old:0.821,explained_var_new:0.852
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:913, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02535,lr_multiplier:7.594,loss:2.0212042331695557,entropy:1.8817744255065918,explained_var_old:0.817,explained_var_new:0.852
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:914, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.02263,lr_multiplier:7.594,loss:2.0482845306396484,entropy:1.9056122303009033,explained_var_old:0.784,explained_var_new:0.809
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:915, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.01769,lr_multiplier:7.594,loss:2.1272833347320557,entropy:1.9382038116455078,explained_var_old:0.762,explained_var_new:0.786
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:916, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02294,lr_multiplier:7.594,loss:1.9626941680908203,entropy:1.8245084285736084,explained_var_old:0.813,explained_var_new:0.823
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:917, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02739,lr_multiplier:7.594,loss:2.0293588638305664,entropy:1.9449784755706787,explained_var_old:0.851,explained_var_new:0.876
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:918, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03017,lr_multiplier:7.594,loss:1.9999955892562866,entropy:1.8733537197113037,explained_var_old:0.807,explained_var_new:0.830
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:919, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02346,lr_multiplier:7.594,loss:2.023844003677368,entropy:1.851241111755371,explained_var_old:0.823,explained_var_new:0.834
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:920, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.03828,lr_multiplier:7.594,loss:2.1470351219177246,entropy:1.980248212814331,explained_var_old:0.788,explained_var_new:0.827
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:921, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02748,lr_multiplier:7.594,loss:2.090686559677124,entropy:1.9336237907409668,explained_var_old:0.795,explained_var_new:0.815
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:922, episode_len:45
TrainPipeline:run: 开始模型训练
kl:0.03297,lr_multiplier:7.594,loss:2.0153439044952393,entropy:1.935470461845398,explained_var_old:0.824,explained_var_new:0.855
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:923, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02718,lr_multiplier:7.594,loss:2.0057456493377686,entropy:1.865621566772461,explained_var_old:0.817,explained_var_new:0.830
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:924, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.03315,lr_multiplier:7.594,loss:2.0145742893218994,entropy:1.8793007135391235,explained_var_old:0.839,explained_var_new:0.860
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:925, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.03270,lr_multiplier:7.594,loss:2.0344221591949463,entropy:1.943028450012207,explained_var_old:0.865,explained_var_new:0.896
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:926, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.02423,lr_multiplier:7.594,loss:2.0552268028259277,entropy:1.951155424118042,explained_var_old:0.854,explained_var_new:0.869
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:927, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.02494,lr_multiplier:7.594,loss:1.975185513496399,entropy:1.912468433380127,explained_var_old:0.893,explained_var_new:0.912
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:928, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02951,lr_multiplier:7.594,loss:2.107752561569214,entropy:1.9378693103790283,explained_var_old:0.825,explained_var_new:0.847
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:929, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02122,lr_multiplier:7.594,loss:2.024718761444092,entropy:1.947322130203247,explained_var_old:0.821,explained_var_new:0.848
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:930, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02633,lr_multiplier:7.594,loss:2.0041701793670654,entropy:1.9023350477218628,explained_var_old:0.850,explained_var_new:0.878
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:931, episode_len:49
TrainPipeline:run: 开始模型训练
kl:0.03722,lr_multiplier:7.594,loss:2.032127618789673,entropy:1.984010934829712,explained_var_old:0.881,explained_var_new:0.902
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:932, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.01975,lr_multiplier:7.594,loss:1.9912433624267578,entropy:1.922218918800354,explained_var_old:0.873,explained_var_new:0.917
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:933, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03880,lr_multiplier:7.594,loss:2.0159718990325928,entropy:1.937265157699585,explained_var_old:0.918,explained_var_new:0.924
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:934, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02563,lr_multiplier:7.594,loss:2.0461978912353516,entropy:1.9682543277740479,explained_var_old:0.913,explained_var_new:0.926
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:935, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02235,lr_multiplier:7.594,loss:1.9807770252227783,entropy:1.9147354364395142,explained_var_old:0.891,explained_var_new:0.909
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:936, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.02952,lr_multiplier:7.594,loss:2.007206916809082,entropy:1.9940232038497925,explained_var_old:0.927,explained_var_new:0.941
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:937, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.03073,lr_multiplier:7.594,loss:2.1483354568481445,entropy:2.0389344692230225,explained_var_old:0.847,explained_var_new:0.866
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:938, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03092,lr_multiplier:7.594,loss:2.0867693424224854,entropy:1.9086453914642334,explained_var_old:0.787,explained_var_new:0.819
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:939, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02229,lr_multiplier:7.594,loss:2.0857126712799072,entropy:1.9550281763076782,explained_var_old:0.785,explained_var_new:0.824
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:940, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03210,lr_multiplier:7.594,loss:2.0609211921691895,entropy:1.9462571144104004,explained_var_old:0.822,explained_var_new:0.844
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:941, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02419,lr_multiplier:7.594,loss:2.046290636062622,entropy:1.9159029722213745,explained_var_old:0.821,explained_var_new:0.856
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:942, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02581,lr_multiplier:7.594,loss:1.997362494468689,entropy:1.9089422225952148,explained_var_old:0.833,explained_var_new:0.873
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:943, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03039,lr_multiplier:7.594,loss:2.1122705936431885,entropy:2.018159866333008,explained_var_old:0.850,explained_var_new:0.870
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:944, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.04526,lr_multiplier:5.062,loss:2.075556755065918,entropy:1.9743530750274658,explained_var_old:0.868,explained_var_new:0.889
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:945, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02124,lr_multiplier:5.062,loss:2.089799642562866,entropy:2.0194833278656006,explained_var_old:0.858,explained_var_new:0.873
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:946, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01517,lr_multiplier:5.062,loss:1.9538723230361938,entropy:1.8750274181365967,explained_var_old:0.867,explained_var_new:0.883
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:947, episode_len:44
TrainPipeline:run: 开始模型训练
kl:0.01828,lr_multiplier:5.062,loss:2.2299857139587402,entropy:1.9879916906356812,explained_var_old:0.707,explained_var_new:0.746
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:948, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01467,lr_multiplier:5.062,loss:2.1525135040283203,entropy:2.0036094188690186,explained_var_old:0.790,explained_var_new:0.812
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:949, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01625,lr_multiplier:5.062,loss:2.233375310897827,entropy:2.0805208683013916,explained_var_old:0.717,explained_var_new:0.767
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:950, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01707,lr_multiplier:5.062,loss:2.141956329345703,entropy:2.0433173179626465,explained_var_old:0.780,explained_var_new:0.816
已经训练: 950轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 9, lose: 1, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:951, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01913,lr_multiplier:5.062,loss:2.228947401046753,entropy:2.0801992416381836,explained_var_old:0.749,explained_var_new:0.794
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:952, episode_len:53
TrainPipeline:run: 开始模型训练
kl:0.01556,lr_multiplier:5.062,loss:2.308044672012329,entropy:2.0905447006225586,explained_var_old:0.698,explained_var_new:0.765
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:953, episode_len:47
TrainPipeline:run: 开始模型训练
kl:0.01640,lr_multiplier:5.062,loss:2.3103229999542236,entropy:2.1204652786254883,explained_var_old:0.749,explained_var_new:0.780
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:954, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01802,lr_multiplier:5.062,loss:2.289768934249878,entropy:2.1149485111236572,explained_var_old:0.755,explained_var_new:0.797
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:955, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03246,lr_multiplier:5.062,loss:2.4068808555603027,entropy:2.2413854598999023,explained_var_old:0.733,explained_var_new:0.775
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:956, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01908,lr_multiplier:5.062,loss:2.299779176712036,entropy:2.166757583618164,explained_var_old:0.782,explained_var_new:0.807
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:957, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02062,lr_multiplier:5.062,loss:2.310637950897217,entropy:2.1554317474365234,explained_var_old:0.754,explained_var_new:0.780
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:958, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01961,lr_multiplier:5.062,loss:2.320988655090332,entropy:2.1825311183929443,explained_var_old:0.766,explained_var_new:0.806
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:959, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01992,lr_multiplier:5.062,loss:2.343897581100464,entropy:2.2075560092926025,explained_var_old:0.782,explained_var_new:0.803
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:960, episode_len:47
TrainPipeline:run: 开始模型训练
kl:0.02388,lr_multiplier:5.062,loss:2.4045584201812744,entropy:2.2110750675201416,explained_var_old:0.685,explained_var_new:0.721
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:961, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.02359,lr_multiplier:5.062,loss:2.4157204627990723,entropy:2.233339786529541,explained_var_old:0.695,explained_var_new:0.732
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:962, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01881,lr_multiplier:5.062,loss:2.265603542327881,entropy:2.1634037494659424,explained_var_old:0.769,explained_var_new:0.794
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:963, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01986,lr_multiplier:5.062,loss:2.357815980911255,entropy:2.2265093326568604,explained_var_old:0.770,explained_var_new:0.799
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:964, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02422,lr_multiplier:5.062,loss:2.399116277694702,entropy:2.2546603679656982,explained_var_old:0.777,explained_var_new:0.800
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:965, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01849,lr_multiplier:5.062,loss:2.406982421875,entropy:2.250730037689209,explained_var_old:0.762,explained_var_new:0.782
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:966, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02473,lr_multiplier:5.062,loss:2.301257371902466,entropy:2.1188509464263916,explained_var_old:0.735,explained_var_new:0.764
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:967, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02930,lr_multiplier:5.062,loss:2.357095956802368,entropy:2.2225985527038574,explained_var_old:0.797,explained_var_new:0.810
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:968, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02134,lr_multiplier:5.062,loss:2.3024768829345703,entropy:2.164637565612793,explained_var_old:0.786,explained_var_new:0.801
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:969, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.01727,lr_multiplier:5.062,loss:2.3295116424560547,entropy:2.2064661979675293,explained_var_old:0.801,explained_var_new:0.815
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:970, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.01612,lr_multiplier:5.062,loss:2.374302387237549,entropy:2.24837064743042,explained_var_old:0.793,explained_var_new:0.813
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:971, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01514,lr_multiplier:5.062,loss:2.3870506286621094,entropy:2.224973201751709,explained_var_old:0.772,explained_var_new:0.793
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:972, episode_len:53
TrainPipeline:run: 开始模型训练
kl:0.02104,lr_multiplier:5.062,loss:2.3456900119781494,entropy:2.19443416595459,explained_var_old:0.763,explained_var_new:0.781
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:973, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01773,lr_multiplier:5.062,loss:2.3980228900909424,entropy:2.309852123260498,explained_var_old:0.789,explained_var_new:0.814
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:974, episode_len:40
TrainPipeline:run: 开始模型训练
kl:0.02094,lr_multiplier:5.062,loss:2.4985275268554688,entropy:2.2495384216308594,explained_var_old:0.663,explained_var_new:0.689
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:975, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01778,lr_multiplier:5.062,loss:2.5775160789489746,entropy:2.3348679542541504,explained_var_old:0.690,explained_var_new:0.715
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:976, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02630,lr_multiplier:5.062,loss:2.4998936653137207,entropy:2.3125250339508057,explained_var_old:0.625,explained_var_new:0.658
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:977, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01886,lr_multiplier:5.062,loss:2.4806160926818848,entropy:2.2943148612976074,explained_var_old:0.655,explained_var_new:0.680
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:978, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02277,lr_multiplier:5.062,loss:2.513601064682007,entropy:2.3371267318725586,explained_var_old:0.697,explained_var_new:0.723
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:979, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01944,lr_multiplier:5.062,loss:2.517124891281128,entropy:2.2810821533203125,explained_var_old:0.656,explained_var_new:0.689
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:980, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.02059,lr_multiplier:5.062,loss:2.5533132553100586,entropy:2.292978525161743,explained_var_old:0.626,explained_var_new:0.673
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:981, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01412,lr_multiplier:5.062,loss:2.4827756881713867,entropy:2.2704474925994873,explained_var_old:0.639,explained_var_new:0.664
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:982, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02284,lr_multiplier:5.062,loss:2.591149091720581,entropy:2.344762086868286,explained_var_old:0.584,explained_var_new:0.628
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:983, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02712,lr_multiplier:5.062,loss:2.534083604812622,entropy:2.3094911575317383,explained_var_old:0.701,explained_var_new:0.727
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:984, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02435,lr_multiplier:5.062,loss:2.5220563411712646,entropy:2.3264565467834473,explained_var_old:0.665,explained_var_new:0.699
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:985, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02725,lr_multiplier:5.062,loss:2.491302728652954,entropy:2.2548828125,explained_var_old:0.585,explained_var_new:0.638
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:986, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02622,lr_multiplier:5.062,loss:2.535282850265503,entropy:2.2638843059539795,explained_var_old:0.625,explained_var_new:0.671
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:987, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01908,lr_multiplier:5.062,loss:2.492274284362793,entropy:2.2812204360961914,explained_var_old:0.630,explained_var_new:0.666
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:988, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02150,lr_multiplier:5.062,loss:2.461611747741699,entropy:2.27052640914917,explained_var_old:0.648,explained_var_new:0.675
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:989, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02024,lr_multiplier:5.062,loss:2.534402370452881,entropy:2.319887161254883,explained_var_old:0.589,explained_var_new:0.623
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:990, episode_len:44
TrainPipeline:run: 开始模型训练
kl:0.01838,lr_multiplier:5.062,loss:2.5357773303985596,entropy:2.287802219390869,explained_var_old:0.568,explained_var_new:0.601
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:991, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02409,lr_multiplier:5.062,loss:2.585573196411133,entropy:2.2792458534240723,explained_var_old:0.399,explained_var_new:0.460
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:992, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02350,lr_multiplier:5.062,loss:2.64288592338562,entropy:2.327812433242798,explained_var_old:0.390,explained_var_new:0.483
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:993, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.01825,lr_multiplier:5.062,loss:2.709594488143921,entropy:2.3151907920837402,explained_var_old:0.276,explained_var_new:0.356
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:994, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02196,lr_multiplier:5.062,loss:2.6250109672546387,entropy:2.274712085723877,explained_var_old:0.383,explained_var_new:0.407
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:995, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01775,lr_multiplier:5.062,loss:2.5154380798339844,entropy:2.2337000370025635,explained_var_old:0.454,explained_var_new:0.500
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:996, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02379,lr_multiplier:5.062,loss:2.564220905303955,entropy:2.2725987434387207,explained_var_old:0.445,explained_var_new:0.475
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:997, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01590,lr_multiplier:5.062,loss:2.567859649658203,entropy:2.234307050704956,explained_var_old:0.493,explained_var_new:0.540
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:998, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02471,lr_multiplier:5.062,loss:2.6073269844055176,entropy:2.2646427154541016,explained_var_old:0.368,explained_var_new:0.425
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:999, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01969,lr_multiplier:5.062,loss:2.591359853744507,entropy:2.2333195209503174,explained_var_old:0.267,explained_var_new:0.304
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1000, episode_len:47
TrainPipeline:run: 开始模型训练
kl:0.03399,lr_multiplier:5.062,loss:2.603679656982422,entropy:2.315032720565796,explained_var_old:0.272,explained_var_new:0.346
已经训练: 1000轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:1000, win: 10, lose: 0, tie:0
相较于MCTS@1000, 截至目前的最佳胜率=1.0 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1001, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01885,lr_multiplier:5.062,loss:2.563204526901245,entropy:2.289991617202759,explained_var_old:0.284,explained_var_new:0.332
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1002, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02605,lr_multiplier:5.062,loss:2.526198625564575,entropy:2.2164573669433594,explained_var_old:0.279,explained_var_new:0.327
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1003, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02611,lr_multiplier:5.062,loss:2.6236672401428223,entropy:2.296048164367676,explained_var_old:0.365,explained_var_new:0.418
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1004, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02559,lr_multiplier:5.062,loss:2.60573673248291,entropy:2.3023808002471924,explained_var_old:0.262,explained_var_new:0.320
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1005, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.01518,lr_multiplier:5.062,loss:2.5995850563049316,entropy:2.2579917907714844,explained_var_old:0.278,explained_var_new:0.317
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1006, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02415,lr_multiplier:5.062,loss:2.516428232192993,entropy:2.2441062927246094,explained_var_old:0.251,explained_var_new:0.298
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1007, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01394,lr_multiplier:5.062,loss:2.616292953491211,entropy:2.3068013191223145,explained_var_old:0.254,explained_var_new:0.273
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1008, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02169,lr_multiplier:5.062,loss:2.6593170166015625,entropy:2.341280698776245,explained_var_old:0.238,explained_var_new:0.273
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1009, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01374,lr_multiplier:5.062,loss:2.586153984069824,entropy:2.332897663116455,explained_var_old:0.191,explained_var_new:0.235
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1010, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01947,lr_multiplier:5.062,loss:2.47554349899292,entropy:2.26895809173584,explained_var_old:0.311,explained_var_new:0.337
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1011, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02441,lr_multiplier:5.062,loss:2.5999789237976074,entropy:2.359642744064331,explained_var_old:0.235,explained_var_new:0.257
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1012, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01900,lr_multiplier:5.062,loss:2.598572015762329,entropy:2.3285911083221436,explained_var_old:0.222,explained_var_new:0.248
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1013, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02178,lr_multiplier:5.062,loss:2.50978684425354,entropy:2.2272305488586426,explained_var_old:0.291,explained_var_new:0.315
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1014, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01868,lr_multiplier:5.062,loss:2.634361982345581,entropy:2.2947044372558594,explained_var_old:0.275,explained_var_new:0.297
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1015, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01534,lr_multiplier:5.062,loss:2.5058915615081787,entropy:2.2298121452331543,explained_var_old:0.309,explained_var_new:0.327
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1016, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01614,lr_multiplier:5.062,loss:2.5517210960388184,entropy:2.27974534034729,explained_var_old:0.209,explained_var_new:0.241
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1017, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.01543,lr_multiplier:5.062,loss:2.6256351470947266,entropy:2.332082509994507,explained_var_old:0.262,explained_var_new:0.284
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1018, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01104,lr_multiplier:5.062,loss:2.6156539916992188,entropy:2.2823925018310547,explained_var_old:0.263,explained_var_new:0.289
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1019, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02826,lr_multiplier:5.062,loss:2.6052072048187256,entropy:2.330458164215088,explained_var_old:0.337,explained_var_new:0.362
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1020, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01353,lr_multiplier:5.062,loss:2.600687026977539,entropy:2.336899757385254,explained_var_old:0.353,explained_var_new:0.379
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1021, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01939,lr_multiplier:5.062,loss:2.5225141048431396,entropy:2.294199228286743,explained_var_old:0.311,explained_var_new:0.343
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1022, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01468,lr_multiplier:5.062,loss:2.464211940765381,entropy:2.281135082244873,explained_var_old:0.332,explained_var_new:0.360
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1023, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02171,lr_multiplier:5.062,loss:2.605806589126587,entropy:2.3888449668884277,explained_var_old:0.314,explained_var_new:0.331
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1024, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02176,lr_multiplier:5.062,loss:2.5191164016723633,entropy:2.3492183685302734,explained_var_old:0.300,explained_var_new:0.319
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1025, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02411,lr_multiplier:5.062,loss:2.490462064743042,entropy:2.3284244537353516,explained_var_old:0.264,explained_var_new:0.280
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1026, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.01899,lr_multiplier:5.062,loss:2.5713844299316406,entropy:2.3436474800109863,explained_var_old:0.109,explained_var_new:0.150
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1027, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02262,lr_multiplier:5.062,loss:2.5136282444000244,entropy:2.306948184967041,explained_var_old:0.242,explained_var_new:0.258
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1028, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01774,lr_multiplier:5.062,loss:2.5458476543426514,entropy:2.3224668502807617,explained_var_old:0.274,explained_var_new:0.310
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1029, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01984,lr_multiplier:5.062,loss:2.560673236846924,entropy:2.3504998683929443,explained_var_old:0.172,explained_var_new:0.203
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1030, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.01931,lr_multiplier:5.062,loss:2.5273611545562744,entropy:2.3551993370056152,explained_var_old:0.295,explained_var_new:0.314
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1031, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.01755,lr_multiplier:5.062,loss:2.5336036682128906,entropy:2.3197169303894043,explained_var_old:0.253,explained_var_new:0.290
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1032, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01880,lr_multiplier:5.062,loss:2.4838132858276367,entropy:2.31386137008667,explained_var_old:0.216,explained_var_new:0.258
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1033, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01754,lr_multiplier:5.062,loss:2.4735918045043945,entropy:2.2688372135162354,explained_var_old:0.227,explained_var_new:0.251
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1034, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.01819,lr_multiplier:5.062,loss:2.5511786937713623,entropy:2.335583209991455,explained_var_old:0.202,explained_var_new:0.246
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1035, episode_len:42
TrainPipeline:run: 开始模型训练
kl:0.01688,lr_multiplier:5.062,loss:2.561192274093628,entropy:2.2883248329162598,explained_var_old:0.103,explained_var_new:0.150
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1036, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01844,lr_multiplier:5.062,loss:2.5743026733398438,entropy:2.301823616027832,explained_var_old:0.155,explained_var_new:0.173
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1037, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01368,lr_multiplier:5.062,loss:2.614943504333496,entropy:2.372689723968506,explained_var_old:0.163,explained_var_new:0.186
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1038, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02336,lr_multiplier:5.062,loss:2.570213794708252,entropy:2.311188220977783,explained_var_old:0.095,explained_var_new:0.126
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1039, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03479,lr_multiplier:5.062,loss:2.560321807861328,entropy:2.337510347366333,explained_var_old:0.115,explained_var_new:0.147
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1040, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02339,lr_multiplier:5.062,loss:2.5120387077331543,entropy:2.3098578453063965,explained_var_old:0.006,explained_var_new:0.058
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1041, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01790,lr_multiplier:5.062,loss:2.597851276397705,entropy:2.30859375,explained_var_old:0.083,explained_var_new:0.102
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1042, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02312,lr_multiplier:5.062,loss:2.5869038105010986,entropy:2.3717246055603027,explained_var_old:0.037,explained_var_new:0.065
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1043, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03117,lr_multiplier:5.062,loss:2.5704355239868164,entropy:2.321429491043091,explained_var_old:0.097,explained_var_new:0.129
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1044, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01476,lr_multiplier:5.062,loss:2.545534610748291,entropy:2.28027081489563,explained_var_old:0.077,explained_var_new:0.094
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1045, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.03238,lr_multiplier:5.062,loss:2.626476526260376,entropy:2.399864435195923,explained_var_old:0.075,explained_var_new:0.092
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1046, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01591,lr_multiplier:5.062,loss:2.568218231201172,entropy:2.346391201019287,explained_var_old:0.128,explained_var_new:0.157
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1047, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02113,lr_multiplier:5.062,loss:2.644153594970703,entropy:2.3833913803100586,explained_var_old:0.137,explained_var_new:0.161
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1048, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02193,lr_multiplier:5.062,loss:2.5891594886779785,entropy:2.3131024837493896,explained_var_old:0.099,explained_var_new:0.136
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1049, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02159,lr_multiplier:5.062,loss:2.5726771354675293,entropy:2.3012266159057617,explained_var_old:0.139,explained_var_new:0.164
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1050, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02201,lr_multiplier:5.062,loss:2.5862255096435547,entropy:2.3325324058532715,explained_var_old:0.166,explained_var_new:0.192
已经训练: 1050轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:2000, win: 6, lose: 4, tie:0
相较于MCTS@2000, 截至目前的最佳胜率=0.6 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1051, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02441,lr_multiplier:5.062,loss:2.493878126144409,entropy:2.266589403152466,explained_var_old:0.096,explained_var_new:0.140
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1052, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02457,lr_multiplier:5.062,loss:2.560443878173828,entropy:2.270512580871582,explained_var_old:0.149,explained_var_new:0.171
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1053, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03021,lr_multiplier:5.062,loss:2.508157730102539,entropy:2.274669647216797,explained_var_old:0.160,explained_var_new:0.187
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1054, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01832,lr_multiplier:5.062,loss:2.47693133354187,entropy:2.3228533267974854,explained_var_old:0.210,explained_var_new:0.238
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1055, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02603,lr_multiplier:5.062,loss:2.4952452182769775,entropy:2.312570333480835,explained_var_old:0.162,explained_var_new:0.193
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1056, episode_len:51
TrainPipeline:run: 开始模型训练
kl:0.01576,lr_multiplier:5.062,loss:2.5580201148986816,entropy:2.343379020690918,explained_var_old:0.018,explained_var_new:0.078
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1057, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02089,lr_multiplier:5.062,loss:2.5002706050872803,entropy:2.310533046722412,explained_var_old:0.146,explained_var_new:0.171
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1058, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01598,lr_multiplier:5.062,loss:2.4794421195983887,entropy:2.3313286304473877,explained_var_old:0.119,explained_var_new:0.142
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1059, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01892,lr_multiplier:5.062,loss:2.405365228652954,entropy:2.3239877223968506,explained_var_old:0.129,explained_var_new:0.148
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1060, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01711,lr_multiplier:5.062,loss:2.4569661617279053,entropy:2.3603572845458984,explained_var_old:0.112,explained_var_new:0.137
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1061, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01574,lr_multiplier:5.062,loss:2.364515542984009,entropy:2.262474536895752,explained_var_old:0.089,explained_var_new:0.112
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1062, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02127,lr_multiplier:5.062,loss:2.4038918018341064,entropy:2.27226185798645,explained_var_old:0.119,explained_var_new:0.134
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1063, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02415,lr_multiplier:5.062,loss:2.3942205905914307,entropy:2.3158133029937744,explained_var_old:0.256,explained_var_new:0.290
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1064, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01452,lr_multiplier:5.062,loss:2.3679847717285156,entropy:2.294731855392456,explained_var_old:0.212,explained_var_new:0.235
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1065, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01610,lr_multiplier:5.062,loss:2.4023094177246094,entropy:2.2975564002990723,explained_var_old:0.224,explained_var_new:0.243
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1066, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00960,lr_multiplier:7.594,loss:2.4297900199890137,entropy:2.3691296577453613,explained_var_old:0.260,explained_var_new:0.278
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1067, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02089,lr_multiplier:7.594,loss:2.3740437030792236,entropy:2.316514730453491,explained_var_old:0.098,explained_var_new:0.164
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1068, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02500,lr_multiplier:7.594,loss:2.3900818824768066,entropy:2.324089288711548,explained_var_old:0.216,explained_var_new:0.229
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1069, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02235,lr_multiplier:7.594,loss:2.37431001663208,entropy:2.3328027725219727,explained_var_old:0.235,explained_var_new:0.257
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1070, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02304,lr_multiplier:7.594,loss:2.3668277263641357,entropy:2.3276448249816895,explained_var_old:0.155,explained_var_new:0.177
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1071, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02317,lr_multiplier:7.594,loss:2.2835700511932373,entropy:2.2495269775390625,explained_var_old:0.045,explained_var_new:0.079
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1072, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03049,lr_multiplier:7.594,loss:2.343951940536499,entropy:2.329782485961914,explained_var_old:0.168,explained_var_new:0.179
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1073, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02780,lr_multiplier:7.594,loss:2.374833583831787,entropy:2.3268203735351562,explained_var_old:0.203,explained_var_new:0.216
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1074, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02696,lr_multiplier:7.594,loss:2.393063545227051,entropy:2.314218521118164,explained_var_old:0.213,explained_var_new:0.240
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1075, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02475,lr_multiplier:7.594,loss:2.276329278945923,entropy:2.2755215167999268,explained_var_old:0.137,explained_var_new:0.158
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1076, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02541,lr_multiplier:7.594,loss:2.293488025665283,entropy:2.3031809329986572,explained_var_old:-0.057,explained_var_new:0.036
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1077, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02395,lr_multiplier:7.594,loss:2.3349642753601074,entropy:2.3047547340393066,explained_var_old:-0.267,explained_var_new:-0.076
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1078, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02052,lr_multiplier:7.594,loss:2.26794695854187,entropy:2.279705286026001,explained_var_old:0.184,explained_var_new:0.211
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1079, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02848,lr_multiplier:7.594,loss:2.2890779972076416,entropy:2.2860183715820312,explained_var_old:0.140,explained_var_new:0.156
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1080, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.02758,lr_multiplier:7.594,loss:2.311723232269287,entropy:2.279215097427368,explained_var_old:0.086,explained_var_new:0.096
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1081, episode_len:42
TrainPipeline:run: 开始模型训练
kl:0.02021,lr_multiplier:7.594,loss:2.348273515701294,entropy:2.2902612686157227,explained_var_old:0.013,explained_var_new:0.031
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1082, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02833,lr_multiplier:7.594,loss:2.295874834060669,entropy:2.224855661392212,explained_var_old:0.026,explained_var_new:0.044
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1083, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01752,lr_multiplier:7.594,loss:2.368133783340454,entropy:2.2606918811798096,explained_var_old:0.019,explained_var_new:0.042
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1084, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02648,lr_multiplier:7.594,loss:2.332731008529663,entropy:2.281301736831665,explained_var_old:0.028,explained_var_new:0.051
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1085, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01858,lr_multiplier:7.594,loss:2.3193321228027344,entropy:2.2713680267333984,explained_var_old:0.027,explained_var_new:0.036
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1086, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02097,lr_multiplier:7.594,loss:2.3742876052856445,entropy:2.2955174446105957,explained_var_old:0.021,explained_var_new:0.037
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1087, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01857,lr_multiplier:7.594,loss:2.348036050796509,entropy:2.291335105895996,explained_var_old:0.030,explained_var_new:0.047
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1088, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02820,lr_multiplier:7.594,loss:2.2896149158477783,entropy:2.2602627277374268,explained_var_old:0.039,explained_var_new:0.053
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1089, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02752,lr_multiplier:7.594,loss:2.4260611534118652,entropy:2.346489429473877,explained_var_old:0.006,explained_var_new:0.021
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1090, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.03268,lr_multiplier:7.594,loss:2.3774585723876953,entropy:2.322051525115967,explained_var_old:0.040,explained_var_new:0.055
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1091, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03150,lr_multiplier:7.594,loss:2.333503007888794,entropy:2.247553825378418,explained_var_old:0.063,explained_var_new:0.078
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1092, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02103,lr_multiplier:7.594,loss:2.3813467025756836,entropy:2.2730414867401123,explained_var_old:0.053,explained_var_new:0.076
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1093, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03026,lr_multiplier:7.594,loss:2.3351778984069824,entropy:2.2748355865478516,explained_var_old:0.071,explained_var_new:0.083
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1094, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03930,lr_multiplier:7.594,loss:2.318660020828247,entropy:2.2675094604492188,explained_var_old:0.102,explained_var_new:0.115
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1095, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03051,lr_multiplier:7.594,loss:2.298625946044922,entropy:2.2067322731018066,explained_var_old:0.109,explained_var_new:0.125
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1096, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02121,lr_multiplier:7.594,loss:2.359492301940918,entropy:2.279682159423828,explained_var_old:0.078,explained_var_new:0.089
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1097, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.02345,lr_multiplier:7.594,loss:2.40140700340271,entropy:2.2638790607452393,explained_var_old:0.025,explained_var_new:0.034
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1098, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02554,lr_multiplier:7.594,loss:2.380802631378174,entropy:2.274810314178467,explained_var_old:0.021,explained_var_new:0.037
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1099, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01727,lr_multiplier:7.594,loss:2.3788652420043945,entropy:2.301166296005249,explained_var_old:0.032,explained_var_new:0.049
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1100, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02099,lr_multiplier:7.594,loss:2.383845329284668,entropy:2.279557228088379,explained_var_old:0.041,explained_var_new:0.048
已经训练: 1100轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:2000, win: 7, lose: 2, tie:1
相较于MCTS@2000, 截至目前的最佳胜率=0.75 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1101, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02364,lr_multiplier:7.594,loss:2.3937652111053467,entropy:2.2803499698638916,explained_var_old:0.018,explained_var_new:0.040
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1102, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02725,lr_multiplier:7.594,loss:2.3373966217041016,entropy:2.2719147205352783,explained_var_old:-0.021,explained_var_new:0.009
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1103, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02936,lr_multiplier:7.594,loss:2.3077127933502197,entropy:2.2657711505889893,explained_var_old:-0.003,explained_var_new:0.010
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1104, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.02159,lr_multiplier:7.594,loss:2.3999874591827393,entropy:2.285470485687256,explained_var_old:-0.024,explained_var_new:-0.013
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1105, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02137,lr_multiplier:7.594,loss:2.3176276683807373,entropy:2.2578864097595215,explained_var_old:-0.002,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1106, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01512,lr_multiplier:7.594,loss:2.4438085556030273,entropy:2.348254680633545,explained_var_old:0.002,explained_var_new:0.019
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1107, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01567,lr_multiplier:7.594,loss:2.430140972137451,entropy:2.3379955291748047,explained_var_old:0.001,explained_var_new:0.011
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1108, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01797,lr_multiplier:7.594,loss:2.3622887134552,entropy:2.2861642837524414,explained_var_old:0.012,explained_var_new:0.021
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1109, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02006,lr_multiplier:7.594,loss:2.3376846313476562,entropy:2.251377820968628,explained_var_old:0.002,explained_var_new:0.010
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1110, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02024,lr_multiplier:7.594,loss:2.4850962162017822,entropy:2.3814780712127686,explained_var_old:0.024,explained_var_new:0.032
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1111, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01753,lr_multiplier:7.594,loss:2.4072065353393555,entropy:2.3408379554748535,explained_var_old:0.025,explained_var_new:0.038
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1112, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.01598,lr_multiplier:7.594,loss:2.3834145069122314,entropy:2.288572311401367,explained_var_old:-0.009,explained_var_new:-0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1113, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02185,lr_multiplier:7.594,loss:2.3996617794036865,entropy:2.2897815704345703,explained_var_old:-0.004,explained_var_new:0.013
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1114, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01205,lr_multiplier:7.594,loss:2.3996617794036865,entropy:2.3004062175750732,explained_var_old:-0.013,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1115, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01938,lr_multiplier:7.594,loss:2.439241409301758,entropy:2.326077699661255,explained_var_old:0.010,explained_var_new:0.016
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1116, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02062,lr_multiplier:7.594,loss:2.5109217166900635,entropy:2.4204044342041016,explained_var_old:0.011,explained_var_new:0.016
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1117, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.01485,lr_multiplier:7.594,loss:2.4506919384002686,entropy:2.327894926071167,explained_var_old:0.004,explained_var_new:0.010
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1118, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01491,lr_multiplier:7.594,loss:2.441889524459839,entropy:2.310650587081909,explained_var_old:-0.003,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1119, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02058,lr_multiplier:7.594,loss:2.4286959171295166,entropy:2.2837631702423096,explained_var_old:-0.007,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1120, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01890,lr_multiplier:7.594,loss:2.4227676391601562,entropy:2.2796289920806885,explained_var_old:0.014,explained_var_new:0.020
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1121, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00986,lr_multiplier:11.391,loss:2.390631675720215,entropy:2.269676685333252,explained_var_old:0.015,explained_var_new:0.029
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1122, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03062,lr_multiplier:11.391,loss:2.469834566116333,entropy:2.3554859161376953,explained_var_old:0.016,explained_var_new:0.035
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1123, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.03058,lr_multiplier:11.391,loss:2.400428295135498,entropy:2.2903449535369873,explained_var_old:0.027,explained_var_new:0.045
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1124, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01908,lr_multiplier:11.391,loss:2.4611427783966064,entropy:2.294673204421997,explained_var_old:0.028,explained_var_new:0.065
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1125, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02260,lr_multiplier:11.391,loss:2.3885655403137207,entropy:2.2970945835113525,explained_var_old:0.035,explained_var_new:0.082
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1126, episode_len:53
TrainPipeline:run: 开始模型训练
kl:0.02656,lr_multiplier:11.391,loss:2.413713216781616,entropy:2.2479121685028076,explained_var_old:0.066,explained_var_new:0.098
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1127, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02500,lr_multiplier:11.391,loss:2.4152565002441406,entropy:2.275646924972534,explained_var_old:0.071,explained_var_new:0.114
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1128, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02123,lr_multiplier:11.391,loss:2.4407360553741455,entropy:2.295264720916748,explained_var_old:0.094,explained_var_new:0.126
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1129, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03028,lr_multiplier:11.391,loss:2.4178528785705566,entropy:2.2868754863739014,explained_var_old:0.105,explained_var_new:0.123
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1130, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.02171,lr_multiplier:11.391,loss:2.4502217769622803,entropy:2.2832794189453125,explained_var_old:0.164,explained_var_new:0.193
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1131, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02905,lr_multiplier:11.391,loss:2.4497218132019043,entropy:2.2907183170318604,explained_var_old:0.174,explained_var_new:0.202
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1132, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02530,lr_multiplier:11.391,loss:2.3551292419433594,entropy:2.22391939163208,explained_var_old:0.150,explained_var_new:0.183
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1133, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02965,lr_multiplier:11.391,loss:2.405580997467041,entropy:2.2716877460479736,explained_var_old:0.177,explained_var_new:0.207
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1134, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02637,lr_multiplier:11.391,loss:2.497337579727173,entropy:2.315274477005005,explained_var_old:0.072,explained_var_new:0.126
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1135, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02250,lr_multiplier:11.391,loss:2.4913179874420166,entropy:2.3283872604370117,explained_var_old:0.078,explained_var_new:0.126
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1136, episode_len:44
TrainPipeline:run: 开始模型训练
kl:0.02882,lr_multiplier:11.391,loss:2.414776086807251,entropy:2.252027988433838,explained_var_old:0.090,explained_var_new:0.132
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1137, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02572,lr_multiplier:11.391,loss:2.4676756858825684,entropy:2.285428285598755,explained_var_old:0.135,explained_var_new:0.162
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1138, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02600,lr_multiplier:11.391,loss:2.459637403488159,entropy:2.2857630252838135,explained_var_old:0.061,explained_var_new:0.112
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1139, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02312,lr_multiplier:11.391,loss:2.448875904083252,entropy:2.3149497509002686,explained_var_old:0.075,explained_var_new:0.101
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1140, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03125,lr_multiplier:11.391,loss:2.3904480934143066,entropy:2.266672134399414,explained_var_old:0.069,explained_var_new:0.110
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1141, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02506,lr_multiplier:11.391,loss:2.413271903991699,entropy:2.268099069595337,explained_var_old:0.076,explained_var_new:0.105
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1142, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02706,lr_multiplier:11.391,loss:2.4283788204193115,entropy:2.303990364074707,explained_var_old:0.079,explained_var_new:0.125
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1143, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03117,lr_multiplier:11.391,loss:2.4594168663024902,entropy:2.2991552352905273,explained_var_old:0.141,explained_var_new:0.177
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1144, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03212,lr_multiplier:11.391,loss:2.379804849624634,entropy:2.291104555130005,explained_var_old:0.041,explained_var_new:0.094
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1145, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.02795,lr_multiplier:11.391,loss:2.344849109649658,entropy:2.1987240314483643,explained_var_old:0.051,explained_var_new:0.111
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1146, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.03180,lr_multiplier:11.391,loss:2.3846287727355957,entropy:2.284411668777466,explained_var_old:0.021,explained_var_new:0.072
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1147, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02781,lr_multiplier:11.391,loss:2.395322561264038,entropy:2.2074620723724365,explained_var_old:0.090,explained_var_new:0.115
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1148, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02656,lr_multiplier:11.391,loss:2.4817631244659424,entropy:2.338697671890259,explained_var_old:0.080,explained_var_new:0.112
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1149, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02918,lr_multiplier:11.391,loss:2.407623291015625,entropy:2.2668662071228027,explained_var_old:0.103,explained_var_new:0.154
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1150, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03363,lr_multiplier:11.391,loss:2.382290840148926,entropy:2.286870241165161,explained_var_old:0.089,explained_var_new:0.118
已经训练: 1150轮
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:2000, win: 5, lose: 5, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1151, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02966,lr_multiplier:11.391,loss:2.433567523956299,entropy:2.2849748134613037,explained_var_old:0.099,explained_var_new:0.123
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1152, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03050,lr_multiplier:11.391,loss:2.3808865547180176,entropy:2.270810127258301,explained_var_old:0.061,explained_var_new:0.097
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1153, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03343,lr_multiplier:11.391,loss:2.4248404502868652,entropy:2.2588088512420654,explained_var_old:0.064,explained_var_new:0.093
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1154, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02445,lr_multiplier:11.391,loss:2.3864855766296387,entropy:2.2503502368927,explained_var_old:0.073,explained_var_new:0.115
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1155, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02269,lr_multiplier:11.391,loss:2.367751359939575,entropy:2.246683120727539,explained_var_old:0.028,explained_var_new:0.074
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1156, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02270,lr_multiplier:11.391,loss:2.4190659523010254,entropy:2.2737841606140137,explained_var_old:0.101,explained_var_new:0.141
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1157, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02670,lr_multiplier:11.391,loss:2.384021520614624,entropy:2.2713584899902344,explained_var_old:0.091,explained_var_new:0.116
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1158, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.03189,lr_multiplier:11.391,loss:2.370368003845215,entropy:2.2589635848999023,explained_var_old:0.033,explained_var_new:0.098
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1159, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02114,lr_multiplier:11.391,loss:2.354882001876831,entropy:2.2292861938476562,explained_var_old:0.126,explained_var_new:0.158
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1160, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02231,lr_multiplier:11.391,loss:2.2782723903656006,entropy:2.1827824115753174,explained_var_old:0.042,explained_var_new:0.086
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1161, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02746,lr_multiplier:11.391,loss:2.305983781814575,entropy:2.179771900177002,explained_var_old:0.094,explained_var_new:0.134
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1162, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.02663,lr_multiplier:11.391,loss:2.3351986408233643,entropy:2.209638833999634,explained_var_old:0.048,explained_var_new:0.090
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1163, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.03518,lr_multiplier:11.391,loss:2.3939168453216553,entropy:2.2366180419921875,explained_var_old:0.043,explained_var_new:0.082
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1164, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.03196,lr_multiplier:11.391,loss:2.3004841804504395,entropy:2.161433458328247,explained_var_old:0.048,explained_var_new:0.079
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1165, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02462,lr_multiplier:11.391,loss:2.4067893028259277,entropy:2.1686880588531494,explained_var_old:0.060,explained_var_new:0.093
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1166, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02651,lr_multiplier:11.391,loss:2.406017541885376,entropy:2.1859240531921387,explained_var_old:0.086,explained_var_new:0.105
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1167, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.03348,lr_multiplier:11.391,loss:2.38545560836792,entropy:2.165360689163208,explained_var_old:0.105,explained_var_new:0.130
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1168, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02778,lr_multiplier:11.391,loss:2.4483087062835693,entropy:2.2007713317871094,explained_var_old:0.067,explained_var_new:0.099
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1169, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03026,lr_multiplier:11.391,loss:2.4330122470855713,entropy:2.2161166667938232,explained_var_old:0.100,explained_var_new:0.132
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1170, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03285,lr_multiplier:11.391,loss:2.4152731895446777,entropy:2.2056357860565186,explained_var_old:0.086,explained_var_new:0.107
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1171, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.04242,lr_multiplier:7.594,loss:2.4298691749572754,entropy:2.1648306846618652,explained_var_old:0.036,explained_var_new:0.062
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1172, episode_len:48
TrainPipeline:run: 开始模型训练
kl:0.02196,lr_multiplier:7.594,loss:2.454829692840576,entropy:2.1789450645446777,explained_var_old:0.031,explained_var_new:0.061
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1173, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01563,lr_multiplier:7.594,loss:2.4523305892944336,entropy:2.199524402618408,explained_var_old:0.067,explained_var_new:0.087
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1174, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02301,lr_multiplier:7.594,loss:2.383486747741699,entropy:2.1550116539001465,explained_var_old:-0.023,explained_var_new:0.014
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1175, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01594,lr_multiplier:7.594,loss:2.4519991874694824,entropy:2.169067859649658,explained_var_old:0.062,explained_var_new:0.082
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1176, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02312,lr_multiplier:7.594,loss:2.4025728702545166,entropy:2.1734187602996826,explained_var_old:0.034,explained_var_new:0.052
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1177, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03200,lr_multiplier:7.594,loss:2.416635513305664,entropy:2.2105422019958496,explained_var_old:0.050,explained_var_new:0.074
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1178, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02644,lr_multiplier:7.594,loss:2.4471352100372314,entropy:2.211498498916626,explained_var_old:0.037,explained_var_new:0.054
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1179, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02064,lr_multiplier:7.594,loss:2.3794820308685303,entropy:2.1331140995025635,explained_var_old:0.084,explained_var_new:0.108
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1180, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.02422,lr_multiplier:7.594,loss:2.4660801887512207,entropy:2.1901659965515137,explained_var_old:0.061,explained_var_new:0.088
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1181, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02504,lr_multiplier:7.594,loss:2.414376735687256,entropy:2.1805858612060547,explained_var_old:0.082,explained_var_new:0.114
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1182, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01970,lr_multiplier:7.594,loss:2.4348018169403076,entropy:2.1503746509552,explained_var_old:0.106,explained_var_new:0.135
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1183, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01751,lr_multiplier:7.594,loss:2.433947801589966,entropy:2.17753267288208,explained_var_old:0.079,explained_var_new:0.108
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1184, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02463,lr_multiplier:7.594,loss:2.4376277923583984,entropy:2.1102840900421143,explained_var_old:0.088,explained_var_new:0.116
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1185, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02293,lr_multiplier:7.594,loss:2.5077171325683594,entropy:2.238758087158203,explained_var_old:0.067,explained_var_new:0.091
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1186, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02065,lr_multiplier:7.594,loss:2.515773296356201,entropy:2.2054953575134277,explained_var_old:0.098,explained_var_new:0.138
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1187, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01998,lr_multiplier:7.594,loss:2.517932415008545,entropy:2.2398934364318848,explained_var_old:0.068,explained_var_new:0.104
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1188, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02195,lr_multiplier:7.594,loss:2.465984582901001,entropy:2.12296986579895,explained_var_old:0.045,explained_var_new:0.086
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1189, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02016,lr_multiplier:7.594,loss:2.4576940536499023,entropy:2.143315076828003,explained_var_old:0.094,explained_var_new:0.126
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1190, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01668,lr_multiplier:7.594,loss:2.4157564640045166,entropy:2.1757025718688965,explained_var_old:0.054,explained_var_new:0.093
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1191, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01960,lr_multiplier:7.594,loss:2.4668374061584473,entropy:2.20818829536438,explained_var_old:0.093,explained_var_new:0.145
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1192, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.01847,lr_multiplier:7.594,loss:2.42608380317688,entropy:2.1698639392852783,explained_var_old:0.042,explained_var_new:0.081
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1193, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.02486,lr_multiplier:7.594,loss:2.4608566761016846,entropy:2.2381184101104736,explained_var_old:0.048,explained_var_new:0.100
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1194, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02016,lr_multiplier:7.594,loss:2.4262778759002686,entropy:2.1921544075012207,explained_var_old:0.064,explained_var_new:0.100
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1195, episode_len:48
TrainPipeline:run: 开始模型训练
kl:0.02076,lr_multiplier:7.594,loss:2.459979772567749,entropy:2.19816255569458,explained_var_old:0.090,explained_var_new:0.141
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1196, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02062,lr_multiplier:7.594,loss:2.4610559940338135,entropy:2.20770263671875,explained_var_old:0.079,explained_var_new:0.126
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1197, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02299,lr_multiplier:7.594,loss:2.463369369506836,entropy:2.2024288177490234,explained_var_old:0.057,explained_var_new:0.076
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1198, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02613,lr_multiplier:7.594,loss:2.3608641624450684,entropy:2.1520979404449463,explained_var_old:0.015,explained_var_new:0.062
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1199, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02093,lr_multiplier:7.594,loss:2.391050338745117,entropy:2.1180455684661865,explained_var_old:0.047,explained_var_new:0.072
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1200, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01758,lr_multiplier:7.594,loss:2.3957595825195312,entropy:2.178130626678467,explained_var_old:0.011,explained_var_new:0.034
已经训练: 1200轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:2000, win: 7, lose: 3, tie:0
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1201, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03384,lr_multiplier:7.594,loss:2.389662027359009,entropy:2.1387176513671875,explained_var_old:0.031,explained_var_new:0.059
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1202, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02876,lr_multiplier:7.594,loss:2.4235222339630127,entropy:2.171884059906006,explained_var_old:0.059,explained_var_new:0.098
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1203, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02472,lr_multiplier:7.594,loss:2.456165313720703,entropy:2.23722767829895,explained_var_old:0.075,explained_var_new:0.103
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1204, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02861,lr_multiplier:7.594,loss:2.4099807739257812,entropy:2.255493640899658,explained_var_old:0.019,explained_var_new:0.062
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1205, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02094,lr_multiplier:7.594,loss:2.4068429470062256,entropy:2.2500622272491455,explained_var_old:0.096,explained_var_new:0.121
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1206, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02462,lr_multiplier:7.594,loss:2.3804609775543213,entropy:2.227893829345703,explained_var_old:0.047,explained_var_new:0.077
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1207, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.02076,lr_multiplier:7.594,loss:2.4215195178985596,entropy:2.259078025817871,explained_var_old:0.033,explained_var_new:0.076
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1208, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02071,lr_multiplier:7.594,loss:2.3778929710388184,entropy:2.2424230575561523,explained_var_old:0.008,explained_var_new:0.039
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1209, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01641,lr_multiplier:7.594,loss:2.348828077316284,entropy:2.2068076133728027,explained_var_old:0.042,explained_var_new:0.065
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1210, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02405,lr_multiplier:7.594,loss:2.381521224975586,entropy:2.2818362712860107,explained_var_old:0.047,explained_var_new:0.061
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1211, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.02048,lr_multiplier:7.594,loss:2.4385180473327637,entropy:2.2742679119110107,explained_var_old:0.006,explained_var_new:0.031
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1212, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01692,lr_multiplier:7.594,loss:2.354689121246338,entropy:2.191392421722412,explained_var_old:-0.042,explained_var_new:-0.011
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1213, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02537,lr_multiplier:7.594,loss:2.4431424140930176,entropy:2.219688653945923,explained_var_old:0.043,explained_var_new:0.050
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1214, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02793,lr_multiplier:7.594,loss:2.411695957183838,entropy:2.2564005851745605,explained_var_old:0.031,explained_var_new:0.053
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1215, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02869,lr_multiplier:7.594,loss:2.409416437149048,entropy:2.2513861656188965,explained_var_old:0.017,explained_var_new:0.035
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1216, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01799,lr_multiplier:7.594,loss:2.310131072998047,entropy:2.198692798614502,explained_var_old:0.011,explained_var_new:0.036
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1217, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01892,lr_multiplier:7.594,loss:2.310434103012085,entropy:2.1719038486480713,explained_var_old:-0.012,explained_var_new:0.032
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1218, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01742,lr_multiplier:7.594,loss:2.3551828861236572,entropy:2.2389726638793945,explained_var_old:0.064,explained_var_new:0.076
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1219, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01825,lr_multiplier:7.594,loss:2.28861403465271,entropy:2.1464242935180664,explained_var_old:0.043,explained_var_new:0.062
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1220, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01808,lr_multiplier:7.594,loss:2.360790967941284,entropy:2.259650230407715,explained_var_old:0.029,explained_var_new:0.056
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1221, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01899,lr_multiplier:7.594,loss:2.3359105587005615,entropy:2.2364633083343506,explained_var_old:0.017,explained_var_new:0.037
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1222, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02013,lr_multiplier:7.594,loss:2.2887089252471924,entropy:2.1803700923919678,explained_var_old:0.001,explained_var_new:0.020
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1223, episode_len:36
TrainPipeline:run: 开始模型训练
kl:0.02372,lr_multiplier:7.594,loss:2.3400588035583496,entropy:2.1941399574279785,explained_var_old:0.031,explained_var_new:0.058
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1224, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02910,lr_multiplier:7.594,loss:2.299997091293335,entropy:2.1574625968933105,explained_var_old:0.018,explained_var_new:0.038
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1225, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02111,lr_multiplier:7.594,loss:2.377622127532959,entropy:2.2260594367980957,explained_var_old:0.021,explained_var_new:0.035
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1226, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02471,lr_multiplier:7.594,loss:2.3583531379699707,entropy:2.2367019653320312,explained_var_old:0.057,explained_var_new:0.066
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1227, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02089,lr_multiplier:7.594,loss:2.3515145778656006,entropy:2.1855719089508057,explained_var_old:0.023,explained_var_new:0.049
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1228, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.02113,lr_multiplier:7.594,loss:2.3699653148651123,entropy:2.175783157348633,explained_var_old:0.068,explained_var_new:0.104
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1229, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01714,lr_multiplier:7.594,loss:2.417809009552002,entropy:2.2271299362182617,explained_var_old:0.033,explained_var_new:0.059
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1230, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01656,lr_multiplier:7.594,loss:2.3853588104248047,entropy:2.230386734008789,explained_var_old:0.055,explained_var_new:0.067
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1231, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01562,lr_multiplier:7.594,loss:2.3501317501068115,entropy:2.1886088848114014,explained_var_old:0.085,explained_var_new:0.116
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1232, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01743,lr_multiplier:7.594,loss:2.357935667037964,entropy:2.224034309387207,explained_var_old:0.040,explained_var_new:0.064
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1233, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01975,lr_multiplier:7.594,loss:2.387944221496582,entropy:2.246345043182373,explained_var_old:0.061,explained_var_new:0.080
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1234, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01558,lr_multiplier:7.594,loss:2.399921178817749,entropy:2.246654510498047,explained_var_old:0.082,explained_var_new:0.099
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1235, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01697,lr_multiplier:7.594,loss:2.307579278945923,entropy:2.1759190559387207,explained_var_old:0.093,explained_var_new:0.120
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1236, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01942,lr_multiplier:7.594,loss:2.3408260345458984,entropy:2.2364180088043213,explained_var_old:0.011,explained_var_new:0.034
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1237, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01258,lr_multiplier:7.594,loss:2.326470375061035,entropy:2.185866117477417,explained_var_old:0.031,explained_var_new:0.055
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1238, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01726,lr_multiplier:7.594,loss:2.420530319213867,entropy:2.2701096534729004,explained_var_old:0.042,explained_var_new:0.055
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1239, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01276,lr_multiplier:7.594,loss:2.3855419158935547,entropy:2.2064473628997803,explained_var_old:0.017,explained_var_new:0.030
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1240, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01195,lr_multiplier:7.594,loss:2.301086664199829,entropy:2.128525972366333,explained_var_old:0.020,explained_var_new:0.032
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1241, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01106,lr_multiplier:7.594,loss:2.3382761478424072,entropy:2.1834590435028076,explained_var_old:0.026,explained_var_new:0.039
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1242, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.01402,lr_multiplier:7.594,loss:2.3077332973480225,entropy:2.1420719623565674,explained_var_old:0.013,explained_var_new:0.037
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1243, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01262,lr_multiplier:7.594,loss:2.314922332763672,entropy:2.1462435722351074,explained_var_old:0.022,explained_var_new:0.040
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1244, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01465,lr_multiplier:7.594,loss:2.3749024868011475,entropy:2.1833176612854004,explained_var_old:0.021,explained_var_new:0.035
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1245, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01318,lr_multiplier:7.594,loss:2.283690929412842,entropy:2.135019540786743,explained_var_old:-0.002,explained_var_new:0.023
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1246, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01277,lr_multiplier:7.594,loss:2.2814409732818604,entropy:2.1321263313293457,explained_var_old:0.031,explained_var_new:0.054
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1247, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01622,lr_multiplier:7.594,loss:2.2401363849639893,entropy:2.1465394496917725,explained_var_old:0.065,explained_var_new:0.072
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1248, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01213,lr_multiplier:7.594,loss:2.405686855316162,entropy:2.203840732574463,explained_var_old:0.103,explained_var_new:0.148
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1249, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.01073,lr_multiplier:7.594,loss:2.3075110912323,entropy:2.11450457572937,explained_var_old:0.077,explained_var_new:0.112
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1250, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01089,lr_multiplier:7.594,loss:2.3018577098846436,entropy:2.1256699562072754,explained_var_old:0.089,explained_var_new:0.137
已经训练: 1250轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:2000, win: 7, lose: 2, tie:1
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1251, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01148,lr_multiplier:7.594,loss:2.248296022415161,entropy:2.1161882877349854,explained_var_old:0.157,explained_var_new:0.221
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1252, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01038,lr_multiplier:7.594,loss:2.2818398475646973,entropy:2.166959047317505,explained_var_old:0.210,explained_var_new:0.248
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1253, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.01285,lr_multiplier:7.594,loss:2.262960195541382,entropy:2.085610866546631,explained_var_old:0.138,explained_var_new:0.168
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1254, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.01463,lr_multiplier:7.594,loss:2.2812390327453613,entropy:2.126232624053955,explained_var_old:0.245,explained_var_new:0.298
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1255, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01431,lr_multiplier:7.594,loss:2.260591506958008,entropy:2.090258836746216,explained_var_old:0.181,explained_var_new:0.227
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1256, episode_len:49
TrainPipeline:run: 开始模型训练
kl:0.01312,lr_multiplier:7.594,loss:2.3661012649536133,entropy:2.181884765625,explained_var_old:0.235,explained_var_new:0.265
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1257, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01543,lr_multiplier:7.594,loss:2.2468385696411133,entropy:2.081792116165161,explained_var_old:0.269,explained_var_new:0.302
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1258, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02130,lr_multiplier:7.594,loss:2.331273078918457,entropy:2.1656322479248047,explained_var_old:0.296,explained_var_new:0.318
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1259, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01853,lr_multiplier:7.594,loss:2.3227670192718506,entropy:2.1731226444244385,explained_var_old:0.255,explained_var_new:0.285
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1260, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01821,lr_multiplier:7.594,loss:2.2764790058135986,entropy:2.109968423843384,explained_var_old:0.285,explained_var_new:0.309
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1261, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02164,lr_multiplier:7.594,loss:2.4229400157928467,entropy:2.2594313621520996,explained_var_old:0.116,explained_var_new:0.165
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1262, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02175,lr_multiplier:7.594,loss:2.354750633239746,entropy:2.2098569869995117,explained_var_old:0.126,explained_var_new:0.158
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1263, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02357,lr_multiplier:7.594,loss:2.3569211959838867,entropy:2.1779072284698486,explained_var_old:0.132,explained_var_new:0.162
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1264, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.01813,lr_multiplier:7.594,loss:2.3256683349609375,entropy:2.152175188064575,explained_var_old:0.122,explained_var_new:0.151
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1265, episode_len:36
TrainPipeline:run: 开始模型训练
kl:0.01924,lr_multiplier:7.594,loss:2.385291576385498,entropy:2.1402742862701416,explained_var_old:-0.101,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1266, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01555,lr_multiplier:7.594,loss:2.4134938716888428,entropy:2.198122024536133,explained_var_old:0.001,explained_var_new:0.020
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1267, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00974,lr_multiplier:11.391,loss:2.419994831085205,entropy:2.208315849304199,explained_var_old:0.031,explained_var_new:0.041
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1268, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01957,lr_multiplier:11.391,loss:2.357614517211914,entropy:2.164578676223755,explained_var_old:0.010,explained_var_new:0.039
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1269, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03004,lr_multiplier:11.391,loss:2.3699522018432617,entropy:2.166611671447754,explained_var_old:0.034,explained_var_new:0.067
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1270, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02697,lr_multiplier:11.391,loss:2.447981119155884,entropy:2.198871612548828,explained_var_old:0.035,explained_var_new:0.058
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1271, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02598,lr_multiplier:11.391,loss:2.4093544483184814,entropy:2.1995444297790527,explained_var_old:0.013,explained_var_new:0.060
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1272, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.02664,lr_multiplier:11.391,loss:2.390897750854492,entropy:2.1606063842773438,explained_var_old:0.033,explained_var_new:0.064
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1273, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02454,lr_multiplier:11.391,loss:2.3275516033172607,entropy:2.1581077575683594,explained_var_old:0.053,explained_var_new:0.092
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1274, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02546,lr_multiplier:11.391,loss:2.2935237884521484,entropy:2.1340951919555664,explained_var_old:-0.011,explained_var_new:0.018
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1275, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02444,lr_multiplier:11.391,loss:2.419550657272339,entropy:2.2077412605285645,explained_var_old:0.039,explained_var_new:0.064
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1276, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02585,lr_multiplier:11.391,loss:2.3983733654022217,entropy:2.1952216625213623,explained_var_old:0.012,explained_var_new:0.030
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1277, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02661,lr_multiplier:11.391,loss:2.321758270263672,entropy:2.152299642562866,explained_var_old:0.003,explained_var_new:0.041
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1278, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02815,lr_multiplier:11.391,loss:2.328796148300171,entropy:2.1882097721099854,explained_var_old:0.061,explained_var_new:0.081
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1279, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02940,lr_multiplier:11.391,loss:2.3595893383026123,entropy:2.205054759979248,explained_var_old:0.047,explained_var_new:0.061
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1280, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.03918,lr_multiplier:11.391,loss:2.375950336456299,entropy:2.199049949645996,explained_var_old:0.018,explained_var_new:0.028
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1281, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.03055,lr_multiplier:11.391,loss:2.4074525833129883,entropy:2.214527130126953,explained_var_old:0.020,explained_var_new:0.035
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1282, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02224,lr_multiplier:11.391,loss:2.3493311405181885,entropy:2.18497896194458,explained_var_old:0.043,explained_var_new:0.059
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1283, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02414,lr_multiplier:11.391,loss:2.347111225128174,entropy:2.1946678161621094,explained_var_old:0.064,explained_var_new:0.081
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1284, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02837,lr_multiplier:11.391,loss:2.393298625946045,entropy:2.188345432281494,explained_var_old:0.030,explained_var_new:0.073
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1285, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.02693,lr_multiplier:11.391,loss:2.3223798274993896,entropy:2.162020444869995,explained_var_old:0.028,explained_var_new:0.053
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1286, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02157,lr_multiplier:11.391,loss:2.4159462451934814,entropy:2.2511754035949707,explained_var_old:0.043,explained_var_new:0.059
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1287, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02308,lr_multiplier:11.391,loss:2.333078384399414,entropy:2.155574083328247,explained_var_old:0.051,explained_var_new:0.069
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1288, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.02545,lr_multiplier:11.391,loss:2.40366268157959,entropy:2.1676993370056152,explained_var_old:-0.022,explained_var_new:0.008
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1289, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.02434,lr_multiplier:11.391,loss:2.4041714668273926,entropy:2.1643364429473877,explained_var_old:-0.020,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1290, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02720,lr_multiplier:11.391,loss:2.3351988792419434,entropy:2.172334909439087,explained_var_old:0.009,explained_var_new:0.013
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1291, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02459,lr_multiplier:11.391,loss:2.3920416831970215,entropy:2.149271011352539,explained_var_old:0.004,explained_var_new:0.014
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1292, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02870,lr_multiplier:11.391,loss:2.3764140605926514,entropy:2.1622650623321533,explained_var_old:0.014,explained_var_new:0.020
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1293, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02837,lr_multiplier:11.391,loss:2.4988434314727783,entropy:2.2582240104675293,explained_var_old:0.009,explained_var_new:0.022
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1294, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02310,lr_multiplier:11.391,loss:2.378826856613159,entropy:2.1671390533447266,explained_var_old:0.028,explained_var_new:0.042
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1295, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02237,lr_multiplier:11.391,loss:2.3709254264831543,entropy:2.168043851852417,explained_var_old:0.013,explained_var_new:0.026
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1296, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02536,lr_multiplier:11.391,loss:2.3820877075195312,entropy:2.1982879638671875,explained_var_old:-0.016,explained_var_new:0.012
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1297, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02030,lr_multiplier:11.391,loss:2.3912241458892822,entropy:2.1960999965667725,explained_var_old:0.016,explained_var_new:0.020
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1298, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02147,lr_multiplier:11.391,loss:2.311180353164673,entropy:2.124195098876953,explained_var_old:0.003,explained_var_new:0.009
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1299, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02021,lr_multiplier:11.391,loss:2.3241117000579834,entropy:2.0916264057159424,explained_var_old:0.002,explained_var_new:0.011
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1300, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01996,lr_multiplier:11.391,loss:2.3375141620635986,entropy:2.0972862243652344,explained_var_old:0.019,explained_var_new:0.035
已经训练: 1300轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:2000, win: 8, lose: 2, tie:0
相较于MCTS@2000, 截至目前的最佳胜率=0.8 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1301, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01665,lr_multiplier:11.391,loss:2.3029797077178955,entropy:2.1409571170806885,explained_var_old:0.028,explained_var_new:0.033
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1302, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02285,lr_multiplier:11.391,loss:2.3480300903320312,entropy:2.131373167037964,explained_var_old:0.015,explained_var_new:0.034
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1303, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02494,lr_multiplier:11.391,loss:2.400649309158325,entropy:2.1888136863708496,explained_var_old:0.012,explained_var_new:0.018
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1304, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02507,lr_multiplier:11.391,loss:2.3416695594787598,entropy:2.1199302673339844,explained_var_old:0.043,explained_var_new:0.059
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1305, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02974,lr_multiplier:11.391,loss:2.390392780303955,entropy:2.176190137863159,explained_var_old:0.025,explained_var_new:0.038
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1306, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03145,lr_multiplier:11.391,loss:2.4171221256256104,entropy:2.197387456893921,explained_var_old:0.024,explained_var_new:0.034
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1307, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02833,lr_multiplier:11.391,loss:2.3706486225128174,entropy:2.194262742996216,explained_var_old:0.009,explained_var_new:0.024
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1308, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02654,lr_multiplier:11.391,loss:2.364370822906494,entropy:2.146439790725708,explained_var_old:0.029,explained_var_new:0.044
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1309, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02220,lr_multiplier:11.391,loss:2.4180147647857666,entropy:2.171485424041748,explained_var_old:0.029,explained_var_new:0.056
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1310, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02969,lr_multiplier:11.391,loss:2.360938787460327,entropy:2.1297194957733154,explained_var_old:0.016,explained_var_new:0.054
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1311, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02815,lr_multiplier:11.391,loss:2.346705198287964,entropy:2.0644447803497314,explained_var_old:0.054,explained_var_new:0.083
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1312, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.03731,lr_multiplier:11.391,loss:2.3523154258728027,entropy:2.108112335205078,explained_var_old:0.067,explained_var_new:0.110
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1313, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02156,lr_multiplier:11.391,loss:2.179239273071289,entropy:1.9479591846466064,explained_var_old:0.078,explained_var_new:0.117
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1314, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.03129,lr_multiplier:11.391,loss:2.4322729110717773,entropy:2.18630051612854,explained_var_old:0.064,explained_var_new:0.103
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1315, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02986,lr_multiplier:11.391,loss:2.310671806335449,entropy:2.1083335876464844,explained_var_old:0.027,explained_var_new:0.057
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1316, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.03871,lr_multiplier:11.391,loss:2.391509532928467,entropy:2.1534440517425537,explained_var_old:0.064,explained_var_new:0.112
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1317, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02394,lr_multiplier:11.391,loss:2.330169677734375,entropy:2.119905948638916,explained_var_old:0.075,explained_var_new:0.115
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1318, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02430,lr_multiplier:11.391,loss:2.2793924808502197,entropy:2.0866990089416504,explained_var_old:0.093,explained_var_new:0.128
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1319, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02636,lr_multiplier:11.391,loss:2.3236563205718994,entropy:2.0927770137786865,explained_var_old:0.029,explained_var_new:0.073
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1320, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02873,lr_multiplier:11.391,loss:2.2880187034606934,entropy:2.056764841079712,explained_var_old:0.005,explained_var_new:0.050
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1321, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03283,lr_multiplier:11.391,loss:2.3762190341949463,entropy:2.1239941120147705,explained_var_old:0.036,explained_var_new:0.081
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1322, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02900,lr_multiplier:11.391,loss:2.358459234237671,entropy:2.1055855751037598,explained_var_old:0.003,explained_var_new:0.036
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1323, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.03188,lr_multiplier:11.391,loss:2.3939216136932373,entropy:2.1023216247558594,explained_var_old:0.023,explained_var_new:0.046
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1324, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02787,lr_multiplier:11.391,loss:2.3924851417541504,entropy:2.0845179557800293,explained_var_old:0.038,explained_var_new:0.063
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1325, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.03315,lr_multiplier:11.391,loss:2.323408603668213,entropy:2.0187623500823975,explained_var_old:0.033,explained_var_new:0.065
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1326, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.03428,lr_multiplier:11.391,loss:2.422661781311035,entropy:2.1487317085266113,explained_var_old:0.031,explained_var_new:0.074
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1327, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.03962,lr_multiplier:11.391,loss:2.402944803237915,entropy:2.075394868850708,explained_var_old:0.126,explained_var_new:0.171
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1328, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03955,lr_multiplier:11.391,loss:2.4061410427093506,entropy:2.067775249481201,explained_var_old:0.050,explained_var_new:0.089
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1329, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.04121,lr_multiplier:7.594,loss:2.411628007888794,entropy:2.1078665256500244,explained_var_old:0.009,explained_var_new:0.075
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1330, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01599,lr_multiplier:7.594,loss:2.412623405456543,entropy:2.07197904586792,explained_var_old:0.031,explained_var_new:0.076
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1331, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02213,lr_multiplier:7.594,loss:2.395460605621338,entropy:2.1224279403686523,explained_var_old:0.057,explained_var_new:0.088
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1332, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01993,lr_multiplier:7.594,loss:2.336130380630493,entropy:2.017120361328125,explained_var_old:-0.043,explained_var_new:0.017
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1333, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01963,lr_multiplier:7.594,loss:2.4404914379119873,entropy:2.089925765991211,explained_var_old:0.041,explained_var_new:0.057
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1334, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02252,lr_multiplier:7.594,loss:2.4166100025177,entropy:2.1461141109466553,explained_var_old:0.037,explained_var_new:0.055
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1335, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.01996,lr_multiplier:7.594,loss:2.4070353507995605,entropy:2.0928103923797607,explained_var_old:0.044,explained_var_new:0.064
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1336, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01892,lr_multiplier:7.594,loss:2.4027087688446045,entropy:2.0582337379455566,explained_var_old:0.054,explained_var_new:0.082
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1337, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01554,lr_multiplier:7.594,loss:2.3734536170959473,entropy:2.0544960498809814,explained_var_old:0.033,explained_var_new:0.054
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1338, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02014,lr_multiplier:7.594,loss:2.3981032371520996,entropy:2.1466546058654785,explained_var_old:0.078,explained_var_new:0.114
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1339, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02155,lr_multiplier:7.594,loss:2.341574192047119,entropy:2.12783145904541,explained_var_old:0.037,explained_var_new:0.087
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1340, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01815,lr_multiplier:7.594,loss:2.3173859119415283,entropy:2.079587697982788,explained_var_old:0.072,explained_var_new:0.106
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1341, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02004,lr_multiplier:7.594,loss:2.3314669132232666,entropy:2.085806131362915,explained_var_old:0.116,explained_var_new:0.161
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1342, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02252,lr_multiplier:7.594,loss:2.259535074234009,entropy:2.0444047451019287,explained_var_old:0.033,explained_var_new:0.083
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1343, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02103,lr_multiplier:7.594,loss:2.335118055343628,entropy:2.1415419578552246,explained_var_old:0.099,explained_var_new:0.132
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1344, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.02237,lr_multiplier:7.594,loss:2.331167697906494,entropy:2.071702003479004,explained_var_old:0.048,explained_var_new:0.080
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1345, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01868,lr_multiplier:7.594,loss:2.366659164428711,entropy:2.1463687419891357,explained_var_old:0.084,explained_var_new:0.116
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1346, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01840,lr_multiplier:7.594,loss:2.3072381019592285,entropy:2.1339707374572754,explained_var_old:0.113,explained_var_new:0.133
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1347, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02286,lr_multiplier:7.594,loss:2.3541200160980225,entropy:2.1464056968688965,explained_var_old:0.125,explained_var_new:0.146
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1348, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.02096,lr_multiplier:7.594,loss:2.382549524307251,entropy:2.2001829147338867,explained_var_old:0.115,explained_var_new:0.141
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1349, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01928,lr_multiplier:7.594,loss:2.27323579788208,entropy:2.175321340560913,explained_var_old:0.176,explained_var_new:0.205
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1350, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02035,lr_multiplier:7.594,loss:2.2428228855133057,entropy:2.140934944152832,explained_var_old:0.279,explained_var_new:0.318
已经训练: 1350轮
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Tie
Game end. Winner is player 1
num_playouts:2000, win: 6, lose: 0, tie:4
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1351, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02058,lr_multiplier:7.594,loss:2.27630877494812,entropy:2.179285764694214,explained_var_old:0.226,explained_var_new:0.250
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1352, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02290,lr_multiplier:7.594,loss:2.3094322681427,entropy:2.2104249000549316,explained_var_old:0.261,explained_var_new:0.287
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1353, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01978,lr_multiplier:7.594,loss:2.2627782821655273,entropy:2.160109519958496,explained_var_old:0.280,explained_var_new:0.312
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1354, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01562,lr_multiplier:7.594,loss:2.261176824569702,entropy:2.183894157409668,explained_var_old:0.297,explained_var_new:0.317
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1355, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01318,lr_multiplier:7.594,loss:2.3065872192382812,entropy:2.234323501586914,explained_var_old:0.265,explained_var_new:0.286
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1356, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01293,lr_multiplier:7.594,loss:2.2962915897369385,entropy:2.195514440536499,explained_var_old:0.263,explained_var_new:0.302
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1357, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01639,lr_multiplier:7.594,loss:2.2583558559417725,entropy:2.174581289291382,explained_var_old:0.159,explained_var_new:0.205
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1358, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01425,lr_multiplier:7.594,loss:2.2689366340637207,entropy:2.1533572673797607,explained_var_old:0.050,explained_var_new:0.114
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1359, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01244,lr_multiplier:7.594,loss:2.2869675159454346,entropy:2.146611213684082,explained_var_old:0.045,explained_var_new:0.083
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1360, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.01790,lr_multiplier:7.594,loss:2.3294224739074707,entropy:2.2099649906158447,explained_var_old:0.016,explained_var_new:0.032
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1361, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01515,lr_multiplier:7.594,loss:2.2805721759796143,entropy:2.151042938232422,explained_var_old:-0.029,explained_var_new:0.014
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1362, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02054,lr_multiplier:7.594,loss:2.3334267139434814,entropy:2.152449131011963,explained_var_old:0.038,explained_var_new:0.087
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1363, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02113,lr_multiplier:7.594,loss:2.414694309234619,entropy:2.2051920890808105,explained_var_old:0.058,explained_var_new:0.085
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1364, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.01892,lr_multiplier:7.594,loss:2.3649849891662598,entropy:2.198431968688965,explained_var_old:0.001,explained_var_new:0.059
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1365, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02056,lr_multiplier:7.594,loss:2.3081347942352295,entropy:2.1547493934631348,explained_var_old:0.086,explained_var_new:0.106
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1366, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01676,lr_multiplier:7.594,loss:2.3335914611816406,entropy:2.1394472122192383,explained_var_old:0.026,explained_var_new:0.049
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1367, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01268,lr_multiplier:7.594,loss:2.4251556396484375,entropy:2.225712537765503,explained_var_old:0.017,explained_var_new:0.051
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1368, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02097,lr_multiplier:7.594,loss:2.321823835372925,entropy:2.148635149002075,explained_var_old:0.085,explained_var_new:0.143
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1369, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01494,lr_multiplier:7.594,loss:2.2349462509155273,entropy:2.1061694622039795,explained_var_old:0.081,explained_var_new:0.102
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1370, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01613,lr_multiplier:7.594,loss:2.270772933959961,entropy:2.1265101432800293,explained_var_old:0.040,explained_var_new:0.096
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1371, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01348,lr_multiplier:7.594,loss:2.318277359008789,entropy:2.118861675262451,explained_var_old:0.111,explained_var_new:0.138
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1372, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01735,lr_multiplier:7.594,loss:2.289301633834839,entropy:2.1207573413848877,explained_var_old:0.052,explained_var_new:0.086
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1373, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01538,lr_multiplier:7.594,loss:2.297100067138672,entropy:2.138568639755249,explained_var_old:0.010,explained_var_new:0.055
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1374, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01128,lr_multiplier:7.594,loss:2.3417181968688965,entropy:2.1319360733032227,explained_var_old:0.043,explained_var_new:0.079
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1375, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01077,lr_multiplier:7.594,loss:2.298851251602173,entropy:2.11080265045166,explained_var_old:0.093,explained_var_new:0.118
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1376, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01402,lr_multiplier:7.594,loss:2.2982232570648193,entropy:2.090278148651123,explained_var_old:0.021,explained_var_new:0.074
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1377, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01223,lr_multiplier:7.594,loss:2.298858880996704,entropy:2.1194636821746826,explained_var_old:0.003,explained_var_new:0.052
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1378, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01740,lr_multiplier:7.594,loss:2.347557544708252,entropy:2.14249324798584,explained_var_old:0.053,explained_var_new:0.078
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1379, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01523,lr_multiplier:7.594,loss:2.2807095050811768,entropy:2.1124322414398193,explained_var_old:0.054,explained_var_new:0.078
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1380, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01601,lr_multiplier:7.594,loss:2.2544336318969727,entropy:2.0896899700164795,explained_var_old:0.031,explained_var_new:0.050
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1381, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01566,lr_multiplier:7.594,loss:2.296208143234253,entropy:2.1333765983581543,explained_var_old:0.034,explained_var_new:0.068
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1382, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01774,lr_multiplier:7.594,loss:2.2387754917144775,entropy:2.0860657691955566,explained_var_old:0.075,explained_var_new:0.101
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1383, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.01766,lr_multiplier:7.594,loss:2.3117737770080566,entropy:2.1765923500061035,explained_var_old:0.047,explained_var_new:0.100
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1384, episode_len:37
TrainPipeline:run: 开始模型训练
kl:0.01606,lr_multiplier:7.594,loss:2.2753660678863525,entropy:2.1030614376068115,explained_var_old:0.082,explained_var_new:0.177
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1385, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.01338,lr_multiplier:7.594,loss:2.261249542236328,entropy:2.076040267944336,explained_var_old:0.145,explained_var_new:0.210
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1386, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01421,lr_multiplier:7.594,loss:2.21000599861145,entropy:2.076784133911133,explained_var_old:0.162,explained_var_new:0.225
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1387, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01716,lr_multiplier:7.594,loss:2.1958913803100586,entropy:2.0843594074249268,explained_var_old:0.285,explained_var_new:0.325
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1388, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02000,lr_multiplier:7.594,loss:2.2123422622680664,entropy:2.1173386573791504,explained_var_old:0.295,explained_var_new:0.350
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1389, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02008,lr_multiplier:7.594,loss:2.1751654148101807,entropy:2.0511810779571533,explained_var_old:0.242,explained_var_new:0.314
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1390, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02572,lr_multiplier:7.594,loss:2.284623622894287,entropy:2.166008949279785,explained_var_old:0.324,explained_var_new:0.349
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1391, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01994,lr_multiplier:7.594,loss:2.2199714183807373,entropy:2.0768582820892334,explained_var_old:0.329,explained_var_new:0.362
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1392, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02314,lr_multiplier:7.594,loss:2.2364838123321533,entropy:2.1144773960113525,explained_var_old:0.290,explained_var_new:0.316
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1393, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01430,lr_multiplier:7.594,loss:2.1577706336975098,entropy:2.0721676349639893,explained_var_old:0.178,explained_var_new:0.206
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1394, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01707,lr_multiplier:7.594,loss:2.226414203643799,entropy:2.097357988357544,explained_var_old:0.343,explained_var_new:0.373
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1395, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02057,lr_multiplier:7.594,loss:2.1253058910369873,entropy:2.056658983230591,explained_var_old:0.176,explained_var_new:0.245
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1396, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02036,lr_multiplier:7.594,loss:2.222334861755371,entropy:2.131397008895874,explained_var_old:0.264,explained_var_new:0.292
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1397, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01601,lr_multiplier:7.594,loss:2.1139416694641113,entropy:2.0588338375091553,explained_var_old:0.248,explained_var_new:0.283
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1398, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02009,lr_multiplier:7.594,loss:2.116922378540039,entropy:2.05338978767395,explained_var_old:0.240,explained_var_new:0.268
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1399, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01350,lr_multiplier:7.594,loss:2.034235715866089,entropy:1.9754605293273926,explained_var_old:0.271,explained_var_new:0.297
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1400, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02291,lr_multiplier:7.594,loss:2.080888509750366,entropy:2.0272274017333984,explained_var_old:0.341,explained_var_new:0.365
已经训练: 1400轮
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Tie
Game end. Tie
Game end. Tie
Game end. Winner is player 2
num_playouts:2000, win: 3, lose: 3, tie:4
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1401, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01824,lr_multiplier:7.594,loss:2.101928949356079,entropy:2.0306591987609863,explained_var_old:0.361,explained_var_new:0.386
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1402, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01716,lr_multiplier:7.594,loss:2.107661724090576,entropy:2.019063949584961,explained_var_old:0.288,explained_var_new:0.316
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1403, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01642,lr_multiplier:7.594,loss:2.1090645790100098,entropy:2.0538177490234375,explained_var_old:0.429,explained_var_new:0.449
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1404, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01417,lr_multiplier:7.594,loss:2.145598888397217,entropy:2.056710720062256,explained_var_old:0.369,explained_var_new:0.394
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1405, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01415,lr_multiplier:7.594,loss:2.0709688663482666,entropy:2.0379703044891357,explained_var_old:0.180,explained_var_new:0.233
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1406, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01977,lr_multiplier:7.594,loss:1.9838545322418213,entropy:1.905914306640625,explained_var_old:0.168,explained_var_new:0.195
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1407, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02375,lr_multiplier:7.594,loss:2.0840115547180176,entropy:2.055961847305298,explained_var_old:0.178,explained_var_new:0.196
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1408, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.01838,lr_multiplier:7.594,loss:2.0661654472351074,entropy:2.011012554168701,explained_var_old:0.131,explained_var_new:0.142
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1409, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01376,lr_multiplier:7.594,loss:2.0975286960601807,entropy:2.043571949005127,explained_var_old:0.042,explained_var_new:0.057
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1410, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01510,lr_multiplier:7.594,loss:2.0919082164764404,entropy:2.050612211227417,explained_var_old:0.003,explained_var_new:0.020
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1411, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01683,lr_multiplier:7.594,loss:2.09265398979187,entropy:2.0744781494140625,explained_var_old:0.055,explained_var_new:0.078
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1412, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01389,lr_multiplier:7.594,loss:2.142549514770508,entropy:2.097369432449341,explained_var_old:0.148,explained_var_new:0.165
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1413, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01388,lr_multiplier:7.594,loss:2.0266082286834717,entropy:2.0070903301239014,explained_var_old:0.128,explained_var_new:0.146
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1414, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01675,lr_multiplier:7.594,loss:2.087540626525879,entropy:2.039717197418213,explained_var_old:0.162,explained_var_new:0.175
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1415, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01853,lr_multiplier:7.594,loss:2.0278449058532715,entropy:1.9729535579681396,explained_var_old:0.140,explained_var_new:0.151
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1416, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01639,lr_multiplier:7.594,loss:2.0285446643829346,entropy:2.0101475715637207,explained_var_old:0.125,explained_var_new:0.138
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1417, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02247,lr_multiplier:7.594,loss:2.036041736602783,entropy:1.983940601348877,explained_var_old:0.086,explained_var_new:0.099
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1418, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01479,lr_multiplier:7.594,loss:2.1226799488067627,entropy:2.099332809448242,explained_var_old:0.059,explained_var_new:0.075
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1419, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01398,lr_multiplier:7.594,loss:2.079688787460327,entropy:2.0393588542938232,explained_var_old:0.074,explained_var_new:0.085
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1420, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01513,lr_multiplier:7.594,loss:2.031365156173706,entropy:1.966181755065918,explained_var_old:0.115,explained_var_new:0.120
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1421, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01533,lr_multiplier:7.594,loss:2.1217257976531982,entropy:2.099094867706299,explained_var_old:0.017,explained_var_new:0.026
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1422, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01257,lr_multiplier:7.594,loss:2.0299744606018066,entropy:1.9754186868667603,explained_var_old:0.051,explained_var_new:0.063
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1423, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01259,lr_multiplier:7.594,loss:1.9933946132659912,entropy:1.9838180541992188,explained_var_old:-0.018,explained_var_new:0.004
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1424, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01153,lr_multiplier:7.594,loss:2.0339365005493164,entropy:2.000609874725342,explained_var_old:0.038,explained_var_new:0.041
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1425, episode_len:50
TrainPipeline:run: 开始模型训练
kl:0.01244,lr_multiplier:7.594,loss:2.074241876602173,entropy:2.0051660537719727,explained_var_old:-0.010,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1426, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01363,lr_multiplier:7.594,loss:2.068890333175659,entropy:2.022953987121582,explained_var_old:-0.019,explained_var_new:-0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1427, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01294,lr_multiplier:7.594,loss:2.047494649887085,entropy:1.9745357036590576,explained_var_old:-0.004,explained_var_new:0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1428, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01662,lr_multiplier:7.594,loss:1.9949766397476196,entropy:1.9450652599334717,explained_var_old:-0.044,explained_var_new:-0.027
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1429, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01664,lr_multiplier:7.594,loss:2.0530242919921875,entropy:2.042041301727295,explained_var_old:-0.033,explained_var_new:-0.017
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1430, episode_len:45
TrainPipeline:run: 开始模型训练
kl:0.02093,lr_multiplier:7.594,loss:2.056565761566162,entropy:1.9943526983261108,explained_var_old:-0.004,explained_var_new:0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1431, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02199,lr_multiplier:7.594,loss:2.042769432067871,entropy:1.9533737897872925,explained_var_old:0.002,explained_var_new:0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1432, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01835,lr_multiplier:7.594,loss:2.0580568313598633,entropy:2.038444995880127,explained_var_old:-0.006,explained_var_new:-0.005
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1433, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01771,lr_multiplier:7.594,loss:2.080876350402832,entropy:2.0020155906677246,explained_var_old:0.001,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1434, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01876,lr_multiplier:7.594,loss:2.101262092590332,entropy:1.9936954975128174,explained_var_old:-0.009,explained_var_new:-0.008
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1435, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01617,lr_multiplier:7.594,loss:2.080312967300415,entropy:1.994340419769287,explained_var_old:-0.002,explained_var_new:-0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1436, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01279,lr_multiplier:7.594,loss:2.0492920875549316,entropy:1.9725019931793213,explained_var_old:0.002,explained_var_new:0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1437, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01225,lr_multiplier:7.594,loss:2.055920124053955,entropy:1.9911675453186035,explained_var_old:0.000,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1438, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01730,lr_multiplier:7.594,loss:2.033721923828125,entropy:1.9430469274520874,explained_var_old:0.003,explained_var_new:0.004
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1439, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.01859,lr_multiplier:7.594,loss:2.063340902328491,entropy:1.9622347354888916,explained_var_old:0.001,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1440, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01891,lr_multiplier:7.594,loss:2.095964193344116,entropy:2.0250117778778076,explained_var_old:-0.004,explained_var_new:-0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1441, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01842,lr_multiplier:7.594,loss:2.049358606338501,entropy:1.9396666288375854,explained_var_old:-0.003,explained_var_new:-0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1442, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01704,lr_multiplier:7.594,loss:2.0800249576568604,entropy:1.968132734298706,explained_var_old:0.001,explained_var_new:0.004
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1443, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02670,lr_multiplier:7.594,loss:2.1453258991241455,entropy:2.009829044342041,explained_var_old:0.005,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1444, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02415,lr_multiplier:7.594,loss:2.1751952171325684,entropy:1.9830875396728516,explained_var_old:0.002,explained_var_new:0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1445, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02015,lr_multiplier:7.594,loss:2.1220576763153076,entropy:1.9473826885223389,explained_var_old:-0.000,explained_var_new:0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1446, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01668,lr_multiplier:7.594,loss:2.140169143676758,entropy:1.9563149213790894,explained_var_old:-0.002,explained_var_new:-0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1447, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01530,lr_multiplier:7.594,loss:2.1985535621643066,entropy:2.037121057510376,explained_var_old:0.001,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1448, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.01501,lr_multiplier:7.594,loss:2.1862008571624756,entropy:1.9821282625198364,explained_var_old:-0.001,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1449, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01732,lr_multiplier:7.594,loss:2.245939254760742,entropy:2.0426716804504395,explained_var_old:0.006,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1450, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01488,lr_multiplier:7.594,loss:2.1924428939819336,entropy:1.9616374969482422,explained_var_old:0.002,explained_var_new:0.004
已经训练: 1450轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:2000, win: 7, lose: 1, tie:2
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1451, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01379,lr_multiplier:7.594,loss:2.290726661682129,entropy:2.042513847351074,explained_var_old:-0.001,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1452, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01562,lr_multiplier:7.594,loss:2.277409553527832,entropy:2.065793514251709,explained_var_old:0.001,explained_var_new:0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1453, episode_len:48
TrainPipeline:run: 开始模型训练
kl:0.01687,lr_multiplier:7.594,loss:2.2651331424713135,entropy:2.0331501960754395,explained_var_old:0.004,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1454, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01646,lr_multiplier:7.594,loss:2.3051846027374268,entropy:2.0430288314819336,explained_var_old:0.003,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1455, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.01788,lr_multiplier:7.594,loss:2.2540969848632812,entropy:1.9896727800369263,explained_var_old:0.002,explained_var_new:0.014
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1456, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02118,lr_multiplier:7.594,loss:2.286844253540039,entropy:2.0230605602264404,explained_var_old:0.008,explained_var_new:0.035
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1457, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01695,lr_multiplier:7.594,loss:2.2281954288482666,entropy:1.9693111181259155,explained_var_old:0.035,explained_var_new:0.059
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1458, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01576,lr_multiplier:7.594,loss:2.253685474395752,entropy:2.0257058143615723,explained_var_old:0.031,explained_var_new:0.067
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1459, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02318,lr_multiplier:7.594,loss:2.2645888328552246,entropy:1.951228141784668,explained_var_old:0.032,explained_var_new:0.052
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1460, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.02013,lr_multiplier:7.594,loss:2.3179574012756348,entropy:2.0136213302612305,explained_var_old:0.038,explained_var_new:0.061
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1461, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.01542,lr_multiplier:7.594,loss:2.2056076526641846,entropy:1.9201925992965698,explained_var_old:0.017,explained_var_new:0.039
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1462, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02102,lr_multiplier:7.594,loss:2.3266994953155518,entropy:1.9421532154083252,explained_var_old:0.065,explained_var_new:0.087
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1463, episode_len:47
TrainPipeline:run: 开始模型训练
kl:0.02062,lr_multiplier:7.594,loss:2.3346824645996094,entropy:2.010732650756836,explained_var_old:0.044,explained_var_new:0.070
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1464, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02110,lr_multiplier:7.594,loss:2.2686476707458496,entropy:1.9317846298217773,explained_var_old:0.060,explained_var_new:0.075
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1465, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01931,lr_multiplier:7.594,loss:2.403242826461792,entropy:2.0292391777038574,explained_var_old:0.097,explained_var_new:0.114
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1466, episode_len:36
TrainPipeline:run: 开始模型训练
kl:0.02371,lr_multiplier:7.594,loss:2.4026012420654297,entropy:2.0276665687561035,explained_var_old:0.032,explained_var_new:0.066
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1467, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01999,lr_multiplier:7.594,loss:2.4392380714416504,entropy:2.063962936401367,explained_var_old:0.076,explained_var_new:0.092
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1468, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01678,lr_multiplier:7.594,loss:2.326223850250244,entropy:1.9230116605758667,explained_var_old:0.050,explained_var_new:0.066
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1469, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02184,lr_multiplier:7.594,loss:2.4000649452209473,entropy:2.033881664276123,explained_var_old:0.099,explained_var_new:0.130
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1470, episode_len:39
TrainPipeline:run: 开始模型训练
kl:0.02275,lr_multiplier:7.594,loss:2.404892683029175,entropy:1.979607105255127,explained_var_old:0.078,explained_var_new:0.102
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1471, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.02027,lr_multiplier:7.594,loss:2.40035080909729,entropy:2.0018770694732666,explained_var_old:0.064,explained_var_new:0.103
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1472, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02185,lr_multiplier:7.594,loss:2.465636730194092,entropy:2.0020394325256348,explained_var_old:0.081,explained_var_new:0.098
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1473, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02193,lr_multiplier:7.594,loss:2.4494333267211914,entropy:2.031853199005127,explained_var_old:0.072,explained_var_new:0.093
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1474, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02553,lr_multiplier:7.594,loss:2.3855297565460205,entropy:1.994655966758728,explained_var_old:0.100,explained_var_new:0.124
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1475, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.02286,lr_multiplier:7.594,loss:2.4370992183685303,entropy:2.0636980533599854,explained_var_old:0.107,explained_var_new:0.127
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1476, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02349,lr_multiplier:7.594,loss:2.4387412071228027,entropy:2.033402681350708,explained_var_old:0.024,explained_var_new:0.062
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1477, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02591,lr_multiplier:7.594,loss:2.4113402366638184,entropy:1.9556776285171509,explained_var_old:0.058,explained_var_new:0.085
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1478, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.02940,lr_multiplier:7.594,loss:2.3985581398010254,entropy:1.975372314453125,explained_var_old:0.091,explained_var_new:0.130
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1479, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.03250,lr_multiplier:7.594,loss:2.479313611984253,entropy:2.0404651165008545,explained_var_old:0.013,explained_var_new:0.054
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1480, episode_len:18
TrainPipeline:run: 开始模型训练
kl:0.03804,lr_multiplier:7.594,loss:2.4319682121276855,entropy:1.9542156457901,explained_var_old:0.022,explained_var_new:0.050
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1481, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03012,lr_multiplier:7.594,loss:2.3966879844665527,entropy:1.9405255317687988,explained_var_old:0.029,explained_var_new:0.053
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1482, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.03856,lr_multiplier:7.594,loss:2.3962090015411377,entropy:1.9780385494232178,explained_var_old:0.095,explained_var_new:0.123
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1483, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03478,lr_multiplier:7.594,loss:2.3588976860046387,entropy:1.988516092300415,explained_var_old:0.070,explained_var_new:0.094
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1484, episode_len:45
TrainPipeline:run: 开始模型训练
kl:0.02935,lr_multiplier:7.594,loss:2.4379663467407227,entropy:1.9687151908874512,explained_var_old:0.044,explained_var_new:0.068
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1485, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.04069,lr_multiplier:5.062,loss:2.417998790740967,entropy:2.0380754470825195,explained_var_old:0.050,explained_var_new:0.069
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1486, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02445,lr_multiplier:5.062,loss:2.4182143211364746,entropy:2.0198545455932617,explained_var_old:0.057,explained_var_new:0.089
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1487, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01691,lr_multiplier:5.062,loss:2.334252119064331,entropy:1.9143083095550537,explained_var_old:0.042,explained_var_new:0.074
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1488, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01401,lr_multiplier:5.062,loss:2.3951268196105957,entropy:1.9771625995635986,explained_var_old:0.059,explained_var_new:0.075
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1489, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01538,lr_multiplier:5.062,loss:2.4079349040985107,entropy:1.9844021797180176,explained_var_old:0.053,explained_var_new:0.088
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1490, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.01231,lr_multiplier:5.062,loss:2.3748552799224854,entropy:2.0018582344055176,explained_var_old:0.044,explained_var_new:0.088
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1491, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01520,lr_multiplier:5.062,loss:2.3869435787200928,entropy:2.0116870403289795,explained_var_old:0.091,explained_var_new:0.104
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1492, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02308,lr_multiplier:5.062,loss:2.4186763763427734,entropy:2.0102460384368896,explained_var_old:0.037,explained_var_new:0.052
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1493, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.03011,lr_multiplier:5.062,loss:2.3389663696289062,entropy:2.0266199111938477,explained_var_old:0.062,explained_var_new:0.089
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1494, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02176,lr_multiplier:5.062,loss:2.365756034851074,entropy:1.9947974681854248,explained_var_old:0.102,explained_var_new:0.140
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1495, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01821,lr_multiplier:5.062,loss:2.3064098358154297,entropy:1.9819321632385254,explained_var_old:0.088,explained_var_new:0.120
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1496, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01442,lr_multiplier:5.062,loss:2.380967855453491,entropy:2.0350093841552734,explained_var_old:0.106,explained_var_new:0.133
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1497, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01314,lr_multiplier:5.062,loss:2.268794536590576,entropy:1.9198861122131348,explained_var_old:0.084,explained_var_new:0.126
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1498, episode_len:45
TrainPipeline:run: 开始模型训练
kl:0.01428,lr_multiplier:5.062,loss:2.3388211727142334,entropy:1.9722129106521606,explained_var_old:0.059,explained_var_new:0.110
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1499, episode_len:46
TrainPipeline:run: 开始模型训练
kl:0.01919,lr_multiplier:5.062,loss:2.319075107574463,entropy:1.932694435119629,explained_var_old:0.030,explained_var_new:0.056
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1500, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.01560,lr_multiplier:5.062,loss:2.3880486488342285,entropy:1.9435689449310303,explained_var_old:0.072,explained_var_new:0.103
已经训练: 1500轮
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:2000, win: 5, lose: 4, tie:1
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1501, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02071,lr_multiplier:5.062,loss:2.3855435848236084,entropy:1.986173152923584,explained_var_old:0.091,explained_var_new:0.116
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1502, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01967,lr_multiplier:5.062,loss:2.4016494750976562,entropy:1.9918110370635986,explained_var_old:0.082,explained_var_new:0.138
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1503, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02068,lr_multiplier:5.062,loss:2.3456978797912598,entropy:1.9140419960021973,explained_var_old:0.107,explained_var_new:0.142
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1504, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02129,lr_multiplier:5.062,loss:2.3051230907440186,entropy:1.8806078433990479,explained_var_old:0.091,explained_var_new:0.115
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1505, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01470,lr_multiplier:5.062,loss:2.371453285217285,entropy:1.9789881706237793,explained_var_old:0.070,explained_var_new:0.091
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1506, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01362,lr_multiplier:5.062,loss:2.3356735706329346,entropy:1.9316649436950684,explained_var_old:0.125,explained_var_new:0.173
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1507, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01870,lr_multiplier:5.062,loss:2.350442886352539,entropy:1.941980242729187,explained_var_old:0.182,explained_var_new:0.220
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1508, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00860,lr_multiplier:7.594,loss:2.355558395385742,entropy:1.9231195449829102,explained_var_old:0.125,explained_var_new:0.161
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1509, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02122,lr_multiplier:7.594,loss:2.3584656715393066,entropy:1.9430524110794067,explained_var_old:0.169,explained_var_new:0.223
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1510, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02334,lr_multiplier:7.594,loss:2.3355836868286133,entropy:1.9863234758377075,explained_var_old:0.177,explained_var_new:0.246
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1511, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02908,lr_multiplier:7.594,loss:2.2916479110717773,entropy:1.9755284786224365,explained_var_old:0.274,explained_var_new:0.352
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1512, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03185,lr_multiplier:7.594,loss:2.341130018234253,entropy:2.0086820125579834,explained_var_old:0.244,explained_var_new:0.332
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1513, episode_len:11
TrainPipeline:run: 开始模型训练
kl:0.03137,lr_multiplier:7.594,loss:2.1812684535980225,entropy:1.906967282295227,explained_var_old:0.319,explained_var_new:0.377
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1514, episode_len:48
TrainPipeline:run: 开始模型训练
kl:0.02913,lr_multiplier:7.594,loss:2.280850648880005,entropy:1.9379791021347046,explained_var_old:0.228,explained_var_new:0.321
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1515, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03294,lr_multiplier:7.594,loss:2.304551362991333,entropy:1.9792120456695557,explained_var_old:0.330,explained_var_new:0.413
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1516, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02229,lr_multiplier:7.594,loss:2.291510820388794,entropy:2.0017030239105225,explained_var_old:0.315,explained_var_new:0.404
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1517, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02489,lr_multiplier:7.594,loss:2.2473461627960205,entropy:2.005615234375,explained_var_old:0.359,explained_var_new:0.412
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1518, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02168,lr_multiplier:7.594,loss:2.2618672847747803,entropy:1.9831643104553223,explained_var_old:0.353,explained_var_new:0.402
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1519, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.04253,lr_multiplier:5.062,loss:2.267504930496216,entropy:1.960965871810913,explained_var_old:0.202,explained_var_new:0.286
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1520, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02962,lr_multiplier:5.062,loss:2.290919065475464,entropy:1.9911868572235107,explained_var_old:0.320,explained_var_new:0.397
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1521, episode_len:36
TrainPipeline:run: 开始模型训练
kl:0.02569,lr_multiplier:5.062,loss:2.375900983810425,entropy:2.029496431350708,explained_var_old:0.307,explained_var_new:0.351
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1522, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.03327,lr_multiplier:5.062,loss:2.305321455001831,entropy:2.030690908432007,explained_var_old:0.339,explained_var_new:0.389
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1523, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03148,lr_multiplier:5.062,loss:2.354464054107666,entropy:2.0035958290100098,explained_var_old:0.278,explained_var_new:0.352
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1524, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01808,lr_multiplier:5.062,loss:2.332336187362671,entropy:2.0160000324249268,explained_var_old:0.355,explained_var_new:0.403
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1525, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01823,lr_multiplier:5.062,loss:2.2885475158691406,entropy:2.019307851791382,explained_var_old:0.332,explained_var_new:0.400
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1526, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01637,lr_multiplier:5.062,loss:2.2850778102874756,entropy:2.0264971256256104,explained_var_old:0.421,explained_var_new:0.466
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1527, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01740,lr_multiplier:5.062,loss:2.2634994983673096,entropy:1.989179253578186,explained_var_old:0.343,explained_var_new:0.410
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1528, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01540,lr_multiplier:5.062,loss:2.2752468585968018,entropy:2.0075626373291016,explained_var_old:0.313,explained_var_new:0.391
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1529, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01773,lr_multiplier:5.062,loss:2.3435263633728027,entropy:2.0421717166900635,explained_var_old:0.233,explained_var_new:0.289
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1530, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02408,lr_multiplier:5.062,loss:2.1966564655303955,entropy:1.9890614748001099,explained_var_old:0.300,explained_var_new:0.350
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1531, episode_len:43
TrainPipeline:run: 开始模型训练
kl:0.02521,lr_multiplier:5.062,loss:2.304419755935669,entropy:2.053258180618286,explained_var_old:0.373,explained_var_new:0.428
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1532, episode_len:16
TrainPipeline:run: 开始模型训练
kl:0.01451,lr_multiplier:5.062,loss:2.24923038482666,entropy:2.0426409244537354,explained_var_old:0.248,explained_var_new:0.333
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1533, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02791,lr_multiplier:5.062,loss:2.2949037551879883,entropy:1.9759669303894043,explained_var_old:0.231,explained_var_new:0.260
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1534, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03576,lr_multiplier:5.062,loss:2.2061383724212646,entropy:1.9773582220077515,explained_var_old:0.212,explained_var_new:0.273
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1535, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01814,lr_multiplier:5.062,loss:2.250253200531006,entropy:2.049098491668701,explained_var_old:0.268,explained_var_new:0.345
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1536, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01622,lr_multiplier:5.062,loss:2.3292317390441895,entropy:2.0821170806884766,explained_var_old:0.149,explained_var_new:0.238
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1537, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01335,lr_multiplier:5.062,loss:2.2730085849761963,entropy:2.0041792392730713,explained_var_old:0.174,explained_var_new:0.212
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1538, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02157,lr_multiplier:5.062,loss:2.3129193782806396,entropy:2.0668890476226807,explained_var_old:0.112,explained_var_new:0.144
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1539, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01941,lr_multiplier:5.062,loss:2.2439794540405273,entropy:1.9885475635528564,explained_var_old:0.220,explained_var_new:0.278
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1540, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02538,lr_multiplier:5.062,loss:2.3145828247070312,entropy:2.0797016620635986,explained_var_old:0.232,explained_var_new:0.293
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1541, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01359,lr_multiplier:5.062,loss:2.303518772125244,entropy:2.047647714614868,explained_var_old:0.238,explained_var_new:0.278
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1542, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01429,lr_multiplier:5.062,loss:2.3254401683807373,entropy:2.023221492767334,explained_var_old:0.289,explained_var_new:0.338
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1543, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01117,lr_multiplier:5.062,loss:2.2583768367767334,entropy:2.0093116760253906,explained_var_old:0.254,explained_var_new:0.307
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1544, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01615,lr_multiplier:5.062,loss:2.301389694213867,entropy:2.0380265712738037,explained_var_old:0.160,explained_var_new:0.228
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1545, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01019,lr_multiplier:5.062,loss:2.297215461730957,entropy:2.048086166381836,explained_var_old:0.162,explained_var_new:0.192
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1546, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01411,lr_multiplier:5.062,loss:2.2289950847625732,entropy:2.0329957008361816,explained_var_old:0.192,explained_var_new:0.229
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1547, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01267,lr_multiplier:5.062,loss:2.2974557876586914,entropy:2.0280730724334717,explained_var_old:0.092,explained_var_new:0.144
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1548, episode_len:13
TrainPipeline:run: 开始模型训练
kl:0.01181,lr_multiplier:5.062,loss:2.2271997928619385,entropy:1.980873465538025,explained_var_old:0.185,explained_var_new:0.214
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1549, episode_len:54
TrainPipeline:run: 开始模型训练
kl:0.01442,lr_multiplier:5.062,loss:2.3756494522094727,entropy:2.1076910495758057,explained_var_old:0.050,explained_var_new:0.096
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1550, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01078,lr_multiplier:5.062,loss:2.343707323074341,entropy:2.070192813873291,explained_var_old:0.090,explained_var_new:0.145
已经训练: 1550轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:2000, win: 10, lose: 0, tie:0
相较于MCTS@2000, 截至目前的最佳胜率=1.0 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1551, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01622,lr_multiplier:5.062,loss:2.2617135047912598,entropy:1.9976855516433716,explained_var_old:0.151,explained_var_new:0.184
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1552, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01229,lr_multiplier:5.062,loss:2.331512212753296,entropy:2.086702346801758,explained_var_old:0.171,explained_var_new:0.204
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1553, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01422,lr_multiplier:5.062,loss:2.3049376010894775,entropy:2.0441441535949707,explained_var_old:0.174,explained_var_new:0.212
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1554, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01934,lr_multiplier:5.062,loss:2.3924756050109863,entropy:2.0754575729370117,explained_var_old:0.129,explained_var_new:0.189
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1555, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02072,lr_multiplier:5.062,loss:2.3162271976470947,entropy:2.0528035163879395,explained_var_old:0.143,explained_var_new:0.200
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1556, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01739,lr_multiplier:5.062,loss:2.2588002681732178,entropy:2.051757574081421,explained_var_old:0.220,explained_var_new:0.264
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1557, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01500,lr_multiplier:5.062,loss:2.347745656967163,entropy:2.066047191619873,explained_var_old:0.174,explained_var_new:0.220
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1558, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01903,lr_multiplier:5.062,loss:2.2793045043945312,entropy:2.046360492706299,explained_var_old:0.212,explained_var_new:0.249
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1559, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01761,lr_multiplier:5.062,loss:2.2115139961242676,entropy:2.027761459350586,explained_var_old:0.298,explained_var_new:0.332
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1560, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01134,lr_multiplier:5.062,loss:2.255857467651367,entropy:2.072535753250122,explained_var_old:0.246,explained_var_new:0.289
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1561, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.01309,lr_multiplier:5.062,loss:2.3431737422943115,entropy:2.069751501083374,explained_var_old:0.254,explained_var_new:0.298
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1562, episode_len:41
TrainPipeline:run: 开始模型训练
kl:0.01536,lr_multiplier:5.062,loss:2.373293876647949,entropy:2.0867533683776855,explained_var_old:0.092,explained_var_new:0.167
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1563, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01134,lr_multiplier:5.062,loss:2.3439743518829346,entropy:2.1055831909179688,explained_var_old:0.271,explained_var_new:0.309
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1564, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01721,lr_multiplier:5.062,loss:2.2689571380615234,entropy:2.0496530532836914,explained_var_old:0.276,explained_var_new:0.348
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1565, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01136,lr_multiplier:5.062,loss:2.2118020057678223,entropy:2.012643337249756,explained_var_old:0.243,explained_var_new:0.310
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1566, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01426,lr_multiplier:5.062,loss:2.3054966926574707,entropy:2.032977819442749,explained_var_old:0.282,explained_var_new:0.322
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1567, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01163,lr_multiplier:5.062,loss:2.2735702991485596,entropy:2.105722188949585,explained_var_old:0.259,explained_var_new:0.292
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1568, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01600,lr_multiplier:5.062,loss:2.24127459526062,entropy:2.0994958877563477,explained_var_old:0.160,explained_var_new:0.222
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1569, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00884,lr_multiplier:7.594,loss:2.286127805709839,entropy:2.1154119968414307,explained_var_old:0.158,explained_var_new:0.198
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1570, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02184,lr_multiplier:7.594,loss:2.213015079498291,entropy:2.0147206783294678,explained_var_old:0.280,explained_var_new:0.337
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1571, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02440,lr_multiplier:7.594,loss:2.2569565773010254,entropy:2.135821580886841,explained_var_old:0.294,explained_var_new:0.355
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1572, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01800,lr_multiplier:7.594,loss:2.2629520893096924,entropy:2.1217522621154785,explained_var_old:0.368,explained_var_new:0.418
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1573, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.03020,lr_multiplier:7.594,loss:2.2866318225860596,entropy:2.1084961891174316,explained_var_old:0.214,explained_var_new:0.282
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1574, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03170,lr_multiplier:7.594,loss:2.276667594909668,entropy:2.1098456382751465,explained_var_old:0.315,explained_var_new:0.374
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1575, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02131,lr_multiplier:7.594,loss:2.2984938621520996,entropy:2.1098668575286865,explained_var_old:0.309,explained_var_new:0.370
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1576, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01981,lr_multiplier:7.594,loss:2.263688802719116,entropy:2.0957789421081543,explained_var_old:0.381,explained_var_new:0.428
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1577, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.02809,lr_multiplier:7.594,loss:2.2227954864501953,entropy:2.0879993438720703,explained_var_old:0.305,explained_var_new:0.370
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1578, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03294,lr_multiplier:7.594,loss:2.1870062351226807,entropy:2.006443738937378,explained_var_old:0.324,explained_var_new:0.406
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1579, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02492,lr_multiplier:7.594,loss:2.263073444366455,entropy:2.1529600620269775,explained_var_old:0.457,explained_var_new:0.532
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1580, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02396,lr_multiplier:7.594,loss:2.1386945247650146,entropy:2.000798463821411,explained_var_old:0.453,explained_var_new:0.502
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1581, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02536,lr_multiplier:7.594,loss:2.2447402477264404,entropy:2.1456828117370605,explained_var_old:0.422,explained_var_new:0.468
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1582, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.01524,lr_multiplier:7.594,loss:2.2784152030944824,entropy:2.0993289947509766,explained_var_old:0.425,explained_var_new:0.483
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1583, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02550,lr_multiplier:7.594,loss:2.172947645187378,entropy:2.034374237060547,explained_var_old:0.318,explained_var_new:0.390
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1584, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03025,lr_multiplier:7.594,loss:2.1538469791412354,entropy:2.0362002849578857,explained_var_old:0.411,explained_var_new:0.490
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1585, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03637,lr_multiplier:7.594,loss:2.194139003753662,entropy:2.0453948974609375,explained_var_old:0.244,explained_var_new:0.346
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1586, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03046,lr_multiplier:7.594,loss:2.2277469635009766,entropy:2.085172414779663,explained_var_old:0.308,explained_var_new:0.338
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1587, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03081,lr_multiplier:7.594,loss:2.1179373264312744,entropy:2.042353630065918,explained_var_old:0.360,explained_var_new:0.447
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1588, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02612,lr_multiplier:7.594,loss:2.21722674369812,entropy:2.0693070888519287,explained_var_old:0.343,explained_var_new:0.407
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1589, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02454,lr_multiplier:7.594,loss:2.3022947311401367,entropy:2.1726760864257812,explained_var_old:0.342,explained_var_new:0.418
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1590, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02781,lr_multiplier:7.594,loss:2.2049405574798584,entropy:2.089600086212158,explained_var_old:0.423,explained_var_new:0.466
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1591, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02203,lr_multiplier:7.594,loss:2.276150703430176,entropy:2.0851190090179443,explained_var_old:0.443,explained_var_new:0.489
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1592, episode_len:36
TrainPipeline:run: 开始模型训练
kl:0.03204,lr_multiplier:7.594,loss:2.223027467727661,entropy:2.1298465728759766,explained_var_old:0.302,explained_var_new:0.384
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1593, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.03059,lr_multiplier:7.594,loss:2.137751579284668,entropy:1.9829492568969727,explained_var_old:0.347,explained_var_new:0.397
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1594, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02650,lr_multiplier:7.594,loss:2.200531482696533,entropy:2.055755615234375,explained_var_old:0.326,explained_var_new:0.387
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1595, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02014,lr_multiplier:7.594,loss:2.2124509811401367,entropy:2.060396432876587,explained_var_old:0.448,explained_var_new:0.489
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1596, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02503,lr_multiplier:7.594,loss:2.245910882949829,entropy:2.036970376968384,explained_var_old:0.306,explained_var_new:0.371
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1597, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02155,lr_multiplier:7.594,loss:2.2140684127807617,entropy:2.031212329864502,explained_var_old:0.427,explained_var_new:0.473
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1598, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02200,lr_multiplier:7.594,loss:2.2249650955200195,entropy:2.0717482566833496,explained_var_old:0.367,explained_var_new:0.427
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1599, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01629,lr_multiplier:7.594,loss:2.2031097412109375,entropy:2.049574613571167,explained_var_old:0.489,explained_var_new:0.541
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1600, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01838,lr_multiplier:7.594,loss:2.199233293533325,entropy:2.0184221267700195,explained_var_old:0.458,explained_var_new:0.495
已经训练: 1600轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
num_playouts:3000, win: 8, lose: 1, tie:1
相较于MCTS@3000, 截至目前的最佳胜率=0.85 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1601, episode_len:36
TrainPipeline:run: 开始模型训练
kl:0.02756,lr_multiplier:7.594,loss:2.1820993423461914,entropy:1.9882338047027588,explained_var_old:0.388,explained_var_new:0.428
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1602, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02665,lr_multiplier:7.594,loss:2.2979671955108643,entropy:2.078226089477539,explained_var_old:0.343,explained_var_new:0.404
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1603, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01686,lr_multiplier:7.594,loss:2.2384421825408936,entropy:2.021207332611084,explained_var_old:0.411,explained_var_new:0.449
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1604, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01969,lr_multiplier:7.594,loss:2.199150562286377,entropy:2.0005218982696533,explained_var_old:0.426,explained_var_new:0.475
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1605, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02054,lr_multiplier:7.594,loss:2.195605754852295,entropy:2.0017900466918945,explained_var_old:0.489,explained_var_new:0.529
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1606, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02181,lr_multiplier:7.594,loss:2.2512412071228027,entropy:2.03739857673645,explained_var_old:0.425,explained_var_new:0.480
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1607, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02807,lr_multiplier:7.594,loss:2.181428909301758,entropy:2.0065524578094482,explained_var_old:0.447,explained_var_new:0.506
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1608, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.02530,lr_multiplier:7.594,loss:2.0996992588043213,entropy:1.9228813648223877,explained_var_old:0.393,explained_var_new:0.456
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1609, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02242,lr_multiplier:7.594,loss:2.2176990509033203,entropy:1.9598251581192017,explained_var_old:0.418,explained_var_new:0.471
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1610, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02188,lr_multiplier:7.594,loss:2.3105149269104004,entropy:2.089724063873291,explained_var_old:0.357,explained_var_new:0.404
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1611, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.03007,lr_multiplier:7.594,loss:2.2287676334381104,entropy:2.071183204650879,explained_var_old:0.345,explained_var_new:0.425
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1612, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01935,lr_multiplier:7.594,loss:2.234804630279541,entropy:2.0790576934814453,explained_var_old:0.418,explained_var_new:0.465
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1613, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01891,lr_multiplier:7.594,loss:2.2617998123168945,entropy:2.0689330101013184,explained_var_old:0.321,explained_var_new:0.382
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1614, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01802,lr_multiplier:7.594,loss:2.26296329498291,entropy:2.0780820846557617,explained_var_old:0.255,explained_var_new:0.337
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1615, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01400,lr_multiplier:7.594,loss:2.1609034538269043,entropy:2.0119173526763916,explained_var_old:0.378,explained_var_new:0.432
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1616, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01915,lr_multiplier:7.594,loss:2.2275218963623047,entropy:2.021601676940918,explained_var_old:0.359,explained_var_new:0.418
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1617, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02030,lr_multiplier:7.594,loss:2.2302889823913574,entropy:2.00787091255188,explained_var_old:0.242,explained_var_new:0.310
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1618, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02297,lr_multiplier:7.594,loss:2.234156847000122,entropy:2.016691207885742,explained_var_old:0.209,explained_var_new:0.277
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1619, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01640,lr_multiplier:7.594,loss:2.220427989959717,entropy:2.042137861251831,explained_var_old:0.222,explained_var_new:0.298
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1620, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02497,lr_multiplier:7.594,loss:2.2117795944213867,entropy:2.0160105228424072,explained_var_old:0.306,explained_var_new:0.348
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1621, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02849,lr_multiplier:7.594,loss:2.324143409729004,entropy:2.1543519496917725,explained_var_old:0.163,explained_var_new:0.237
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1622, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02539,lr_multiplier:7.594,loss:2.177683115005493,entropy:2.015223503112793,explained_var_old:0.185,explained_var_new:0.238
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1623, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02617,lr_multiplier:7.594,loss:2.151118516921997,entropy:1.989617109298706,explained_var_old:0.203,explained_var_new:0.285
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1624, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02349,lr_multiplier:7.594,loss:2.2404446601867676,entropy:2.0587832927703857,explained_var_old:0.136,explained_var_new:0.218
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1625, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02768,lr_multiplier:7.594,loss:2.251771926879883,entropy:2.090080738067627,explained_var_old:0.173,explained_var_new:0.228
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1626, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02316,lr_multiplier:7.594,loss:2.1919898986816406,entropy:2.0461156368255615,explained_var_old:0.143,explained_var_new:0.231
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1627, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02407,lr_multiplier:7.594,loss:2.202374219894409,entropy:2.0410337448120117,explained_var_old:0.185,explained_var_new:0.269
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1628, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02853,lr_multiplier:7.594,loss:2.2320363521575928,entropy:2.1259164810180664,explained_var_old:0.222,explained_var_new:0.299
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1629, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02613,lr_multiplier:7.594,loss:2.219621181488037,entropy:2.080922842025757,explained_var_old:0.236,explained_var_new:0.327
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1630, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03714,lr_multiplier:7.594,loss:2.165114164352417,entropy:2.0459234714508057,explained_var_old:0.139,explained_var_new:0.209
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1631, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02861,lr_multiplier:7.594,loss:2.192077398300171,entropy:2.0389232635498047,explained_var_old:0.225,explained_var_new:0.306
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1632, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03596,lr_multiplier:7.594,loss:2.182631492614746,entropy:2.085714817047119,explained_var_old:0.220,explained_var_new:0.295
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1633, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02623,lr_multiplier:7.594,loss:2.153085470199585,entropy:2.0001296997070312,explained_var_old:0.280,explained_var_new:0.336
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1634, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02467,lr_multiplier:7.594,loss:2.16788387298584,entropy:2.0871310234069824,explained_var_old:0.328,explained_var_new:0.392
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1635, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02348,lr_multiplier:7.594,loss:2.08379864692688,entropy:2.005441665649414,explained_var_old:0.235,explained_var_new:0.318
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1636, episode_len:24
TrainPipeline:run: 开始模型训练
kl:0.02070,lr_multiplier:7.594,loss:2.1309473514556885,entropy:2.0435502529144287,explained_var_old:0.337,explained_var_new:0.410
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1637, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03064,lr_multiplier:7.594,loss:2.1368567943573,entropy:2.035876989364624,explained_var_old:0.219,explained_var_new:0.277
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1638, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03288,lr_multiplier:7.594,loss:2.1636924743652344,entropy:2.0394680500030518,explained_var_old:0.223,explained_var_new:0.265
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1639, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.04110,lr_multiplier:5.062,loss:2.110309600830078,entropy:1.9926865100860596,explained_var_old:0.170,explained_var_new:0.227
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1640, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01864,lr_multiplier:5.062,loss:1.9755043983459473,entropy:1.8988111019134521,explained_var_old:0.273,explained_var_new:0.336
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1641, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01964,lr_multiplier:5.062,loss:2.0695278644561768,entropy:2.0088889598846436,explained_var_old:0.190,explained_var_new:0.241
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1642, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01265,lr_multiplier:5.062,loss:2.030811309814453,entropy:1.9745360612869263,explained_var_old:0.384,explained_var_new:0.421
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1643, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02057,lr_multiplier:5.062,loss:2.0078511238098145,entropy:1.9361416101455688,explained_var_old:0.276,explained_var_new:0.327
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1644, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01628,lr_multiplier:5.062,loss:2.0934836864471436,entropy:1.9858858585357666,explained_var_old:0.204,explained_var_new:0.280
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1645, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01608,lr_multiplier:5.062,loss:2.079817295074463,entropy:2.0131945610046387,explained_var_old:0.223,explained_var_new:0.279
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1646, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.02601,lr_multiplier:5.062,loss:2.097928285598755,entropy:2.0160226821899414,explained_var_old:0.171,explained_var_new:0.210
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1647, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02110,lr_multiplier:5.062,loss:2.0691678524017334,entropy:2.006692886352539,explained_var_old:0.155,explained_var_new:0.228
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1648, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02374,lr_multiplier:5.062,loss:2.1420679092407227,entropy:2.03444766998291,explained_var_old:-0.013,explained_var_new:0.026
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1649, episode_len:46
TrainPipeline:run: 开始模型训练
kl:0.01885,lr_multiplier:5.062,loss:2.0485000610351562,entropy:1.9644964933395386,explained_var_old:0.033,explained_var_new:0.080
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1650, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01342,lr_multiplier:5.062,loss:2.108668565750122,entropy:1.9912309646606445,explained_var_old:-0.015,explained_var_new:0.037
已经训练: 1650轮
Game end. Winner is player 2
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:3000, win: 5, lose: 3, tie:2
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1651, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01597,lr_multiplier:5.062,loss:2.147500514984131,entropy:2.039926052093506,explained_var_old:0.058,explained_var_new:0.071
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1652, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01346,lr_multiplier:5.062,loss:2.0687754154205322,entropy:1.92244553565979,explained_var_old:0.057,explained_var_new:0.080
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1653, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.01568,lr_multiplier:5.062,loss:2.2025959491729736,entropy:2.0526537895202637,explained_var_old:0.023,explained_var_new:0.048
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1654, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00966,lr_multiplier:7.594,loss:2.0379533767700195,entropy:1.9001294374465942,explained_var_old:0.044,explained_var_new:0.087
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1655, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02373,lr_multiplier:7.594,loss:2.0653512477874756,entropy:1.9255149364471436,explained_var_old:0.074,explained_var_new:0.123
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1656, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03372,lr_multiplier:7.594,loss:2.140286922454834,entropy:2.019061803817749,explained_var_old:0.124,explained_var_new:0.154
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1657, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02430,lr_multiplier:7.594,loss:2.083883762359619,entropy:1.9491288661956787,explained_var_old:0.137,explained_var_new:0.166
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1658, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02434,lr_multiplier:7.594,loss:2.061833620071411,entropy:1.950787901878357,explained_var_old:0.147,explained_var_new:0.180
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1659, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02378,lr_multiplier:7.594,loss:2.041431427001953,entropy:1.964843511581421,explained_var_old:0.097,explained_var_new:0.128
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1660, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02583,lr_multiplier:7.594,loss:2.1095869541168213,entropy:1.996361494064331,explained_var_old:0.105,explained_var_new:0.141
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1661, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01777,lr_multiplier:7.594,loss:2.07599139213562,entropy:2.007683515548706,explained_var_old:0.112,explained_var_new:0.149
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1662, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01342,lr_multiplier:7.594,loss:2.0323119163513184,entropy:1.9570430517196655,explained_var_old:0.165,explained_var_new:0.214
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1663, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01324,lr_multiplier:7.594,loss:2.1230084896087646,entropy:2.036620616912842,explained_var_old:0.132,explained_var_new:0.162
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1664, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01867,lr_multiplier:7.594,loss:2.0434484481811523,entropy:1.9377291202545166,explained_var_old:0.126,explained_var_new:0.153
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1665, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01515,lr_multiplier:7.594,loss:1.9938757419586182,entropy:1.8861280679702759,explained_var_old:0.163,explained_var_new:0.213
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1666, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02870,lr_multiplier:7.594,loss:2.093749761581421,entropy:1.9850596189498901,explained_var_old:0.079,explained_var_new:0.134
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1667, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02535,lr_multiplier:7.594,loss:2.061612129211426,entropy:1.9522188901901245,explained_var_old:0.135,explained_var_new:0.187
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1668, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02482,lr_multiplier:7.594,loss:2.033132553100586,entropy:1.935241460800171,explained_var_old:0.114,explained_var_new:0.152
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1669, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02089,lr_multiplier:7.594,loss:2.0823991298675537,entropy:1.9553989171981812,explained_var_old:0.043,explained_var_new:0.080
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1670, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01936,lr_multiplier:7.594,loss:2.0233945846557617,entropy:1.9178372621536255,explained_var_old:0.128,explained_var_new:0.173
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1671, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02344,lr_multiplier:7.594,loss:1.9346299171447754,entropy:1.9014133214950562,explained_var_old:-0.003,explained_var_new:0.094
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1672, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02703,lr_multiplier:7.594,loss:2.031032085418701,entropy:1.9883620738983154,explained_var_old:0.038,explained_var_new:0.114
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1673, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02878,lr_multiplier:7.594,loss:1.9985718727111816,entropy:1.9827780723571777,explained_var_old:-0.097,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1674, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02078,lr_multiplier:7.594,loss:1.9078373908996582,entropy:1.8831241130828857,explained_var_old:-0.167,explained_var_new:-0.034
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1675, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02555,lr_multiplier:7.594,loss:1.9223084449768066,entropy:1.9053313732147217,explained_var_old:0.017,explained_var_new:0.066
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1676, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02972,lr_multiplier:7.594,loss:1.927203893661499,entropy:1.9202791452407837,explained_var_old:0.049,explained_var_new:0.090
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1677, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02608,lr_multiplier:7.594,loss:1.9988255500793457,entropy:1.9412391185760498,explained_var_old:0.028,explained_var_new:0.070
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1678, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02784,lr_multiplier:7.594,loss:1.964135766029358,entropy:1.9449464082717896,explained_var_old:-0.024,explained_var_new:0.013
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1679, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02314,lr_multiplier:7.594,loss:2.0217502117156982,entropy:1.975368618965149,explained_var_old:0.092,explained_var_new:0.115
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1680, episode_len:40
TrainPipeline:run: 开始模型训练
kl:0.02498,lr_multiplier:7.594,loss:2.0303125381469727,entropy:1.9693547487258911,explained_var_old:0.012,explained_var_new:0.034
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1681, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02100,lr_multiplier:7.594,loss:2.0005853176116943,entropy:1.9412766695022583,explained_var_old:0.019,explained_var_new:0.039
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1682, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02084,lr_multiplier:7.594,loss:2.035580635070801,entropy:1.9684343338012695,explained_var_old:-0.013,explained_var_new:0.019
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1683, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01853,lr_multiplier:7.594,loss:2.1564888954162598,entropy:2.081644296646118,explained_var_old:-0.003,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1684, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01839,lr_multiplier:7.594,loss:2.1172823905944824,entropy:2.033355951309204,explained_var_old:0.018,explained_var_new:0.023
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1685, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02256,lr_multiplier:7.594,loss:2.048804521560669,entropy:1.9637291431427002,explained_var_old:0.003,explained_var_new:0.009
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1686, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02746,lr_multiplier:7.594,loss:2.097968578338623,entropy:1.9973223209381104,explained_var_old:0.017,explained_var_new:0.022
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1687, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01834,lr_multiplier:7.594,loss:2.0030977725982666,entropy:1.9458647966384888,explained_var_old:-0.020,explained_var_new:-0.014
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1688, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01678,lr_multiplier:7.594,loss:2.0238847732543945,entropy:1.9555869102478027,explained_var_old:0.002,explained_var_new:0.017
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1689, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02451,lr_multiplier:7.594,loss:2.0121822357177734,entropy:1.925300121307373,explained_var_old:0.007,explained_var_new:0.009
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1690, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02127,lr_multiplier:7.594,loss:2.034097909927368,entropy:1.9739372730255127,explained_var_old:0.008,explained_var_new:0.012
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1691, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01782,lr_multiplier:7.594,loss:2.0083019733428955,entropy:1.9608232975006104,explained_var_old:0.003,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1692, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01539,lr_multiplier:7.594,loss:2.0468459129333496,entropy:2.0159475803375244,explained_var_old:-0.007,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1693, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01753,lr_multiplier:7.594,loss:2.0779025554656982,entropy:1.990208625793457,explained_var_old:0.007,explained_var_new:0.013
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1694, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01831,lr_multiplier:7.594,loss:2.0385937690734863,entropy:1.9648895263671875,explained_var_old:-0.008,explained_var_new:-0.005
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1695, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01823,lr_multiplier:7.594,loss:2.050239324569702,entropy:1.9338150024414062,explained_var_old:0.020,explained_var_new:0.027
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1696, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01564,lr_multiplier:7.594,loss:2.0171873569488525,entropy:1.954742670059204,explained_var_old:0.006,explained_var_new:0.011
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1697, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01661,lr_multiplier:7.594,loss:2.029097557067871,entropy:1.9285869598388672,explained_var_old:0.025,explained_var_new:0.035
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1698, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02046,lr_multiplier:7.594,loss:2.1339662075042725,entropy:2.0352976322174072,explained_var_old:-0.013,explained_var_new:-0.005
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1699, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01835,lr_multiplier:7.594,loss:1.9462664127349854,entropy:1.8906943798065186,explained_var_old:-0.018,explained_var_new:-0.004
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1700, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.01521,lr_multiplier:7.594,loss:2.011730432510376,entropy:1.9238803386688232,explained_var_old:0.003,explained_var_new:0.013
已经训练: 1700轮
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:3000, win: 8, lose: 1, tie:1
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1701, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.01153,lr_multiplier:7.594,loss:2.004429817199707,entropy:1.8903415203094482,explained_var_old:-0.006,explained_var_new:-0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1702, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.01704,lr_multiplier:7.594,loss:2.0368635654449463,entropy:1.9004567861557007,explained_var_old:0.000,explained_var_new:0.008
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1703, episode_len:38
TrainPipeline:run: 开始模型训练
kl:0.01711,lr_multiplier:7.594,loss:2.016653060913086,entropy:1.8867270946502686,explained_var_old:0.012,explained_var_new:0.017
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1704, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01671,lr_multiplier:7.594,loss:2.095949411392212,entropy:1.9100881814956665,explained_var_old:-0.004,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1705, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01733,lr_multiplier:7.594,loss:2.040832996368408,entropy:1.8907110691070557,explained_var_old:0.010,explained_var_new:0.018
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1706, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02497,lr_multiplier:7.594,loss:2.050713300704956,entropy:1.9008817672729492,explained_var_old:0.005,explained_var_new:0.008
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1707, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02013,lr_multiplier:7.594,loss:2.0056912899017334,entropy:1.8520395755767822,explained_var_old:0.025,explained_var_new:0.030
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1708, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01906,lr_multiplier:7.594,loss:2.035334587097168,entropy:1.8947175741195679,explained_var_old:0.005,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1709, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01645,lr_multiplier:7.594,loss:2.016796350479126,entropy:1.8542060852050781,explained_var_old:0.007,explained_var_new:0.010
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1710, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01957,lr_multiplier:7.594,loss:2.1132659912109375,entropy:1.9097442626953125,explained_var_old:-0.012,explained_var_new:-0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1711, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01466,lr_multiplier:7.594,loss:2.1500680446624756,entropy:1.9766383171081543,explained_var_old:-0.008,explained_var_new:-0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1712, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01864,lr_multiplier:7.594,loss:2.128119707107544,entropy:1.9776825904846191,explained_var_old:0.011,explained_var_new:0.014
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1713, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01856,lr_multiplier:7.594,loss:2.061123847961426,entropy:1.9037590026855469,explained_var_old:-0.002,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1714, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02010,lr_multiplier:7.594,loss:2.119407892227173,entropy:1.9425766468048096,explained_var_old:-0.010,explained_var_new:-0.004
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1715, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02874,lr_multiplier:7.594,loss:2.12398099899292,entropy:1.9260194301605225,explained_var_old:-0.012,explained_var_new:-0.008
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1716, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02435,lr_multiplier:7.594,loss:2.1250338554382324,entropy:1.9545326232910156,explained_var_old:-0.014,explained_var_new:-0.010
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1717, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01959,lr_multiplier:7.594,loss:2.1067988872528076,entropy:1.9360811710357666,explained_var_old:0.003,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1718, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02049,lr_multiplier:7.594,loss:2.1205432415008545,entropy:1.9571739435195923,explained_var_old:-0.006,explained_var_new:-0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1719, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01981,lr_multiplier:7.594,loss:2.069941997528076,entropy:1.854629397392273,explained_var_old:-0.004,explained_var_new:-0.003
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1720, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01942,lr_multiplier:7.594,loss:2.082101345062256,entropy:1.911691427230835,explained_var_old:0.008,explained_var_new:0.010
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1721, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.01977,lr_multiplier:7.594,loss:2.0656697750091553,entropy:1.8930988311767578,explained_var_old:-0.001,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1722, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.01493,lr_multiplier:7.594,loss:2.051741123199463,entropy:1.873132348060608,explained_var_old:0.005,explained_var_new:0.012
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1723, episode_len:34
TrainPipeline:run: 开始模型训练
kl:0.01593,lr_multiplier:7.594,loss:2.156853199005127,entropy:1.9287984371185303,explained_var_old:0.007,explained_var_new:0.015
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1724, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01648,lr_multiplier:7.594,loss:2.1173908710479736,entropy:1.9531959295272827,explained_var_old:0.006,explained_var_new:0.011
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1725, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01680,lr_multiplier:7.594,loss:2.1115264892578125,entropy:1.9380109310150146,explained_var_old:-0.012,explained_var_new:-0.009
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1726, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01490,lr_multiplier:7.594,loss:2.0499019622802734,entropy:1.945595145225525,explained_var_old:0.003,explained_var_new:0.011
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1727, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01941,lr_multiplier:7.594,loss:2.094980001449585,entropy:1.9705344438552856,explained_var_old:-0.004,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1728, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01639,lr_multiplier:7.594,loss:1.9982883930206299,entropy:1.8457080125808716,explained_var_old:-0.003,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1729, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01263,lr_multiplier:7.594,loss:2.0720250606536865,entropy:1.903515100479126,explained_var_old:-0.026,explained_var_new:-0.018
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1730, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01348,lr_multiplier:7.594,loss:2.031709909439087,entropy:1.880758285522461,explained_var_old:-0.018,explained_var_new:-0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1731, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00987,lr_multiplier:11.391,loss:2.0842740535736084,entropy:1.981000542640686,explained_var_old:0.004,explained_var_new:0.005
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1732, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01436,lr_multiplier:11.391,loss:2.103799343109131,entropy:1.9198148250579834,explained_var_old:-0.004,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1733, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01738,lr_multiplier:11.391,loss:2.0719473361968994,entropy:1.8956409692764282,explained_var_old:-0.004,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1734, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01656,lr_multiplier:11.391,loss:2.079721689224243,entropy:1.8742029666900635,explained_var_old:-0.005,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1735, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02277,lr_multiplier:11.391,loss:2.056016206741333,entropy:1.8586745262145996,explained_var_old:0.003,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1736, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02594,lr_multiplier:11.391,loss:2.0892248153686523,entropy:1.8530781269073486,explained_var_old:0.003,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1737, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02374,lr_multiplier:11.391,loss:2.066603899002075,entropy:1.7948395013809204,explained_var_old:0.003,explained_var_new:0.010
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1738, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.03434,lr_multiplier:11.391,loss:2.126737594604492,entropy:1.8615617752075195,explained_var_old:0.013,explained_var_new:0.031
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1739, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.03059,lr_multiplier:11.391,loss:2.0634748935699463,entropy:1.8259791135787964,explained_var_old:0.010,explained_var_new:0.026
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1740, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.03912,lr_multiplier:11.391,loss:2.042703151702881,entropy:1.7749372720718384,explained_var_old:0.043,explained_var_new:0.123
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1741, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.03859,lr_multiplier:11.391,loss:2.0200562477111816,entropy:1.7741296291351318,explained_var_old:0.078,explained_var_new:0.092
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1742, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02773,lr_multiplier:11.391,loss:2.1070494651794434,entropy:1.8097597360610962,explained_var_old:0.090,explained_var_new:0.123
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1743, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.03469,lr_multiplier:11.391,loss:2.128988265991211,entropy:1.8455123901367188,explained_var_old:0.104,explained_var_new:0.147
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1744, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.03299,lr_multiplier:11.391,loss:2.1100363731384277,entropy:1.7592992782592773,explained_var_old:0.111,explained_var_new:0.135
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1745, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02443,lr_multiplier:11.391,loss:2.116788864135742,entropy:1.8522870540618896,explained_var_old:0.135,explained_var_new:0.161
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1746, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02410,lr_multiplier:11.391,loss:2.058342695236206,entropy:1.7635917663574219,explained_var_old:0.149,explained_var_new:0.161
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1747, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02188,lr_multiplier:11.391,loss:2.1027684211730957,entropy:1.825501799583435,explained_var_old:0.212,explained_var_new:0.245
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1748, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01954,lr_multiplier:11.391,loss:2.1051878929138184,entropy:1.8118743896484375,explained_var_old:0.179,explained_var_new:0.204
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1749, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02638,lr_multiplier:11.391,loss:2.090287446975708,entropy:1.7711917161941528,explained_var_old:0.239,explained_var_new:0.270
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1750, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02357,lr_multiplier:11.391,loss:2.140232563018799,entropy:1.8197755813598633,explained_var_old:0.196,explained_var_new:0.226
已经训练: 1750轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:3000, win: 8, lose: 1, tie:1
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1751, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02513,lr_multiplier:11.391,loss:2.0740113258361816,entropy:1.7650153636932373,explained_var_old:0.183,explained_var_new:0.214
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1752, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02327,lr_multiplier:11.391,loss:2.033751964569092,entropy:1.7714191675186157,explained_var_old:0.311,explained_var_new:0.352
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1753, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02886,lr_multiplier:11.391,loss:1.9535640478134155,entropy:1.7833746671676636,explained_var_old:0.480,explained_var_new:0.523
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1754, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02995,lr_multiplier:11.391,loss:1.9978647232055664,entropy:1.8369899988174438,explained_var_old:0.543,explained_var_new:0.575
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1755, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02822,lr_multiplier:11.391,loss:1.93381667137146,entropy:1.7955347299575806,explained_var_old:0.554,explained_var_new:0.595
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1756, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.04139,lr_multiplier:7.594,loss:1.9706881046295166,entropy:1.8008631467819214,explained_var_old:0.600,explained_var_new:0.619
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1757, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02067,lr_multiplier:7.594,loss:1.9774858951568604,entropy:1.8246291875839233,explained_var_old:0.594,explained_var_new:0.614
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1758, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01865,lr_multiplier:7.594,loss:2.045628547668457,entropy:1.8865447044372559,explained_var_old:0.567,explained_var_new:0.577
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1759, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01850,lr_multiplier:7.594,loss:1.9719551801681519,entropy:1.8016729354858398,explained_var_old:0.615,explained_var_new:0.627
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1760, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01578,lr_multiplier:7.594,loss:1.9650534391403198,entropy:1.8333548307418823,explained_var_old:0.597,explained_var_new:0.613
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1761, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02503,lr_multiplier:7.594,loss:1.9817204475402832,entropy:1.8614894151687622,explained_var_old:0.604,explained_var_new:0.626
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1762, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01833,lr_multiplier:7.594,loss:1.9810322523117065,entropy:1.8231562376022339,explained_var_old:0.568,explained_var_new:0.587
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1763, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.01747,lr_multiplier:7.594,loss:1.9996957778930664,entropy:1.8695333003997803,explained_var_old:0.601,explained_var_new:0.612
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1764, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01817,lr_multiplier:7.594,loss:1.9915622472763062,entropy:1.8384959697723389,explained_var_old:0.566,explained_var_new:0.586
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1765, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02115,lr_multiplier:7.594,loss:1.98811674118042,entropy:1.8390525579452515,explained_var_old:0.569,explained_var_new:0.583
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1766, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02205,lr_multiplier:7.594,loss:2.023437976837158,entropy:1.9179105758666992,explained_var_old:0.601,explained_var_new:0.625
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1767, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01953,lr_multiplier:7.594,loss:2.0802342891693115,entropy:1.9268810749053955,explained_var_old:0.543,explained_var_new:0.577
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1768, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02917,lr_multiplier:7.594,loss:2.0364277362823486,entropy:1.8811273574829102,explained_var_old:0.531,explained_var_new:0.544
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1769, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02069,lr_multiplier:7.594,loss:2.062350273132324,entropy:1.941139578819275,explained_var_old:0.480,explained_var_new:0.503
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1770, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.02068,lr_multiplier:7.594,loss:2.0785162448883057,entropy:1.9400235414505005,explained_var_old:0.496,explained_var_new:0.515
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1771, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02456,lr_multiplier:7.594,loss:2.107304811477661,entropy:2.0130488872528076,explained_var_old:0.488,explained_var_new:0.513
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1772, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02499,lr_multiplier:7.594,loss:2.1023426055908203,entropy:1.9836463928222656,explained_var_old:0.482,explained_var_new:0.505
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1773, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02689,lr_multiplier:7.594,loss:2.126455783843994,entropy:2.0086441040039062,explained_var_old:0.482,explained_var_new:0.505
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1774, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02472,lr_multiplier:7.594,loss:2.077298641204834,entropy:1.934882402420044,explained_var_old:0.367,explained_var_new:0.408
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1775, episode_len:44
TrainPipeline:run: 开始模型训练
kl:0.03111,lr_multiplier:7.594,loss:2.155726432800293,entropy:1.9917930364608765,explained_var_old:0.276,explained_var_new:0.319
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1776, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03111,lr_multiplier:7.594,loss:2.10433030128479,entropy:1.9263312816619873,explained_var_old:0.187,explained_var_new:0.241
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1777, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02625,lr_multiplier:7.594,loss:2.2375426292419434,entropy:2.0347769260406494,explained_var_old:0.236,explained_var_new:0.267
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1778, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.02267,lr_multiplier:7.594,loss:2.1436655521392822,entropy:1.9634848833084106,explained_var_old:0.337,explained_var_new:0.374
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1779, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02279,lr_multiplier:7.594,loss:2.1529738903045654,entropy:1.967242956161499,explained_var_old:0.332,explained_var_new:0.358
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1780, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01774,lr_multiplier:7.594,loss:2.2067346572875977,entropy:1.9965803623199463,explained_var_old:0.318,explained_var_new:0.349
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1781, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02337,lr_multiplier:7.594,loss:2.1129634380340576,entropy:1.91123366355896,explained_var_old:0.404,explained_var_new:0.448
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1782, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02930,lr_multiplier:7.594,loss:2.151252269744873,entropy:1.9604995250701904,explained_var_old:0.270,explained_var_new:0.330
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1783, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02043,lr_multiplier:7.594,loss:2.103659152984619,entropy:1.9025157690048218,explained_var_old:0.332,explained_var_new:0.362
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1784, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02480,lr_multiplier:7.594,loss:2.1502513885498047,entropy:1.9773917198181152,explained_var_old:0.343,explained_var_new:0.377
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1785, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02354,lr_multiplier:7.594,loss:2.0990118980407715,entropy:1.9369713068008423,explained_var_old:0.369,explained_var_new:0.403
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1786, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01847,lr_multiplier:7.594,loss:2.1083223819732666,entropy:1.9380879402160645,explained_var_old:0.469,explained_var_new:0.500
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1787, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02302,lr_multiplier:7.594,loss:2.0963592529296875,entropy:1.9354528188705444,explained_var_old:0.423,explained_var_new:0.451
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1788, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02579,lr_multiplier:7.594,loss:2.14510440826416,entropy:1.9216017723083496,explained_var_old:0.404,explained_var_new:0.437
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1789, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02285,lr_multiplier:7.594,loss:2.0800769329071045,entropy:1.9041088819503784,explained_var_old:0.398,explained_var_new:0.438
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1790, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02090,lr_multiplier:7.594,loss:2.161562204360962,entropy:1.9875571727752686,explained_var_old:0.373,explained_var_new:0.414
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1791, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.01534,lr_multiplier:7.594,loss:2.220750570297241,entropy:2.0353221893310547,explained_var_old:0.351,explained_var_new:0.389
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1792, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02083,lr_multiplier:7.594,loss:2.1504886150360107,entropy:1.986656904220581,explained_var_old:0.243,explained_var_new:0.315
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1793, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02003,lr_multiplier:7.594,loss:2.214287519454956,entropy:2.0620973110198975,explained_var_old:0.322,explained_var_new:0.363
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1794, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02077,lr_multiplier:7.594,loss:2.161879777908325,entropy:1.9877557754516602,explained_var_old:0.306,explained_var_new:0.360
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1795, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03570,lr_multiplier:7.594,loss:2.2037394046783447,entropy:1.9889711141586304,explained_var_old:0.275,explained_var_new:0.348
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1796, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02338,lr_multiplier:7.594,loss:2.161757707595825,entropy:2.0238678455352783,explained_var_old:0.367,explained_var_new:0.404
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1797, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02505,lr_multiplier:7.594,loss:2.187885284423828,entropy:1.9770704507827759,explained_var_old:0.238,explained_var_new:0.288
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1798, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02223,lr_multiplier:7.594,loss:2.2247540950775146,entropy:2.013077974319458,explained_var_old:0.299,explained_var_new:0.333
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1799, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.03024,lr_multiplier:7.594,loss:2.2589900493621826,entropy:2.061508893966675,explained_var_old:0.219,explained_var_new:0.260
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1800, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02521,lr_multiplier:7.594,loss:2.2474822998046875,entropy:2.0373058319091797,explained_var_old:0.282,explained_var_new:0.330
已经训练: 1800轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:3000, win: 7, lose: 2, tie:1
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1801, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02351,lr_multiplier:7.594,loss:2.223930597305298,entropy:2.013885498046875,explained_var_old:0.317,explained_var_new:0.377
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1802, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02567,lr_multiplier:7.594,loss:2.214334726333618,entropy:2.0100297927856445,explained_var_old:0.273,explained_var_new:0.332
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1803, episode_len:15
TrainPipeline:run: 开始模型训练
kl:0.02602,lr_multiplier:7.594,loss:2.2062060832977295,entropy:1.9882746934890747,explained_var_old:0.352,explained_var_new:0.403
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1804, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02834,lr_multiplier:7.594,loss:2.172051429748535,entropy:1.956977367401123,explained_var_old:0.232,explained_var_new:0.279
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1805, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02290,lr_multiplier:7.594,loss:2.207764148712158,entropy:2.054300546646118,explained_var_old:0.436,explained_var_new:0.486
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1806, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02806,lr_multiplier:7.594,loss:2.1356959342956543,entropy:1.9465453624725342,explained_var_old:0.266,explained_var_new:0.333
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1807, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02400,lr_multiplier:7.594,loss:2.225372314453125,entropy:2.0423970222473145,explained_var_old:0.247,explained_var_new:0.302
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1808, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02703,lr_multiplier:7.594,loss:2.24200701713562,entropy:2.0388355255126953,explained_var_old:0.300,explained_var_new:0.337
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1809, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03092,lr_multiplier:7.594,loss:2.2329018115997314,entropy:2.036193370819092,explained_var_old:0.298,explained_var_new:0.329
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1810, episode_len:30
TrainPipeline:run: 开始模型训练
kl:0.02513,lr_multiplier:7.594,loss:2.2428178787231445,entropy:2.0359833240509033,explained_var_old:0.079,explained_var_new:0.179
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1811, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02948,lr_multiplier:7.594,loss:2.221952438354492,entropy:2.0291266441345215,explained_var_old:0.257,explained_var_new:0.304
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1812, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02692,lr_multiplier:7.594,loss:2.2492966651916504,entropy:2.0630290508270264,explained_var_old:0.241,explained_var_new:0.312
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1813, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03104,lr_multiplier:7.594,loss:2.2233312129974365,entropy:2.016979694366455,explained_var_old:0.241,explained_var_new:0.301
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1814, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02884,lr_multiplier:7.594,loss:2.255704402923584,entropy:2.0643789768218994,explained_var_old:0.225,explained_var_new:0.284
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1815, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.02316,lr_multiplier:7.594,loss:2.269873857498169,entropy:2.014441967010498,explained_var_old:0.101,explained_var_new:0.150
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1816, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03000,lr_multiplier:7.594,loss:2.2303545475006104,entropy:2.00346040725708,explained_var_old:0.178,explained_var_new:0.221
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1817, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.03239,lr_multiplier:7.594,loss:2.3214473724365234,entropy:2.0841472148895264,explained_var_old:0.100,explained_var_new:0.162
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1818, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03640,lr_multiplier:7.594,loss:2.2392165660858154,entropy:2.0264699459075928,explained_var_old:0.114,explained_var_new:0.182
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1819, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.03457,lr_multiplier:7.594,loss:2.2889719009399414,entropy:2.065768003463745,explained_var_old:0.105,explained_var_new:0.170
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1820, episode_len:45
TrainPipeline:run: 开始模型训练
kl:0.04668,lr_multiplier:5.062,loss:2.415205955505371,entropy:2.081423759460449,explained_var_old:0.092,explained_var_new:0.169
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1821, episode_len:32
TrainPipeline:run: 开始模型训练
kl:0.02311,lr_multiplier:5.062,loss:2.383916139602661,entropy:2.133065700531006,explained_var_old:0.190,explained_var_new:0.237
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1822, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03176,lr_multiplier:5.062,loss:2.417532205581665,entropy:2.086848735809326,explained_var_old:0.108,explained_var_new:0.155
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1823, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02041,lr_multiplier:5.062,loss:2.362422227859497,entropy:2.1318259239196777,explained_var_old:0.125,explained_var_new:0.172
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1824, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.02469,lr_multiplier:5.062,loss:2.311832904815674,entropy:2.067141532897949,explained_var_old:0.076,explained_var_new:0.116
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1825, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02109,lr_multiplier:5.062,loss:2.39554500579834,entropy:2.042170524597168,explained_var_old:0.057,explained_var_new:0.092
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1826, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01932,lr_multiplier:5.062,loss:2.302952527999878,entropy:2.0275962352752686,explained_var_old:0.125,explained_var_new:0.166
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1827, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01917,lr_multiplier:5.062,loss:2.336773633956909,entropy:2.0576040744781494,explained_var_old:0.082,explained_var_new:0.133
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1828, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01766,lr_multiplier:5.062,loss:2.3660874366760254,entropy:2.080981492996216,explained_var_old:0.134,explained_var_new:0.205
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1829, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01598,lr_multiplier:5.062,loss:2.4213380813598633,entropy:2.094127655029297,explained_var_old:0.108,explained_var_new:0.165
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1830, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01791,lr_multiplier:5.062,loss:2.3821394443511963,entropy:2.1297779083251953,explained_var_old:0.122,explained_var_new:0.192
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1831, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.02050,lr_multiplier:5.062,loss:2.3658158779144287,entropy:2.103083372116089,explained_var_old:0.205,explained_var_new:0.260
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1832, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01714,lr_multiplier:5.062,loss:2.3873074054718018,entropy:2.098936080932617,explained_var_old:0.167,explained_var_new:0.273
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1833, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.03202,lr_multiplier:5.062,loss:2.415900468826294,entropy:2.0879058837890625,explained_var_old:0.167,explained_var_new:0.231
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1834, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02850,lr_multiplier:5.062,loss:2.2988922595977783,entropy:2.0492115020751953,explained_var_old:0.186,explained_var_new:0.243
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1835, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01788,lr_multiplier:5.062,loss:2.340456485748291,entropy:2.058161973953247,explained_var_old:0.082,explained_var_new:0.159
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1836, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01515,lr_multiplier:5.062,loss:2.3129048347473145,entropy:2.062777042388916,explained_var_old:0.230,explained_var_new:0.286
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1837, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.01691,lr_multiplier:5.062,loss:2.381466865539551,entropy:2.0789427757263184,explained_var_old:0.096,explained_var_new:0.200
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1838, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02067,lr_multiplier:5.062,loss:2.2924065589904785,entropy:2.0469329357147217,explained_var_old:0.190,explained_var_new:0.230
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1839, episode_len:35
TrainPipeline:run: 开始模型训练
kl:0.02492,lr_multiplier:5.062,loss:2.3928146362304688,entropy:2.1097488403320312,explained_var_old:0.200,explained_var_new:0.259
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1840, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.01551,lr_multiplier:5.062,loss:2.3476150035858154,entropy:2.085902690887451,explained_var_old:0.280,explained_var_new:0.335
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1841, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01330,lr_multiplier:5.062,loss:2.3694870471954346,entropy:2.0796804428100586,explained_var_old:0.318,explained_var_new:0.366
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1842, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01875,lr_multiplier:5.062,loss:2.343662738800049,entropy:2.1138195991516113,explained_var_old:0.206,explained_var_new:0.255
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1843, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01515,lr_multiplier:5.062,loss:2.379079818725586,entropy:2.0815610885620117,explained_var_old:0.218,explained_var_new:0.275
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1844, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.01812,lr_multiplier:5.062,loss:2.393707513809204,entropy:2.083357810974121,explained_var_old:0.210,explained_var_new:0.265
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1845, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.02212,lr_multiplier:5.062,loss:2.3650197982788086,entropy:2.105746030807495,explained_var_old:0.275,explained_var_new:0.333
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1846, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01341,lr_multiplier:5.062,loss:2.405470132827759,entropy:2.0834314823150635,explained_var_old:0.210,explained_var_new:0.262
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1847, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01229,lr_multiplier:5.062,loss:2.4323232173919678,entropy:2.1491477489471436,explained_var_old:0.233,explained_var_new:0.291
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1848, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01208,lr_multiplier:5.062,loss:2.3628389835357666,entropy:2.035012722015381,explained_var_old:0.241,explained_var_new:0.304
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1849, episode_len:21
TrainPipeline:run: 开始模型训练
kl:0.01955,lr_multiplier:5.062,loss:2.3724775314331055,entropy:2.0183844566345215,explained_var_old:0.134,explained_var_new:0.208
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1850, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01702,lr_multiplier:5.062,loss:2.364140510559082,entropy:2.0912463665008545,explained_var_old:0.265,explained_var_new:0.303
已经训练: 1850轮
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
num_playouts:3000, win: 6, lose: 0, tie:4
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1851, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01364,lr_multiplier:5.062,loss:2.3372466564178467,entropy:2.12143611907959,explained_var_old:0.255,explained_var_new:0.292
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1852, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02295,lr_multiplier:5.062,loss:2.2239062786102295,entropy:2.009781837463379,explained_var_old:0.236,explained_var_new:0.294
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1853, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02049,lr_multiplier:5.062,loss:2.3002145290374756,entropy:2.0115485191345215,explained_var_old:0.204,explained_var_new:0.240
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1854, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02102,lr_multiplier:5.062,loss:2.270895004272461,entropy:2.0769762992858887,explained_var_old:0.263,explained_var_new:0.301
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1855, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01364,lr_multiplier:5.062,loss:2.1709952354431152,entropy:1.9350590705871582,explained_var_old:0.234,explained_var_new:0.278
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1856, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01837,lr_multiplier:5.062,loss:2.250568389892578,entropy:2.0409598350524902,explained_var_old:0.276,explained_var_new:0.317
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1857, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01242,lr_multiplier:5.062,loss:2.2371506690979004,entropy:2.0676066875457764,explained_var_old:0.209,explained_var_new:0.272
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1858, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01549,lr_multiplier:5.062,loss:2.2620387077331543,entropy:2.0560083389282227,explained_var_old:0.242,explained_var_new:0.281
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1859, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01773,lr_multiplier:5.062,loss:2.169909954071045,entropy:2.019619941711426,explained_var_old:0.211,explained_var_new:0.264
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1860, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02169,lr_multiplier:5.062,loss:2.12196683883667,entropy:1.9421374797821045,explained_var_old:0.232,explained_var_new:0.275
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1861, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01374,lr_multiplier:5.062,loss:2.0820436477661133,entropy:1.9158703088760376,explained_var_old:0.320,explained_var_new:0.360
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1862, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01415,lr_multiplier:5.062,loss:2.0839602947235107,entropy:1.961472988128662,explained_var_old:0.229,explained_var_new:0.288
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1863, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01679,lr_multiplier:5.062,loss:2.1151585578918457,entropy:1.9659087657928467,explained_var_old:0.132,explained_var_new:0.178
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1864, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.01812,lr_multiplier:5.062,loss:2.179685115814209,entropy:2.034804344177246,explained_var_old:0.152,explained_var_new:0.193
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1865, episode_len:20
TrainPipeline:run: 开始模型训练
kl:0.01665,lr_multiplier:5.062,loss:2.1160330772399902,entropy:1.9343761205673218,explained_var_old:0.150,explained_var_new:0.226
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1866, episode_len:22
TrainPipeline:run: 开始模型训练
kl:0.01913,lr_multiplier:5.062,loss:2.1189918518066406,entropy:1.9612027406692505,explained_var_old:0.091,explained_var_new:0.182
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1867, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02439,lr_multiplier:5.062,loss:2.0745344161987305,entropy:1.9608185291290283,explained_var_old:0.030,explained_var_new:0.112
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1868, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02559,lr_multiplier:5.062,loss:2.0986907482147217,entropy:1.943893313407898,explained_var_old:0.127,explained_var_new:0.209
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1869, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02612,lr_multiplier:5.062,loss:2.1018786430358887,entropy:1.9960730075836182,explained_var_old:0.142,explained_var_new:0.206
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1870, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02133,lr_multiplier:5.062,loss:2.085042715072632,entropy:1.985515832901001,explained_var_old:0.108,explained_var_new:0.220
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1871, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01710,lr_multiplier:5.062,loss:2.0821759700775146,entropy:2.0391905307769775,explained_var_old:0.036,explained_var_new:0.103
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1872, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02144,lr_multiplier:5.062,loss:2.003801107406616,entropy:1.9151721000671387,explained_var_old:0.086,explained_var_new:0.144
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1873, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02325,lr_multiplier:5.062,loss:2.0392181873321533,entropy:1.976830005645752,explained_var_old:0.086,explained_var_new:0.128
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1874, episode_len:29
TrainPipeline:run: 开始模型训练
kl:0.01887,lr_multiplier:5.062,loss:2.026956796646118,entropy:1.9453372955322266,explained_var_old:0.088,explained_var_new:0.153
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1875, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01677,lr_multiplier:5.062,loss:2.079768419265747,entropy:2.0077414512634277,explained_var_old:0.090,explained_var_new:0.152
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1876, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01382,lr_multiplier:5.062,loss:1.9942163228988647,entropy:1.9334497451782227,explained_var_old:0.179,explained_var_new:0.224
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1877, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01571,lr_multiplier:5.062,loss:1.9404339790344238,entropy:1.8888509273529053,explained_var_old:0.153,explained_var_new:0.200
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1878, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01649,lr_multiplier:5.062,loss:1.9870388507843018,entropy:1.9364585876464844,explained_var_old:0.215,explained_var_new:0.241
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1879, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01560,lr_multiplier:5.062,loss:2.0416202545166016,entropy:1.9595005512237549,explained_var_old:0.157,explained_var_new:0.219
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1880, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01794,lr_multiplier:5.062,loss:2.072347640991211,entropy:1.9524211883544922,explained_var_old:0.092,explained_var_new:0.137
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1881, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01496,lr_multiplier:5.062,loss:2.0908565521240234,entropy:2.028200149536133,explained_var_old:0.145,explained_var_new:0.170
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1882, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01201,lr_multiplier:5.062,loss:2.0716664791107178,entropy:1.9951632022857666,explained_var_old:0.198,explained_var_new:0.236
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1883, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01412,lr_multiplier:5.062,loss:2.0309524536132812,entropy:1.9833598136901855,explained_var_old:0.175,explained_var_new:0.200
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1884, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01299,lr_multiplier:5.062,loss:2.035829544067383,entropy:1.9511030912399292,explained_var_old:0.189,explained_var_new:0.223
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1885, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01626,lr_multiplier:5.062,loss:1.9958988428115845,entropy:1.9092241525650024,explained_var_old:0.141,explained_var_new:0.174
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1886, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01532,lr_multiplier:5.062,loss:1.973272442817688,entropy:1.9239652156829834,explained_var_old:0.224,explained_var_new:0.249
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1887, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01495,lr_multiplier:5.062,loss:1.989027500152588,entropy:1.938902497291565,explained_var_old:0.028,explained_var_new:0.079
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1888, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01592,lr_multiplier:5.062,loss:1.935750961303711,entropy:1.9134671688079834,explained_var_old:0.033,explained_var_new:0.095
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1889, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01019,lr_multiplier:5.062,loss:2.0173511505126953,entropy:2.008164882659912,explained_var_old:-0.079,explained_var_new:-0.030
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1890, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01397,lr_multiplier:5.062,loss:1.9738976955413818,entropy:1.955215573310852,explained_var_old:0.077,explained_var_new:0.086
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1891, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00983,lr_multiplier:7.594,loss:2.011655330657959,entropy:1.9617912769317627,explained_var_old:0.041,explained_var_new:0.057
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1892, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01051,lr_multiplier:7.594,loss:2.019885778427124,entropy:1.9850972890853882,explained_var_old:0.065,explained_var_new:0.109
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1893, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01915,lr_multiplier:7.594,loss:1.9776047468185425,entropy:1.97489333152771,explained_var_old:0.100,explained_var_new:0.123
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1894, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02486,lr_multiplier:7.594,loss:1.9663883447647095,entropy:1.950230360031128,explained_var_old:0.044,explained_var_new:0.061
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1895, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01897,lr_multiplier:7.594,loss:1.9244447946548462,entropy:1.881166934967041,explained_var_old:-0.030,explained_var_new:0.015
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1896, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01679,lr_multiplier:7.594,loss:1.8845258951187134,entropy:1.8718478679656982,explained_var_old:-0.022,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1897, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01464,lr_multiplier:7.594,loss:1.9303058385849,entropy:1.9106149673461914,explained_var_old:-0.045,explained_var_new:-0.029
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1898, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02156,lr_multiplier:7.594,loss:1.992996335029602,entropy:1.9785038232803345,explained_var_old:-0.038,explained_var_new:-0.030
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1899, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01687,lr_multiplier:7.594,loss:1.8701080083847046,entropy:1.8723313808441162,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1900, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01698,lr_multiplier:7.594,loss:1.952165126800537,entropy:1.9415935277938843,explained_var_old:-inf,explained_var_new:-inf
已经训练: 1900轮
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 2
num_playouts:3000, win: 7, lose: 2, tie:1
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1901, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01686,lr_multiplier:7.594,loss:1.8217027187347412,entropy:1.8447411060333252,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1902, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01740,lr_multiplier:7.594,loss:1.9389739036560059,entropy:1.9266934394836426,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1903, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01567,lr_multiplier:7.594,loss:1.9511091709136963,entropy:1.9624146223068237,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1904, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01738,lr_multiplier:7.594,loss:1.9172066450119019,entropy:1.9090566635131836,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1905, episode_len:40
TrainPipeline:run: 开始模型训练
kl:0.01517,lr_multiplier:7.594,loss:1.9477348327636719,entropy:1.902679204940796,explained_var_old:-0.002,explained_var_new:0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1906, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01221,lr_multiplier:7.594,loss:1.9323480129241943,entropy:1.9211663007736206,explained_var_old:0.002,explained_var_new:0.007
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1907, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01196,lr_multiplier:7.594,loss:2.020385265350342,entropy:1.9862346649169922,explained_var_old:-0.005,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1908, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01350,lr_multiplier:7.594,loss:1.9834645986557007,entropy:1.9464887380599976,explained_var_old:-0.000,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1909, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01144,lr_multiplier:7.594,loss:1.9369807243347168,entropy:1.9047670364379883,explained_var_old:-0.003,explained_var_new:-0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1910, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01301,lr_multiplier:7.594,loss:2.001452922821045,entropy:1.9835638999938965,explained_var_old:-0.001,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1911, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01476,lr_multiplier:7.594,loss:1.942314624786377,entropy:1.9096769094467163,explained_var_old:-0.004,explained_var_new:-0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1912, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01466,lr_multiplier:7.594,loss:1.9670556783676147,entropy:1.9592366218566895,explained_var_old:0.017,explained_var_new:0.020
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1913, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01426,lr_multiplier:7.594,loss:2.053184986114502,entropy:2.0147671699523926,explained_var_old:0.005,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1914, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01303,lr_multiplier:7.594,loss:1.9509425163269043,entropy:1.926840901374817,explained_var_old:-0.005,explained_var_new:-0.005
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1915, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01089,lr_multiplier:7.594,loss:1.9340519905090332,entropy:1.8838927745819092,explained_var_old:0.004,explained_var_new:0.006
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1916, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01297,lr_multiplier:7.594,loss:2.027560234069824,entropy:2.0041565895080566,explained_var_old:0.011,explained_var_new:0.013
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1917, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01108,lr_multiplier:7.594,loss:1.9300183057785034,entropy:1.887516975402832,explained_var_old:-0.003,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1918, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01181,lr_multiplier:7.594,loss:1.981622338294983,entropy:1.9564324617385864,explained_var_old:0.013,explained_var_new:0.018
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1919, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00645,lr_multiplier:11.391,loss:1.9833070039749146,entropy:1.9636480808258057,explained_var_old:0.021,explained_var_new:0.025
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1920, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00952,lr_multiplier:11.391,loss:1.9583343267440796,entropy:1.9190236330032349,explained_var_old:0.019,explained_var_new:0.025
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1921, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01178,lr_multiplier:11.391,loss:2.022998094558716,entropy:1.9877833127975464,explained_var_old:0.008,explained_var_new:0.015
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1922, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01176,lr_multiplier:11.391,loss:1.9875571727752686,entropy:1.951360821723938,explained_var_old:0.019,explained_var_new:0.026
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1923, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01346,lr_multiplier:11.391,loss:1.9566620588302612,entropy:1.9420720338821411,explained_var_old:-0.020,explained_var_new:-0.012
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1924, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01156,lr_multiplier:11.391,loss:1.9679694175720215,entropy:1.9533538818359375,explained_var_old:0.012,explained_var_new:0.019
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1925, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00836,lr_multiplier:11.391,loss:1.8615931272506714,entropy:1.853906512260437,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1926, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00959,lr_multiplier:11.391,loss:1.9834858179092407,entropy:1.9913777112960815,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1927, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00987,lr_multiplier:11.391,loss:1.9699938297271729,entropy:1.9606635570526123,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1928, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00732,lr_multiplier:11.391,loss:1.883868932723999,entropy:1.8833141326904297,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1929, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00873,lr_multiplier:11.391,loss:1.836277723312378,entropy:1.8374325037002563,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1930, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00897,lr_multiplier:11.391,loss:1.9556423425674438,entropy:1.9638653993606567,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1931, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00665,lr_multiplier:11.391,loss:1.8511251211166382,entropy:1.8680063486099243,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1932, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00865,lr_multiplier:11.391,loss:1.812502384185791,entropy:1.805700421333313,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1933, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00815,lr_multiplier:11.391,loss:1.9012864828109741,entropy:1.9049420356750488,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1934, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00733,lr_multiplier:11.391,loss:1.9213258028030396,entropy:1.9205384254455566,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1935, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00863,lr_multiplier:11.391,loss:1.9224666357040405,entropy:1.926170825958252,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1936, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00728,lr_multiplier:11.391,loss:1.9057284593582153,entropy:1.910195231437683,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1937, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00815,lr_multiplier:11.391,loss:1.932996392250061,entropy:1.9266407489776611,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1938, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00606,lr_multiplier:11.391,loss:1.9312732219696045,entropy:1.9368128776550293,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1939, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00700,lr_multiplier:11.391,loss:1.8726826906204224,entropy:1.8675521612167358,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1940, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00817,lr_multiplier:11.391,loss:1.9152486324310303,entropy:1.9263757467269897,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1941, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00732,lr_multiplier:11.391,loss:1.8177309036254883,entropy:1.8111693859100342,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1942, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00879,lr_multiplier:11.391,loss:1.881684422492981,entropy:1.8906556367874146,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1943, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00801,lr_multiplier:11.391,loss:1.9054869413375854,entropy:1.8973300457000732,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1944, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00981,lr_multiplier:11.391,loss:1.8300069570541382,entropy:1.833022117614746,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1945, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00918,lr_multiplier:11.391,loss:1.9213193655014038,entropy:1.9269734621047974,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1946, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00922,lr_multiplier:11.391,loss:1.9304238557815552,entropy:1.9226473569869995,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1947, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00837,lr_multiplier:11.391,loss:1.9109888076782227,entropy:1.9142658710479736,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1948, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00769,lr_multiplier:11.391,loss:1.875143051147461,entropy:1.8745667934417725,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1949, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00543,lr_multiplier:11.391,loss:1.8636811971664429,entropy:1.8706934452056885,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1950, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00442,lr_multiplier:11.391,loss:1.9165619611740112,entropy:1.9202195405960083,explained_var_old:-inf,explained_var_new:-inf
已经训练: 1950轮
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:3000, win: 8, lose: 0, tie:2
相较于MCTS@3000, 截至目前的最佳胜率=0.9 !!!!!!!!
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1951, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00691,lr_multiplier:11.391,loss:1.9484810829162598,entropy:1.9542808532714844,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1952, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00691,lr_multiplier:11.391,loss:1.891815423965454,entropy:1.8903679847717285,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1953, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00671,lr_multiplier:11.391,loss:1.9132394790649414,entropy:1.9087213277816772,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1954, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00409,lr_multiplier:11.391,loss:1.8986389636993408,entropy:1.9063055515289307,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1955, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00428,lr_multiplier:11.391,loss:1.8508427143096924,entropy:1.8562140464782715,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1956, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00554,lr_multiplier:11.391,loss:1.891379952430725,entropy:1.8840831518173218,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1957, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00600,lr_multiplier:11.391,loss:1.974334478378296,entropy:1.9724029302597046,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1958, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00665,lr_multiplier:11.391,loss:1.899919867515564,entropy:1.9075186252593994,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1959, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00558,lr_multiplier:11.391,loss:1.877669095993042,entropy:1.8744308948516846,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1960, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00551,lr_multiplier:11.391,loss:1.8456007242202759,entropy:1.853233814239502,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1961, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00533,lr_multiplier:11.391,loss:1.8788000345230103,entropy:1.872552514076233,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1962, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00421,lr_multiplier:11.391,loss:1.8545018434524536,entropy:1.8640413284301758,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1963, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00466,lr_multiplier:11.391,loss:1.9403682947158813,entropy:1.93912672996521,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1964, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00401,lr_multiplier:11.391,loss:1.82027268409729,entropy:1.822235107421875,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1965, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00406,lr_multiplier:11.391,loss:1.8511697053909302,entropy:1.8543753623962402,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1966, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00487,lr_multiplier:11.391,loss:1.8690780401229858,entropy:1.8709948062896729,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1967, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00458,lr_multiplier:11.391,loss:1.8616539239883423,entropy:1.8724523782730103,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1968, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00391,lr_multiplier:11.391,loss:1.8928170204162598,entropy:1.886755108833313,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1969, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00451,lr_multiplier:11.391,loss:1.91115140914917,entropy:1.908459186553955,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1970, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00866,lr_multiplier:11.391,loss:1.836434245109558,entropy:1.8395018577575684,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1971, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00780,lr_multiplier:11.391,loss:1.9036507606506348,entropy:1.9076297283172607,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1972, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00586,lr_multiplier:11.391,loss:1.7862026691436768,entropy:1.7832467555999756,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1973, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00763,lr_multiplier:11.391,loss:1.9076224565505981,entropy:1.9187476634979248,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1974, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00931,lr_multiplier:11.391,loss:1.888959527015686,entropy:1.8824100494384766,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1975, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00870,lr_multiplier:11.391,loss:1.897326946258545,entropy:1.9014499187469482,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1976, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00668,lr_multiplier:11.391,loss:1.8828974962234497,entropy:1.8854988813400269,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1977, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00420,lr_multiplier:11.391,loss:1.8764960765838623,entropy:1.8825592994689941,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1978, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00429,lr_multiplier:11.391,loss:1.860729694366455,entropy:1.8565818071365356,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1979, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00573,lr_multiplier:11.391,loss:1.8706471920013428,entropy:1.873399257659912,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1980, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00758,lr_multiplier:11.391,loss:1.8806947469711304,entropy:1.8912596702575684,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1981, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00673,lr_multiplier:11.391,loss:1.7922300100326538,entropy:1.7895029783248901,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1982, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00578,lr_multiplier:11.391,loss:1.877964735031128,entropy:1.8779783248901367,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1983, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00532,lr_multiplier:11.391,loss:1.9071258306503296,entropy:1.9096840620040894,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1984, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00495,lr_multiplier:11.391,loss:1.8040837049484253,entropy:1.813995122909546,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1985, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00612,lr_multiplier:11.391,loss:1.85233736038208,entropy:1.8584136962890625,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1986, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00704,lr_multiplier:11.391,loss:1.83380925655365,entropy:1.8379220962524414,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1987, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00691,lr_multiplier:11.391,loss:1.8367036581039429,entropy:1.8302770853042603,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1988, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00582,lr_multiplier:11.391,loss:1.8010872602462769,entropy:1.8064192533493042,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1989, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00575,lr_multiplier:11.391,loss:1.8970060348510742,entropy:1.9033699035644531,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1990, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00542,lr_multiplier:11.391,loss:1.8457953929901123,entropy:1.8449816703796387,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1991, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00597,lr_multiplier:11.391,loss:1.9209322929382324,entropy:1.9208515882492065,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1992, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00743,lr_multiplier:11.391,loss:1.8531718254089355,entropy:1.8485898971557617,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1993, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00563,lr_multiplier:11.391,loss:1.7969938516616821,entropy:1.8080470561981201,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1994, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00618,lr_multiplier:11.391,loss:1.8082343339920044,entropy:1.8087153434753418,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1995, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00589,lr_multiplier:11.391,loss:1.8738971948623657,entropy:1.8803869485855103,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1996, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00503,lr_multiplier:11.391,loss:1.8490550518035889,entropy:1.8556627035140991,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1997, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00582,lr_multiplier:11.391,loss:1.7831956148147583,entropy:1.778363585472107,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1998, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00842,lr_multiplier:11.391,loss:1.835323691368103,entropy:1.8357081413269043,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:1999, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00808,lr_multiplier:11.391,loss:1.8489381074905396,entropy:1.8596155643463135,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2000, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00739,lr_multiplier:11.391,loss:1.888329267501831,entropy:1.895959496498108,explained_var_old:-inf,explained_var_new:-inf
已经训练: 2000轮
Game end. Winner is player 2
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 2
Game end. Tie
Game end. Winner is player 2
Game end. Winner is player 1
Game end. Winner is player 1
num_playouts:3000, win: 4, lose: 4, tie:2
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2001, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00963,lr_multiplier:11.391,loss:1.7726109027862549,entropy:1.776495337486267,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2002, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00796,lr_multiplier:11.391,loss:1.851335883140564,entropy:1.853236436843872,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2003, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00901,lr_multiplier:11.391,loss:1.8003315925598145,entropy:1.7958810329437256,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2004, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00897,lr_multiplier:11.391,loss:1.9097272157669067,entropy:1.9221928119659424,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2005, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00706,lr_multiplier:11.391,loss:1.8211599588394165,entropy:1.8257997035980225,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2006, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00711,lr_multiplier:11.391,loss:1.8692946434020996,entropy:1.8598613739013672,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2007, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00491,lr_multiplier:11.391,loss:1.8409537076950073,entropy:1.8499032258987427,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2008, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00435,lr_multiplier:11.391,loss:1.8297091722488403,entropy:1.8224453926086426,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2009, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00493,lr_multiplier:11.391,loss:1.8500288724899292,entropy:1.8548238277435303,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2010, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00647,lr_multiplier:11.391,loss:1.7761820554733276,entropy:1.772534966468811,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2011, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00817,lr_multiplier:11.391,loss:1.8702585697174072,entropy:1.8773504495620728,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2012, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01193,lr_multiplier:11.391,loss:1.8587043285369873,entropy:1.8498834371566772,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2013, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01218,lr_multiplier:11.391,loss:1.8834683895111084,entropy:1.8927509784698486,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2014, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01158,lr_multiplier:11.391,loss:1.8231881856918335,entropy:1.8242383003234863,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2015, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00994,lr_multiplier:11.391,loss:1.8121834993362427,entropy:1.8155673742294312,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2016, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00807,lr_multiplier:11.391,loss:1.7937469482421875,entropy:1.7996488809585571,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2017, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00658,lr_multiplier:11.391,loss:1.8363089561462402,entropy:1.8409268856048584,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2018, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00484,lr_multiplier:11.391,loss:1.8354477882385254,entropy:1.8414660692214966,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2019, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00722,lr_multiplier:11.391,loss:1.8169649839401245,entropy:1.8206582069396973,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2020, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00812,lr_multiplier:11.391,loss:1.9217042922973633,entropy:1.9211783409118652,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2021, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00836,lr_multiplier:11.391,loss:1.8318922519683838,entropy:1.8421159982681274,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2022, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00658,lr_multiplier:11.391,loss:1.7925360202789307,entropy:1.789556622505188,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2023, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00746,lr_multiplier:11.391,loss:1.83810293674469,entropy:1.850052833557129,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2024, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00687,lr_multiplier:11.391,loss:1.815406322479248,entropy:1.8098645210266113,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2025, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00558,lr_multiplier:11.391,loss:1.8189564943313599,entropy:1.82925546169281,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2026, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00530,lr_multiplier:11.391,loss:1.8889926671981812,entropy:1.8846981525421143,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2027, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00482,lr_multiplier:11.391,loss:1.833807110786438,entropy:1.835370421409607,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2028, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00558,lr_multiplier:11.391,loss:1.7702497243881226,entropy:1.7729805707931519,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2029, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00941,lr_multiplier:11.391,loss:1.7745602130889893,entropy:1.7789366245269775,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2030, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00964,lr_multiplier:11.391,loss:1.791100025177002,entropy:1.7974183559417725,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2031, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00764,lr_multiplier:11.391,loss:1.8713679313659668,entropy:1.8747470378875732,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2032, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00732,lr_multiplier:11.391,loss:1.7793203592300415,entropy:1.7807406187057495,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2033, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00635,lr_multiplier:11.391,loss:1.793188452720642,entropy:1.8031755685806274,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2034, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00612,lr_multiplier:11.391,loss:1.8241114616394043,entropy:1.8191677331924438,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2035, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00616,lr_multiplier:11.391,loss:1.822742223739624,entropy:1.8223655223846436,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2036, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00737,lr_multiplier:11.391,loss:1.8595845699310303,entropy:1.8574585914611816,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2037, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00765,lr_multiplier:11.391,loss:1.797532558441162,entropy:1.8031556606292725,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2038, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00764,lr_multiplier:11.391,loss:1.812263011932373,entropy:1.8022956848144531,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2039, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00826,lr_multiplier:11.391,loss:1.7820799350738525,entropy:1.7973943948745728,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2040, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00664,lr_multiplier:11.391,loss:1.7753270864486694,entropy:1.7711831331253052,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2041, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.00737,lr_multiplier:11.391,loss:1.7813612222671509,entropy:1.7843801975250244,explained_var_old:-inf,explained_var_new:-inf
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2042, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01098,lr_multiplier:11.391,loss:1.8323043584823608,entropy:1.8012040853500366,explained_var_old:-0.001,explained_var_new:-0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2043, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01247,lr_multiplier:11.391,loss:1.7517445087432861,entropy:1.7239558696746826,explained_var_old:-0.004,explained_var_new:-0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2044, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01199,lr_multiplier:11.391,loss:1.8592056035995483,entropy:1.8258743286132812,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2045, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01104,lr_multiplier:11.391,loss:1.7580193281173706,entropy:1.740054726600647,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2046, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01333,lr_multiplier:11.391,loss:1.796770691871643,entropy:1.7850871086120605,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2047, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.01367,lr_multiplier:11.391,loss:1.721649408340454,entropy:1.695180058479309,explained_var_old:0.000,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2048, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01172,lr_multiplier:11.391,loss:1.8958525657653809,entropy:1.858527660369873,explained_var_old:-0.001,explained_var_new:-0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2049, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01152,lr_multiplier:11.391,loss:1.819053292274475,entropy:1.7741689682006836,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2050, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01566,lr_multiplier:11.391,loss:1.855879783630371,entropy:1.8298712968826294,explained_var_old:-0.000,explained_var_new:-0.000
已经训练: 2050轮
Game end. Tie
Game end. Winner is player 1
Game end. Tie
Game end. Tie
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
num_playouts:3000, win: 5, lose: 0, tie:5
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2051, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01584,lr_multiplier:11.391,loss:1.8262017965316772,entropy:1.7642219066619873,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2052, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01711,lr_multiplier:11.391,loss:1.9078596830368042,entropy:1.8589154481887817,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2053, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01453,lr_multiplier:11.391,loss:1.8865550756454468,entropy:1.8512344360351562,explained_var_old:0.001,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2054, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01502,lr_multiplier:11.391,loss:1.8284434080123901,entropy:1.8056707382202148,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2055, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01589,lr_multiplier:11.391,loss:1.800636887550354,entropy:1.7625573873519897,explained_var_old:-0.000,explained_var_new:-0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2056, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02232,lr_multiplier:11.391,loss:1.8422409296035767,entropy:1.7932626008987427,explained_var_old:0.001,explained_var_new:0.002
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2057, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02158,lr_multiplier:11.391,loss:1.8336235284805298,entropy:1.8015105724334717,explained_var_old:0.001,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2058, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02539,lr_multiplier:11.391,loss:1.8820964097976685,entropy:1.8068026304244995,explained_var_old:0.001,explained_var_new:0.001
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2059, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02354,lr_multiplier:11.391,loss:1.8829561471939087,entropy:1.8114320039749146,explained_var_old:0.007,explained_var_new:0.015
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2060, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02300,lr_multiplier:11.391,loss:1.7650130987167358,entropy:1.6815072298049927,explained_var_old:0.007,explained_var_new:0.029
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2061, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01889,lr_multiplier:11.391,loss:1.8803131580352783,entropy:1.8221813440322876,explained_var_old:0.001,explained_var_new:0.061
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2062, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01616,lr_multiplier:11.391,loss:1.8370376825332642,entropy:1.7925004959106445,explained_var_old:-0.012,explained_var_new:0.053
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2063, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01900,lr_multiplier:11.391,loss:1.8182100057601929,entropy:1.7330174446105957,explained_var_old:0.068,explained_var_new:0.150
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2064, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01962,lr_multiplier:11.391,loss:1.8195438385009766,entropy:1.7647627592086792,explained_var_old:0.090,explained_var_new:0.193
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2065, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01789,lr_multiplier:11.391,loss:1.744954228401184,entropy:1.7081804275512695,explained_var_old:0.136,explained_var_new:0.192
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2066, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02447,lr_multiplier:11.391,loss:1.739528775215149,entropy:1.6902796030044556,explained_var_old:0.165,explained_var_new:0.212
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2067, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02693,lr_multiplier:11.391,loss:1.8073335886001587,entropy:1.7797977924346924,explained_var_old:0.133,explained_var_new:0.171
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2068, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02013,lr_multiplier:11.391,loss:1.7472150325775146,entropy:1.6928095817565918,explained_var_old:0.047,explained_var_new:0.069
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2069, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.01907,lr_multiplier:11.391,loss:1.7521309852600098,entropy:1.6916626691818237,explained_var_old:0.094,explained_var_new:0.112
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2070, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02478,lr_multiplier:11.391,loss:1.820276141166687,entropy:1.765638828277588,explained_var_old:0.162,explained_var_new:0.223
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2071, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03309,lr_multiplier:11.391,loss:1.7861005067825317,entropy:1.7281389236450195,explained_var_old:0.053,explained_var_new:0.133
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2072, episode_len:33
TrainPipeline:run: 开始模型训练
kl:0.02497,lr_multiplier:11.391,loss:1.877855658531189,entropy:1.8518661260604858,explained_var_old:0.207,explained_var_new:0.266
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2073, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02394,lr_multiplier:11.391,loss:1.824112892150879,entropy:1.7447481155395508,explained_var_old:0.133,explained_var_new:0.173
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2074, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02792,lr_multiplier:11.391,loss:1.8120217323303223,entropy:1.7411527633666992,explained_var_old:0.160,explained_var_new:0.230
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2075, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.03266,lr_multiplier:11.391,loss:1.8054592609405518,entropy:1.7396459579467773,explained_var_old:0.209,explained_var_new:0.308
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2076, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03575,lr_multiplier:11.391,loss:1.8693054914474487,entropy:1.8123884201049805,explained_var_old:0.268,explained_var_new:0.330
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2077, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02674,lr_multiplier:11.391,loss:1.899483561515808,entropy:1.8238707780838013,explained_var_old:0.277,explained_var_new:0.315
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2078, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03202,lr_multiplier:11.391,loss:1.9219015836715698,entropy:1.8333485126495361,explained_var_old:0.281,explained_var_new:0.352
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2079, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03810,lr_multiplier:11.391,loss:1.8805097341537476,entropy:1.8299492597579956,explained_var_old:0.228,explained_var_new:0.277
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2080, episode_len:31
TrainPipeline:run: 开始模型训练
kl:0.03673,lr_multiplier:11.391,loss:1.9370603561401367,entropy:1.8592535257339478,explained_var_old:0.251,explained_var_new:0.282
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2081, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.03465,lr_multiplier:11.391,loss:1.9129953384399414,entropy:1.8297162055969238,explained_var_old:0.204,explained_var_new:0.254
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2082, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03961,lr_multiplier:11.391,loss:1.9262422323226929,entropy:1.8228909969329834,explained_var_old:0.256,explained_var_new:0.313
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2083, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.04100,lr_multiplier:7.594,loss:1.9344102144241333,entropy:1.850075364112854,explained_var_old:0.295,explained_var_new:0.331
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2084, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03347,lr_multiplier:7.594,loss:1.8933357000350952,entropy:1.8090254068374634,explained_var_old:0.150,explained_var_new:0.183
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2085, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02883,lr_multiplier:7.594,loss:1.9034382104873657,entropy:1.8341506719589233,explained_var_old:0.255,explained_var_new:0.349
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2086, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.02665,lr_multiplier:7.594,loss:1.8871448040008545,entropy:1.793429970741272,explained_var_old:0.187,explained_var_new:0.231
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2087, episode_len:17
TrainPipeline:run: 开始模型训练
kl:0.03430,lr_multiplier:7.594,loss:1.9336525201797485,entropy:1.8245551586151123,explained_var_old:0.191,explained_var_new:0.272
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2088, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03373,lr_multiplier:7.594,loss:1.8924262523651123,entropy:1.7518467903137207,explained_var_old:0.128,explained_var_new:0.193
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2089, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03128,lr_multiplier:7.594,loss:1.9907557964324951,entropy:1.879188895225525,explained_var_old:0.205,explained_var_new:0.236
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2090, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02749,lr_multiplier:7.594,loss:2.018921136856079,entropy:1.9133986234664917,explained_var_old:0.245,explained_var_new:0.289
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2091, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02967,lr_multiplier:7.594,loss:1.9554632902145386,entropy:1.8546199798583984,explained_var_old:0.289,explained_var_new:0.319
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2092, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02775,lr_multiplier:7.594,loss:2.008239984512329,entropy:1.8357183933258057,explained_var_old:0.185,explained_var_new:0.212
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2093, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02710,lr_multiplier:7.594,loss:2.0618972778320312,entropy:1.902113437652588,explained_var_old:0.180,explained_var_new:0.214
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2094, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03357,lr_multiplier:7.594,loss:1.975388765335083,entropy:1.8608152866363525,explained_var_old:0.152,explained_var_new:0.202
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2095, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.03975,lr_multiplier:7.594,loss:1.9471642971038818,entropy:1.8361399173736572,explained_var_old:0.216,explained_var_new:0.235
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2096, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02669,lr_multiplier:7.594,loss:2.029374599456787,entropy:1.9237234592437744,explained_var_old:0.138,explained_var_new:0.161
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2097, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02426,lr_multiplier:7.594,loss:1.9224439859390259,entropy:1.8000478744506836,explained_var_old:0.126,explained_var_new:0.157
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2098, episode_len:26
TrainPipeline:run: 开始模型训练
kl:0.03110,lr_multiplier:7.594,loss:2.015080451965332,entropy:1.8928636312484741,explained_var_old:0.130,explained_var_new:0.166
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2099, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02532,lr_multiplier:7.594,loss:1.9811674356460571,entropy:1.8609228134155273,explained_var_old:0.108,explained_var_new:0.133
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2100, episode_len:19
TrainPipeline:run: 开始模型训练
kl:0.02392,lr_multiplier:7.594,loss:2.0624923706054688,entropy:1.9397863149642944,explained_var_old:0.076,explained_var_new:0.101
已经训练: 2100轮
Game end. Winner is player 2
Game end. Tie
Game end. Winner is player 2
Game end. Tie
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Winner is player 1
Game end. Tie
Game end. Winner is player 2
Game end. Winner is player 1
num_playouts:3000, win: 4, lose: 3, tie:3
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2101, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02731,lr_multiplier:7.594,loss:1.9811912775039673,entropy:1.8687161207199097,explained_var_old:0.129,explained_var_new:0.149
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2102, episode_len:25
TrainPipeline:run: 开始模型训练
kl:0.02904,lr_multiplier:7.594,loss:2.0031416416168213,entropy:1.8440241813659668,explained_var_old:0.173,explained_var_new:0.197
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2103, episode_len:23
TrainPipeline:run: 开始模型训练
kl:0.02813,lr_multiplier:7.594,loss:2.0467019081115723,entropy:1.9288421869277954,explained_var_old:0.113,explained_var_new:0.145
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2104, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02070,lr_multiplier:7.594,loss:2.050316572189331,entropy:1.9051913022994995,explained_var_old:0.155,explained_var_new:0.190
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2105, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02835,lr_multiplier:7.594,loss:2.006643772125244,entropy:1.8455288410186768,explained_var_old:0.145,explained_var_new:0.182
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2106, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02991,lr_multiplier:7.594,loss:1.9326152801513672,entropy:1.8523223400115967,explained_var_old:0.158,explained_var_new:0.193
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2107, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02824,lr_multiplier:7.594,loss:1.9479870796203613,entropy:1.840031623840332,explained_var_old:0.000,explained_var_new:0.065
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2108, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02066,lr_multiplier:7.594,loss:1.9215116500854492,entropy:1.841984748840332,explained_var_old:0.056,explained_var_new:0.077
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2109, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.02715,lr_multiplier:7.594,loss:1.9710819721221924,entropy:1.8015077114105225,explained_var_old:-0.028,explained_var_new:0.000
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2110, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.04072,lr_multiplier:5.062,loss:1.9377233982086182,entropy:1.8239967823028564,explained_var_old:0.110,explained_var_new:0.166
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2111, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02973,lr_multiplier:5.062,loss:2.002572536468506,entropy:1.9144861698150635,explained_var_old:0.047,explained_var_new:0.067
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2112, episode_len:44
TrainPipeline:run: 开始模型训练
kl:0.02200,lr_multiplier:5.062,loss:1.9777833223342896,entropy:1.8666870594024658,explained_var_old:0.059,explained_var_new:0.069
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 1
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2113, episode_len:27
TrainPipeline:run: 开始模型训练
kl:0.02189,lr_multiplier:5.062,loss:1.977522850036621,entropy:1.8631477355957031,explained_var_old:0.033,explained_var_new:0.048
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2114, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01051,lr_multiplier:5.062,loss:2.0604772567749023,entropy:1.8718678951263428,explained_var_old:0.017,explained_var_new:0.028
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2115, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01368,lr_multiplier:5.062,loss:2.042145252227783,entropy:1.8516907691955566,explained_var_old:0.016,explained_var_new:0.031
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2116, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01039,lr_multiplier:5.062,loss:2.047886371612549,entropy:1.8561915159225464,explained_var_old:0.006,explained_var_new:0.037
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2117, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01786,lr_multiplier:5.062,loss:2.0582242012023926,entropy:1.8224197626113892,explained_var_old:0.022,explained_var_new:0.037
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2118, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.01868,lr_multiplier:5.062,loss:2.1080727577209473,entropy:1.8798797130584717,explained_var_old:0.012,explained_var_new:0.029
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Tie
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2119, episode_len:64
TrainPipeline:run: 开始模型训练
kl:0.02156,lr_multiplier:5.062,loss:2.0346627235412598,entropy:1.822021722793579,explained_var_old:0.004,explained_var_new:0.012
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
Game end. Winner is player: 2
TrainPipeline: collect_selfplay_data：数据入栈
batch i:2120, episode_len:28
TrainPipeline:run: 开始模型训练
kl:0.01656,lr_multiplier:5.062,loss:2.082929849624634,entropy:1.894277572631836,explained_var_old:0.042,explained_var_new:0.068
TrainPipeline:run: 收集数据
Game:collect_selfplay_data: 开始自我博弈
